{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some Data\n",
    "\n",
    "a = \"purple is the best city in the forest\"\n",
    "b = \"there is an art to getting your way and throwing bananas on to the street is not it\"  # this is very similar to 'g'\n",
    "c = \"it is not often you find soggy bananas on the street\"\n",
    "d = \"green should have smelled more tranquil but somehow it just tasted rotten\"\n",
    "e = \"joyce enjoyed eating pancakes with ketchup\"\n",
    "f = \"as the asteroid hurtled toward earth becky was upset her dentist appointment had been canceled\"\n",
    "g = \"to get your way you must not bombard the road with yellow fruit\"  # this is very similar to 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = [a, b, c, d, e, f, g]\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/json/data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "docs = []\n",
    "for i in range(len(data)):\n",
    "    docs.append(data[i].get('contents'))\n",
    "    \n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(\"docs\", max_length=512, truncation=True, padding='max_length', return_tensors='pt', add_special_tokens=True)\n",
    "\n",
    "tokens.keys()\n",
    "tokens.get(\"input_ids\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokens.get('input_ids')[0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(input_ids)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.get('last_hidden_state').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4055,  1.1942,  0.7918,  ..., -0.5296,  0.7376,  0.3884],\n",
       "         [-0.4264,  0.9390,  0.8876,  ..., -0.2034,  0.5843,  0.2582],\n",
       "         [-0.4308,  0.8892,  1.3110,  ..., -0.4963,  0.8360,  0.3146],\n",
       "         ...,\n",
       "         [ 0.1689,  1.0010,  0.4724,  ..., -0.1787,  0.1866, -0.1446],\n",
       "         [ 0.1976,  0.9855,  0.5090,  ..., -0.2269,  0.2191, -0.1096],\n",
       "         [ 0.0189,  1.2638,  0.6223,  ..., -0.3361,  0.2688, -0.0729]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "# the embedding of sentence a\n",
    "print(embeddings.shape)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## mean pooling to create the sentece vector\n",
    "\n",
    "# 1. multiply each value in embeddings tensor by its respective attention_mask value.\n",
    "\n",
    "masks = tokens.get('attention_mask')[0].unsqueeze(-1).expand(embeddings.size()).float()\n",
    "print(masks.shape)\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * masks\n",
    "print(masked_embeddings.shape)\n",
    "torch.sum(masked_embeddings, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4055,  1.1942,  0.7918,  ..., -0.5296,  0.7376,  0.3884],\n",
       "         [-0.4264,  0.9390,  0.8876,  ..., -0.2034,  0.5843,  0.2582],\n",
       "         [-0.4308,  0.8892,  1.3110,  ..., -0.4963,  0.8360,  0.3146],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 512, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * masks\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted = torch.clamp(masks.sum(1), min=1e-9)\n",
    "counted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.4737e-01, -2.2722e-01,  2.8184e-01,  4.9897e-01, -6.9554e-02,\n",
       "        -8.5028e-01,  5.3480e-01,  4.9781e-01,  4.2247e-01, -8.1101e-01,\n",
       "        -3.3428e-01, -8.4455e-01,  2.6676e-01,  3.6907e-01,  6.6989e-01,\n",
       "         2.0275e-01, -3.1590e-01,  9.6454e-02,  8.3629e-01, -6.4574e-01,\n",
       "        -1.7763e-01, -4.8748e-01,  1.8015e-02, -5.8890e-01,  8.6877e-01,\n",
       "        -4.7323e-01,  1.6984e-01, -3.7928e-02,  5.0701e-01,  3.2727e-01,\n",
       "         1.2181e-01,  5.0407e-01, -3.9131e-01, -5.4687e-01,  8.7298e-01,\n",
       "         1.0905e+00, -8.5406e-01, -3.7172e-01,  2.3221e-01, -8.2706e-01,\n",
       "         8.6060e-01, -6.6310e-01,  5.0642e-01, -7.8033e-01, -1.2961e+00,\n",
       "        -8.5810e-02, -1.5043e+00,  1.1714e+00,  9.5849e-01, -7.5900e-01,\n",
       "        -1.1085e-02,  7.5281e-02,  3.8400e-01,  3.4750e-01, -8.3249e-01,\n",
       "         2.6063e-01, -6.0691e-02,  1.5899e-01,  1.2728e-01, -4.8628e-01,\n",
       "        -7.4357e-01, -4.9982e-01, -3.9453e-01, -2.0274e-01, -2.4762e-01,\n",
       "         5.8482e-01,  8.4303e-01,  5.1525e-01, -6.9963e-01,  9.4058e-02,\n",
       "         4.1347e-01, -5.9724e-01,  2.7850e-01, -4.7246e-01, -9.1138e-01,\n",
       "         1.8015e-01, -2.0660e-01, -1.8533e-01,  2.0990e+00,  8.1890e-01,\n",
       "         2.6493e-01,  2.6092e-01, -1.1306e-01,  1.4458e-01,  1.9849e-02,\n",
       "         5.6406e-01, -3.2352e-01, -1.9231e-01, -1.1515e+00,  3.0438e-01,\n",
       "         1.7243e-01, -5.8423e-01,  1.6128e+00,  1.3345e-02, -6.5910e-01,\n",
       "        -4.0941e-01,  2.3049e-01, -4.7111e-01, -4.9019e-01,  1.6925e-01,\n",
       "         3.2993e-01, -1.7486e-01, -4.2811e-01,  6.3109e-01, -1.8409e-01,\n",
       "         7.6253e-01, -2.8653e-01, -1.9953e-01, -5.0459e-01,  3.0243e-01,\n",
       "         2.8744e-01, -5.3957e-01, -3.3965e-01,  7.2400e-01, -6.5985e-01,\n",
       "         4.2787e-01, -1.0064e+00,  3.2174e-01,  4.5329e-02,  4.9040e-01,\n",
       "         4.9610e-01, -5.4614e-02,  1.1237e-01,  6.7403e-01,  3.9236e-01,\n",
       "        -3.3424e-01, -4.0921e-01,  1.2401e+00, -4.5133e-01,  2.3026e-01,\n",
       "        -4.8885e-01,  5.4188e-01,  3.6293e-01,  8.0700e-02,  8.4594e-02,\n",
       "        -5.2867e-01, -1.8386e-01,  1.9901e-01, -6.4625e-02, -3.6870e-01,\n",
       "        -6.6089e-01, -6.8108e-02,  2.1076e-01, -2.8103e-01,  3.8485e-01,\n",
       "         1.1390e-01,  1.8962e-01, -1.1465e+00,  2.0372e-01, -6.6746e-01,\n",
       "        -1.5700e-02,  4.5084e-01, -1.2520e+00, -2.1340e-01, -2.4814e-01,\n",
       "         1.1750e-01, -4.5316e-01, -4.7833e-01, -9.3139e-02,  6.2667e-02,\n",
       "        -1.4547e-01,  6.9999e-01,  4.0229e-01,  6.8805e-01, -7.3595e-01,\n",
       "        -1.0755e+00,  5.1120e-01,  7.0331e-01,  1.9685e-01,  4.4647e-01,\n",
       "         4.9125e-01,  4.1147e-01,  6.6421e-01, -9.8339e-02,  1.4755e-01,\n",
       "         2.6713e-01,  3.9782e-01, -9.6794e-02, -1.5793e-01, -5.8853e-01,\n",
       "        -1.2378e-01,  9.1204e-01,  4.5161e-01,  2.7675e-01,  6.1116e-01,\n",
       "         9.7963e-02,  7.6397e-02,  3.1264e-01,  1.1262e+00, -2.6824e-01,\n",
       "         3.9349e-01, -1.4910e-01, -3.7083e-01,  9.7529e-02, -3.0887e-01,\n",
       "         7.2278e-01, -5.0006e-01, -2.1800e-01, -9.9095e-01, -2.3468e-01,\n",
       "         6.5058e-01, -1.0293e-01, -7.5049e-01, -4.7801e-01, -1.6090e+00,\n",
       "         1.0267e-01,  4.4494e-01,  2.4905e-01, -1.1085e+00, -2.3721e-01,\n",
       "        -4.9727e-02,  1.9947e-01,  7.1846e-01, -6.8708e-01,  4.9423e-01,\n",
       "         4.2463e-01, -1.2147e-02, -3.4820e-01,  6.9147e-01, -4.6289e-01,\n",
       "        -2.1349e-01,  6.5843e-01, -4.8641e-01,  3.4150e-01, -2.5226e-01,\n",
       "         4.2009e-01,  4.6285e-01, -2.9478e-01, -1.5329e+00,  5.5617e-01,\n",
       "        -5.8227e-01, -2.3658e-01, -1.3864e+00, -3.9372e-01,  6.1281e-01,\n",
       "         4.9274e-01, -8.3581e-01,  9.9159e-02,  1.9483e+00, -2.5340e-01,\n",
       "         5.5602e-01, -5.9038e-01, -1.8963e-01,  6.7323e-01, -3.8632e-01,\n",
       "        -2.6865e-02,  5.6259e-01, -1.0380e+00,  4.5204e-02,  7.1008e-01,\n",
       "        -1.0329e+00,  1.6499e-01,  1.1865e-01,  4.0741e-01,  1.2875e+00,\n",
       "         6.4202e-02, -7.9507e-01,  3.8245e-01, -1.1990e-01,  1.0175e+00,\n",
       "        -1.4687e-01, -1.4631e-01, -1.4310e+00,  2.9680e-02, -1.1214e-01,\n",
       "        -3.5622e-01, -8.8862e-02,  1.3216e-01,  6.7696e-02, -6.4714e-01,\n",
       "        -5.4033e-01, -5.7400e-02, -7.2819e-03,  1.9134e-01, -1.6402e-01,\n",
       "        -4.4090e-01,  9.9642e-01, -8.2393e-04, -1.2624e-01, -3.7520e-01,\n",
       "         3.3320e-01,  1.9625e-01, -1.7739e+00, -5.9974e-01, -5.1123e-02,\n",
       "         1.7873e-01,  7.0910e-01, -2.6113e-01, -2.4397e-01, -9.0056e-01,\n",
       "        -1.2428e-01, -4.1718e-02, -2.8253e-01, -7.1814e-01,  7.1684e-02,\n",
       "        -2.4431e-01,  4.0953e-01, -2.9171e-02, -5.8153e-01, -1.7561e-01,\n",
       "         2.0583e-02,  3.9347e-01, -5.9716e-01, -1.5539e-01, -2.2104e-01,\n",
       "        -3.1616e-02,  2.3537e-01,  4.2227e-01, -8.9128e-01,  6.0042e-01,\n",
       "        -8.8359e-01,  3.0017e-01, -7.9628e-01,  6.7100e-01,  8.2367e-01,\n",
       "         7.1226e-01, -1.4772e+00, -4.0352e-01,  8.3060e-02, -6.0489e-01,\n",
       "        -4.4679e-01, -3.3746e-01,  2.5329e-01,  9.9050e-01,  8.9260e-01,\n",
       "        -9.3712e-01, -4.6774e-01,  5.8410e-01, -1.1956e+00,  2.5660e-01,\n",
       "         6.5512e-01, -3.3022e-01,  9.1754e-01, -8.2582e-02, -3.8209e-01,\n",
       "         8.0787e-02, -1.5702e+00, -7.5961e-01,  7.6788e-02,  2.8549e-01,\n",
       "         5.6213e-01, -1.0140e-01, -3.0450e-02, -5.2973e-01,  6.3545e-01,\n",
       "         3.7442e-01, -4.6540e-01,  9.3755e-02, -7.6872e-01,  1.5053e-01,\n",
       "         3.8345e-01,  1.0701e+00,  9.3922e-01, -2.2159e-01,  6.1957e-01,\n",
       "        -4.6017e-03, -2.0066e-01,  1.8634e-01, -2.2246e-01,  3.0883e-01,\n",
       "         2.7265e-01,  8.2002e-01, -2.1302e-01,  1.3155e-01, -1.2314e-01,\n",
       "         3.0487e-01, -4.7951e-02, -1.9159e-02,  3.4522e-01,  8.0738e-02,\n",
       "         1.9742e-01,  9.5508e-02,  3.0940e-01,  6.0175e-01, -1.5563e-01,\n",
       "        -5.1198e-01, -7.2332e-01,  3.4154e-01,  1.0372e+00, -1.9142e-01,\n",
       "         1.9784e-01, -3.5706e-01, -2.0295e-02, -7.6522e-01, -3.8600e-01,\n",
       "        -1.7860e-01,  1.8847e-01, -4.0040e-02, -2.2989e-01, -5.3121e-01,\n",
       "         4.1526e-01,  6.7128e-01, -4.8569e-01, -1.1328e-02,  4.3127e-01,\n",
       "         5.2547e-01,  7.8982e-01,  7.6638e-02, -5.2246e-01,  3.3166e-01,\n",
       "        -9.2711e-01,  2.7213e-01,  2.5573e-01, -1.9490e-01,  8.3224e-01,\n",
       "        -4.3337e-01,  2.9814e-01, -3.3110e-01,  3.1387e-02,  3.9450e-01,\n",
       "        -3.3563e-01,  7.7028e-01,  5.0830e-01,  2.3275e-01, -3.2074e-01,\n",
       "         4.2554e-01,  7.6127e-01, -1.1947e+00, -3.1093e-01,  2.9903e-02,\n",
       "         3.1014e-01,  9.6880e-01,  1.5627e+00, -1.6641e-01,  8.0528e-01,\n",
       "         8.5667e-02,  5.1927e-01, -1.0862e+00,  4.0865e-01,  1.1774e+00,\n",
       "         1.2791e+00,  6.6092e-01, -1.5359e+00,  3.8167e-01, -1.5634e-02,\n",
       "         2.6666e-01, -1.0260e+00, -1.4716e+00,  5.7920e-01,  1.8394e-01,\n",
       "        -1.2696e-01, -8.9983e-01,  4.8056e-01,  1.8543e-01,  5.1558e-02,\n",
       "        -5.9695e-01, -1.2361e-02, -7.4092e-02,  3.9930e-01,  5.0970e-01,\n",
       "        -1.0933e-01, -3.6547e-01,  1.3653e+00, -5.6032e-01,  6.8942e-01,\n",
       "        -2.7686e-01, -9.9802e-01,  2.1366e-01, -3.0949e-01, -1.0895e+00,\n",
       "        -2.9778e-02, -8.9311e-01,  2.7800e-01, -9.0195e-01, -1.1710e-01,\n",
       "        -2.3929e-02, -5.2581e-01, -1.9516e-01,  6.3414e-01, -2.9097e-02,\n",
       "         5.2666e-01,  1.6649e-01,  6.1118e-01,  1.8136e+00,  5.9386e-01,\n",
       "        -2.6794e-01, -1.9541e+00,  1.4032e+00,  1.0065e+00,  1.2540e+00,\n",
       "        -1.0527e+00, -4.9919e-01,  5.1575e-01, -1.0124e-01, -1.2004e-01,\n",
       "         3.4122e-02,  8.4891e-02, -4.2627e-01, -1.5726e-02,  3.3613e-02,\n",
       "        -7.9701e-01, -4.8075e-01, -1.5240e-01,  1.5436e-01, -8.1723e-01,\n",
       "        -1.4992e-01, -1.3680e-01,  7.1994e-01,  7.0455e-01, -7.7383e-01,\n",
       "        -1.0044e+00,  1.0568e-01,  3.0909e-01, -8.5451e-01,  1.4899e-01,\n",
       "        -2.6101e-01, -1.7732e-01, -9.0095e-01, -3.9286e-01, -2.6829e-01,\n",
       "        -3.7420e-01,  8.0366e-02,  2.9417e-01, -3.1630e-01,  2.9043e-01,\n",
       "         1.0176e+00, -6.3288e-01, -1.1468e-02, -6.3995e-01, -8.1466e-01,\n",
       "        -9.4510e-01, -7.9918e-01, -1.1023e-01, -1.9778e-01, -1.0153e-01,\n",
       "        -3.9589e-03, -3.5009e-01, -7.5386e-01, -1.4878e+00, -5.5277e-01,\n",
       "        -7.5618e-01, -6.7890e-01,  5.6049e-01, -3.8585e-02,  8.4593e-01,\n",
       "         1.0881e+00, -4.5205e-01, -4.6073e-01, -1.5644e+00,  1.3261e+00,\n",
       "         8.1128e-01,  5.5870e-01, -3.2821e-02,  7.9929e-01, -6.0643e-01,\n",
       "        -7.3654e-01,  2.4073e-02, -5.7210e-01, -1.2090e-02,  7.4237e-01,\n",
       "        -1.5192e+00, -4.5631e-01, -9.6899e-02, -9.6382e-02, -8.2053e-01,\n",
       "         5.6322e-01, -8.6322e-01, -1.7561e-01, -8.9005e-01, -4.3314e-01,\n",
       "         1.0062e+00,  9.9921e-01, -8.4493e-01, -1.2505e-01,  1.9691e-01,\n",
       "        -2.6697e-01, -3.4957e-01, -1.0094e+00, -5.0459e-01,  9.9025e-02,\n",
       "         5.7917e-01, -3.8294e-01,  3.2295e-01,  8.7340e-01, -9.0697e-01,\n",
       "        -5.8082e-02,  2.0316e-01, -5.1189e-01,  1.0859e-01,  3.8348e-01,\n",
       "         7.9237e-01, -3.5136e-02,  1.9148e-01,  1.0847e-01, -2.5982e-01,\n",
       "         8.1713e-01, -5.4490e-01, -7.8685e-01,  2.9958e-02, -3.2939e-01,\n",
       "        -1.0812e-01, -4.5424e-01,  1.8019e-01,  7.3091e-01, -1.1718e+00,\n",
       "         6.7254e-01,  3.4474e-01, -6.6295e-04,  4.6767e-01,  3.8090e-02,\n",
       "         9.4089e-01, -3.0376e-02,  1.0550e-01, -3.3173e-02, -5.4099e-01,\n",
       "         6.4510e-01,  9.3501e-01, -5.3784e-01,  7.5026e-02,  1.1144e+00,\n",
       "         6.4825e-01, -7.5878e-01,  2.6132e-01,  2.3636e-01,  2.8603e-02,\n",
       "        -3.0280e-01,  9.3128e-01, -6.6818e-01,  1.5840e-01,  8.9072e-01,\n",
       "        -2.4059e-01,  1.1326e+00, -5.7109e-01, -6.2637e-01,  1.2109e+00,\n",
       "        -7.1993e-01,  5.2437e-01,  3.2790e-01, -9.2795e-01,  2.3127e-01,\n",
       "        -2.4524e-02,  2.4517e-01, -4.8746e-01,  2.1406e-01, -6.6621e-01,\n",
       "         8.8873e-01,  1.1119e-01,  1.2648e+00,  4.6172e-01,  7.8899e-01,\n",
       "        -1.0523e+00,  5.6776e-01, -8.3123e-01,  2.0882e-01,  3.3356e-01,\n",
       "        -2.4385e-01, -2.3344e-01, -1.4415e-01,  6.3077e-01, -1.2950e-02,\n",
       "         7.7551e-01,  9.6255e-01, -5.0596e-03, -2.5529e-01, -4.2347e-01,\n",
       "        -9.8798e-01, -5.1313e-01,  7.1460e-02,  1.1752e+00, -9.9537e-02,\n",
       "         6.3416e-01,  7.3167e-01, -4.4543e-01, -5.8759e-01,  1.0840e+00,\n",
       "         2.5009e-01, -1.2671e+00, -7.0772e-02,  5.9007e-01, -2.9989e-01,\n",
       "         3.2634e-01, -3.7943e-01, -1.1077e+00, -3.4105e-01,  2.7659e-01,\n",
       "         1.4344e-01, -3.9511e-01,  4.8831e-01, -8.3567e-01, -2.5951e-01,\n",
       "         8.3467e-01, -1.6386e-01,  5.9610e-01, -6.2584e-01, -5.8303e-01,\n",
       "        -1.0221e-01,  5.0836e-01,  5.5109e-01, -5.5228e-01,  9.0674e-01,\n",
       "         9.0884e-02,  1.2340e+00,  1.1278e-01, -4.8567e-01, -8.4079e-01,\n",
       "         3.5773e-01,  2.2397e-01,  3.6136e-01,  9.0805e-01,  1.2010e+00,\n",
       "        -7.2132e-01,  6.5746e-01, -3.0374e-01, -5.1242e-01,  6.9791e-02,\n",
       "         1.3151e+00, -1.8580e+00, -5.1702e-01, -4.9445e-01,  2.5888e-01,\n",
       "        -6.4793e-01,  4.3484e-02,  8.5197e-01,  1.1312e+00, -5.6836e-01,\n",
       "         4.6200e-01,  3.7488e-01,  3.0590e-02, -5.8471e-01, -3.3962e-01,\n",
       "        -5.6087e-01, -3.1393e-01,  3.3920e-01, -5.4050e-02,  4.1015e-01,\n",
       "         1.1411e+00,  1.4532e-02,  6.8895e-01, -8.3302e-01,  2.6343e-01,\n",
       "        -1.3472e-02, -5.0436e-01,  5.6868e-01, -4.6344e-02, -3.6871e-01,\n",
       "         4.2651e-01,  6.8556e-02, -1.9964e-01, -4.9893e-01, -4.5149e-01,\n",
       "        -1.0263e+00,  4.9358e-01, -4.1491e-01, -3.7544e-01,  1.0603e-01,\n",
       "         4.7629e-01, -5.7529e-01,  1.0871e-01, -8.3723e-01, -9.0484e-01,\n",
       "         4.8369e-01, -5.3170e-01, -4.3313e-01,  1.0814e-01, -7.7200e-01,\n",
       "         2.5073e-01, -7.1376e-01,  2.1759e-01, -5.5246e-01, -1.2511e+00,\n",
       "        -4.8391e-02, -1.0088e+00, -2.6149e-02, -4.0379e-01, -1.2720e-01,\n",
       "         1.9777e-01,  4.4348e-01,  7.9200e-02], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = summed / counted\n",
    "\n",
    "mean_pooled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.metrics.pariwise'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpariwise\u001b[39;00m \u001b[39mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# convert to numpy array from torch tensor\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.metrics.pariwise'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pariwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# convert to numpy array from torch tensor\n",
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "scores = np.zeros(mean_pooled.shape[0], mean_pooled.shape[0])\n",
    "\n",
    "for i in range(mean_pooled.shape[0]):\n",
    "    scores[i, :] = cosine_similarity(mean_pooled[i], mean_pooled)[0]\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[[1, 1], \n",
    "                   [2, 2]]])\n",
    "\n",
    "counted_A = torch.clamp(A.sum(1), min=1e-9)\n",
    "\n",
    "counted_A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
