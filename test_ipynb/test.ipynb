{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, subprocess, json\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "# from search_l3s_search.api.encoder.logic import BertGermanCasedDenseEncoder\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
    "\n",
    "dataset_path = \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/json/data.json\"\n",
    "\n",
    "\n",
    "with open(dataset_path) as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "# print(dataset)\n",
    "    \n",
    "        \n",
    "# enc = BertGermanCasedDenseEncoder()\n",
    "\n",
    "# enc.dataset_encoder()\n",
    "contents = []\n",
    "for d in dataset:\n",
    "        contents.append(d[\"contents\"])\n",
    "        \n",
    "type(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048218488693237305\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "tokenizer(contents, add_special_tokens=True, padding='max_length', max_length=512, truncation=True)\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1616382598876953\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "for c in contents:\n",
    "    tokens = tokenizer(c, add_special_tokens=True, padding='max_length', max_length=512, truncation=True)\n",
    "    \n",
    "elapsed = time.time() - t\n",
    "print(elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07217977941036224, 0.09157858043909073, 0.05999606475234032, -0.020205063745379448, 0.02170461416244507, -0.02944577857851982, 0.03564104810357094, 0.0004519230860751122, 0.06526193022727966, -0.11502823233604431, 0.011782891117036343, 0.06713750213384628, -0.06128199025988579, 0.006231870502233505, 0.004843269940465689, 0.051830656826496124, -0.03202732279896736, -0.01102643646299839, 0.08238693326711655, 0.058150727301836014, 0.028431113809347153, -0.005219425540417433, 0.08151587843894958, 0.04477493464946747, -0.013574089854955673, 0.03810984641313553, -0.05324321985244751, 0.05443398654460907, 0.06877885013818741, 0.013043617829680443, 0.09326209872961044, -0.015830939635634422, 0.04249339923262596, 0.07140932977199554, 0.07173920422792435, 0.017670203000307083, -0.112077496945858, -0.07562334090471268, 0.059521548449993134, 0.07727187126874924, 0.07298506796360016, 0.11304982006549835, 0.025053592398762703, -0.03082236647605896, 0.019926216453313828, -0.07809607684612274, -0.03780963644385338, -0.032319966703653336, -0.003458051709458232, -0.08691567927598953, 0.03114311397075653, 0.01244838535785675, 0.06066260486841202, 0.04374367371201515, -0.10687128454446793, -0.08608587831258774, 0.10647741705179214, 0.02396652288734913, -0.014954113401472569, 0.10234984755516052, -0.06292112171649933, 0.08440732955932617, 0.06378950923681259, 0.01864585466682911, 0.1112263947725296, -0.09706335514783859, -0.08924123644828796, -0.07284083217382431, 0.019687091931700706, -0.028796974569559097, -0.04119914770126343, -0.141618549823761, -0.018335873261094093, 0.03202801197767258, -0.08144234120845795, -0.0553269162774086, -0.057262979447841644, 0.08365405350923538, -0.03397713974118233, 0.07905979454517365, 0.05542796105146408, -0.0026162066496908665, -0.0177549347281456, 0.010862321592867374, -0.016288045793771744, 0.041579943150281906, -0.008277698419988155, 0.08733944594860077, 0.022695381194353104, -0.037821874022483826, 0.03174199163913727, -0.02361334301531315, -0.04268179088830948, -0.038264721632003784, -0.03374132513999939, -0.012953228317201138, 0.008493403904139996, -0.05209215730428696, -0.06259632855653763, -0.04746628552675247, -0.06379155814647675, -0.13149043917655945, 0.0395466573536396, -0.03199750930070877, -0.05167046934366226, -0.1404585838317871, -0.08386363834142685, -0.043144889175891876, 0.040471017360687256, 0.01261887140572071, -0.03527580574154854, 0.028574049472808838, 0.007634025998413563, -0.0033390342723578215, 0.056465279310941696, -0.0647340789437294, 0.031603723764419556, -0.030066171661019325, -0.06557171046733856, 0.06484798341989517, 0.07020017504692078, 0.05587660148739815, -0.13524223864078522, 0.14875857532024384, -0.08065780252218246, -0.03870702162384987, -0.014905081130564213, -0.11362398415803909, 0.026430148631334305, 0.027702314779162407, 0.0769462063908577, 0.030611857771873474, 0.03181581199169159, -0.11043741554021835, -0.025730393826961517, 0.1446973979473114, 0.013399288058280945, 0.14867886900901794, 0.07980140298604965, -0.0658775120973587, 0.01957745850086212, -0.10529480874538422, 0.04611585661768913, 0.014239629730582237, -0.05925234407186508, -0.006889231503009796, -0.03802907094359398, 0.07637656480073929, -0.03730400279164314, 0.10687784850597382, -0.02470715343952179, -0.10359369218349457, -0.4139382243156433, -0.03156024217605591, -0.001616805442608893, 0.016756031662225723, 0.05738787725567818, -0.01561539527028799, 0.031279124319553375, 0.07784814387559891, 0.0014765559462830424, 0.07943745702505112, 0.08337833732366562, -0.01599281094968319, 0.06381641328334808, -0.019637122750282288, 0.053972553461790085, 0.02876831404864788, -0.052523788064718246, 0.007298172451555729, 0.09315893054008484, -0.037286434322595596, -0.020963402464985847, 0.11926402896642685, 0.0680248886346817, 0.021709831431508064, 0.008438309654593468, 0.06257833540439606, 0.012394954450428486, -0.02800765447318554, -0.07086976617574692, -0.08820971101522446, 0.00019984332902822644, 0.12487538158893585, -0.019607828930020332, -0.00686393678188324, 0.026706814765930176, -0.11211711913347244, 0.05583515763282776, -0.09829081594944, -0.006042891647666693, 0.05737804248929024, 0.04778728261590004, -0.025390801951289177, -0.01877204142510891, 0.06043194606900215, -0.06864549964666367, 0.019932923838496208, -0.04134960100054741, -0.06771182268857956, 0.03249567374587059, -0.04051549360156059, 0.10638175904750824, 0.0029933247715234756, 0.0021597999148070812, -0.16657163202762604, 0.0008049861644394696, 0.09905217587947845, 0.09896161407232285, 0.07476895302534103, 0.015744537115097046, 0.012466933578252792, 0.05243516340851784, 0.00714125158265233, 0.06375081837177277, -0.03406604379415512, 0.053776368498802185, 0.04064870998263359, 0.09413112699985504, -0.009069847874343395, -0.004674719180911779, -0.006028424017131329, 0.014769821427762508, -0.020958339795470238, 0.03841320052742958, 0.03982025012373924, -0.05085178092122078, -0.01719462126493454, 0.010405494831502438, -0.040849581360816956, -0.06234819442033768, -0.019010664895176888, 0.059785258024930954, -0.0258787851780653, -0.07856287062168121, -0.0607311837375164, 0.02905231900513172, 0.046296220272779465, -0.046372190117836, 0.04802146926522255, -0.010037219151854515, 0.031446851789951324, -0.022888002917170525, -0.015697747468948364, 0.021306941285729408, -0.06901635229587555, -0.05065780133008957, 0.03836226835846901, -0.02874990925192833, 0.010852635838091373, 0.04305426776409149, -0.05413355305790901, -0.01691618002951145, 0.025296946987509727, 0.004261430352926254, 0.060236331075429916, -0.0009042636957019567, 0.04011911898851395, -0.11522509157657623, -0.15564125776290894, 0.07415896654129028, 0.02865217812359333, 0.06870726495981216, -0.07126495987176895, 0.0007860799669288099, 0.037011221051216125, 0.00187009631190449, 0.03882722929120064, -0.05078078806400299, 0.016305120661854744, -0.14755217730998993, 0.011818119324743748, -0.022487955167889595, 0.03218904510140419, 0.0022844362538307905, -0.06293238699436188, -0.058282315731048584, -0.023906225338578224, 0.04806641861796379, 0.13313615322113037, 0.022141072899103165, -0.0021466182079166174, -0.18747787177562714, 0.02108127623796463, 0.04588036984205246, 0.11132293194532394, -0.08114037662744522, -0.10213742405176163, 0.04355598986148834, -0.030371343716979027, 0.04136289656162262, -0.05255204439163208, 0.03825286403298378, -0.04242638126015663, 0.08432900905609131, -0.05975628271698952, -0.002494477666914463, -0.03483480587601662, -0.008981270715594292, 0.005878185387700796, 0.07652740180492401, 0.01522866077721119, -0.02359769493341446, -0.11165742576122284, -0.013161431066691875, -0.03691820427775383, 0.10810402035713196, 0.09407932311296463, -0.14596910774707794, -0.07568518817424774, 0.11998773366212845, 0.0395655520260334, -0.020471680909395218, 0.017040761187672615, -0.03864702582359314, -0.06098806858062744, 0.0735083743929863, 0.04419674351811409, 0.04197385162115097, 0.07203104346990585, 0.005639326758682728, -0.06569630652666092, -0.04457924887537956, 0.04111413657665253, -0.0038624650333076715, -0.06149357184767723, -0.0802936777472496, -0.022922474890947342, 0.048245593905448914, -0.0017321642953902483, -0.13971258699893951, -0.09676367789506912, 0.04952014982700348, 0.18706274032592773, -0.1383190155029297, -0.04994567111134529, -0.02400934137403965, -0.09772156178951263, 0.06797230988740921, -0.006783011835068464, 0.04344978556036949, 0.059448059648275375, -0.08215052634477615, 0.019326524809002876, -0.0063220662996172905, -0.03481149673461914, -0.03555305302143097, -0.05894417315721512, 0.008726408705115318, 0.0370209738612175, 0.04383842647075653, 0.0015914510004222393, 0.011000390164554119, -0.007586173713207245, -0.09133855998516083, -0.017960241064429283, -0.005470593925565481, 0.05646015703678131, 0.027121536433696747, -0.04559476301074028, -0.046081945300102234, -0.060977138578891754, -0.03469599038362503, 0.1747344732284546, -0.03431238606572151, 0.026186306029558182, 0.004647037945687771, -0.025956423953175545, 0.0165752861648798, 0.0009522181353531778, 0.05349193513393402, 0.018732229247689247, -0.03701324388384819, 0.05874583125114441, 0.11903483420610428, 0.009711705148220062, -0.018031451851129532, 0.013718953356146812, -0.024636194109916687, 0.017658626660704613, 0.08405585587024689, 0.22935566306114197, 0.0445270910859108, 0.07273023575544357, 0.09934331476688385, 0.05696619302034378, -0.0471552349627018, -0.12969465553760529, 0.020479045808315277, 0.02720257267355919, -0.011201808229088783, -0.15089525282382965, 0.03393229842185974, -0.03848544880747795, 0.09088961780071259, -0.05787360295653343, 0.05929088965058327, -0.027653884142637253, -0.02981552854180336, -0.017159003764390945, 0.029317570850253105, -0.04079794883728027, -0.09183920174837112, 0.04443797096610069, 0.08239676058292389, -0.005234256386756897, 0.0034682152327150106, 0.017811203375458717, -0.07038193941116333, 0.02816718816757202, 0.04451397806406021, -0.018225446343421936, -0.048454511910676956, -0.07535231858491898, 0.07551964372396469, -0.05950745567679405, 0.05782071128487587, 0.01430582720786333, 0.04682323336601257, -0.06441566348075867, -0.06802766025066376, 0.05003197118639946, -0.02618178352713585, 0.05939885973930359, 0.005832392256706953, -0.05010480806231499, -0.010403566062450409, 0.0029418575577437878, -0.10014328360557556, -0.04191119596362114, 0.047005318105220795, 0.06049670651555061, -0.018231548368930817, 0.0729234367609024, -0.004965652246028185, 0.0031512349378317595, 0.18027684092521667, 0.060937508940696716, 0.0441029891371727, 0.08137736469507217, 0.024821868166327477, 0.009091155603528023, -0.11182565987110138, 0.029594067484140396, -0.06701400876045227, -0.06695496290922165, 0.017486581578850746, -0.05104776844382286, -0.03370347246527672, 0.026702238246798515, 0.06920892000198364, -0.025511201471090317, 0.09421266615390778, 0.07729265838861465, 0.047868505120277405, -0.037728454917669296, 0.08922233432531357, 0.048591408878564835, -0.0036619589664041996, 0.14548204839229584, 0.07045459747314453, 0.07261732965707779, 0.031684521585702896, 0.024462152272462845, -0.09110432118177414, -0.12536175549030304, -0.029440466314554214, -0.11099090427160263, 0.105542853474617, 0.057546019554138184, -0.02081681787967682, -0.017047077417373657, 0.09009755402803421, -0.04116532951593399, 0.009722073562443256, 0.08750409632921219, -0.0140022998675704, 0.07773608714342117, 0.07081062346696854, -0.006457127630710602, 0.08159588277339935, 0.0023892621975392103, -0.013982105068862438, 0.1261834353208542, 0.03659052029252052, 0.10033003240823746, -0.05281457304954529, -0.004954898729920387, 0.1257479339838028, -0.026086611673235893, -0.009515098296105862, 0.05939316749572754, -0.007837322540581226, -0.1479477882385254, 0.016612417995929718, 0.006620196159929037, 0.04435395449399948, -0.06698277592658997, 0.024178776890039444, 0.0374426506459713, -0.027690226212143898, 0.04153275489807129, 0.08977867662906647, -0.06431743502616882, -0.05474352464079857, 0.06568732112646103, 0.08242570608854294, -0.010887129232287407, 0.01852988265454769, -0.08068842440843582, 0.14599506556987762, -0.027479471638798714, -0.08816250413656235, -0.09868234395980835, 0.01405759621411562, 0.011440127156674862, -0.057948339730501175, -0.06175613775849342, 0.024795355275273323, -0.11445093154907227, 0.013647542335093021, -0.04504646360874176, -0.08904647082090378, 0.01833576336503029, -0.004791127052158117, 0.02439987286925316, 0.0021852205973118544, -0.1223888099193573, 0.028902219608426094, -0.022478651255369186, 0.06885887682437897, 0.005429770797491074, 0.011928297579288483, -0.20552872121334076, 0.03740290552377701, 0.06833569705486298, -0.04436023533344269, 0.03258507326245308, 0.0014892719918861985, 0.04729243740439415, 0.10115007311105728, -0.000295432546408847, 0.07011423259973526, 0.08278696984052658, -0.0520700067281723, 0.06344971805810928, -0.02571973390877247, 0.08673211932182312, 0.06339197605848312, 0.08426114916801453, -0.01032283902168274, -0.04122136905789375, 0.006692804861813784, -0.03156983479857445, -0.04988590255379677, 0.04138132557272911, 0.023749105632305145, -0.02722736820578575, 0.08611682057380676, 0.030304159969091415, 0.024305693805217743, -0.0328376367688179, 0.05511205270886421, 0.07093323767185211, -0.016538197174668312, 0.08726464211940765, -0.03245586156845093, -0.027805790305137634, -0.04045988246798515, 0.08781979978084564, -0.061066120862960815, -0.041885118931531906, -0.06602668762207031, 0.003769936738535762, 0.05389191210269928, -0.0160076767206192, -0.014020858332514763, -0.0622028112411499, -0.04506570100784302, -0.03593747690320015, -0.003660567570477724, -0.030565308406949043, -0.022045180201530457, -0.01178345549851656, 0.03152718394994736, -0.0252088513225317, 0.060314010828733444, 0.04907607659697533, 1.1895909309387207, 0.03281673416495323, -0.02565036155283451, -0.04388634115457535, -0.049698978662490845, 0.03259219974279404, -0.0009453032398596406, -0.07019492238759995, -0.0761152133345604, 0.027592625468969345, -0.008910372853279114, 0.042739320546388626, -0.04403841122984886, 0.026196228340268135, -0.019422322511672974, -0.006804562173783779, -0.05019931122660637, 0.012751240283250809, 0.04934714734554291, 0.06463629007339478, -0.015814239159226418, 0.10221157222986221, 0.04771501198410988, 0.05714238062500954, -0.18368951976299286, -0.13771939277648926, 0.013752506114542484, -0.025812853127717972, -0.009033935144543648, 0.03506069630384445, 0.006388361565768719, 0.018412038683891296, 0.011328662745654583, 0.013283503241837025, -0.048123687505722046, 0.029530471190810204, -0.02520117349922657, 0.04174065589904785, -0.08431077003479004, -0.016338355839252472, 0.0032806789968162775, -0.03592800348997116, -0.1197565495967865, -0.07798422873020172, 0.0033032798673957586, 0.009607422165572643, 0.036609552800655365, 0.057598818093538284, 0.05838471278548241, 0.010944980196654797, 0.059312377125024796, -0.03359165042638779, -0.07645457237958908, 0.08749861270189285, -0.056318752467632294, 0.054241571575403214, 0.08437687158584595, 0.014259982854127884, 0.008681000210344791, 0.023881694301962852, 0.013052486814558506, -0.01165121141821146, -0.10317013412714005, -0.025873936712741852, -0.07728128135204315, 0.04999078810214996, 0.057736270129680634, 0.06816829741001129, -0.11120464652776718, 0.10394694656133652, -0.025775402784347534, 0.04131754860281944, -0.0140165314078331, 0.016076933592557907, -0.0009772455086931586, 0.035829368978738785, -0.05451960861682892, -0.11522045731544495, -0.02413547970354557, 0.06737188249826431, 0.016852926462888718, -0.038616981357336044, -0.021678606048226357, -0.02990025468170643, 0.05431568622589111, 0.027310417965054512, 0.010016901418566704, -0.13624358177185059, 0.06885787844657898, -0.1089296042919159, -0.1283181607723236, -0.0373230054974556, 0.01244816929101944, -0.005976976361125708, 0.0549926683306694, -0.03861117362976074, -0.07301965355873108, 0.030319787561893463, -0.055443376302719116, -0.16535332798957825, -0.01497392076998949, 0.015667948871850967, -0.08824630826711655, 0.06923984736204147, -0.01051812432706356, 0.011949574574828148, -0.0309958066791296, 0.15761056542396545, 0.021023541688919067, 0.052057571709156036, 0.009870738722383976, 0.05426447466015816, -0.07105446606874466, -0.008162041194736958, 0.04266027733683586, 0.05236533656716347, 0.15452110767364502, -0.010937385261058807, -0.07008304446935654, 0.026658758521080017, 0.026419484987854958, 0.06955815106630325, -0.03805325925350189, -0.016198672354221344, 0.0414390005171299, 0.049349840730428696, 0.0010191798210144043, 0.06590606272220612, 0.009478529915213585, 0.043368443846702576, -0.08700107783079147, -0.002613449702039361, 0.04056709259748459, 0.02566874958574772, -0.03825598210096359, -0.10620914399623871, -0.05436190590262413, -0.030971050262451172, 0.05768227204680443, -0.014199694618582726, 0.005867937114089727, 0.03477535769343376, 0.008478845469653606, -0.07861461490392685, 0.02689487114548683, 0.11036602407693863, -0.08802405744791031, -0.03418447822332382, 0.027606569230556488, 0.053050730377435684, -0.039728470146656036, -0.023490598425269127, -0.03570091724395752, 18.576993942260742, -0.048000019043684006, 0.046926263719797134, 0.006908027455210686, 0.09569171071052551, 0.011724910698831081, 0.007552358787506819, -0.01956249214708805, -0.08653874695301056, 0.014636289328336716, 0.09866639971733093, 0.09304570406675339, -0.12597209215164185, -0.01037309318780899, 0.02489655464887619, 0.01629222370684147, 0.09570398181676865, 0.03501059114933014, -0.01370587944984436, 0.09007340669631958, 0.007850260473787785, 0.08684130758047104, -0.0297644454985857, 0.1062239333987236, -0.09542987495660782, 0.06093659996986389, 0.03976920619606972]\n"
     ]
    }
   ],
   "source": [
    "# from .logic import DenseEncoder\n",
    "\n",
    "dense_enc = DenseEncoder()\n",
    "\n",
    "dense_vec = dense_enc.xlm_roberta_base_encoder(\"Was is Elektrotechnik\")\n",
    "\n",
    "print(dense_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dense_enc.document_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 768)\n",
      "hnsw_add_vertices: adding 326 elements on top of 0 (preset_levels=0)\n",
      "  max_level = 0\n",
      "Adding 326 elements at level 0\n",
      "Done in 21.725 ms\n",
      "326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd2 = \"\"\"\n",
    "    python -m pyserini.index.faiss \\\n",
    "        --input /home/peng_luh/__github/search_l3s/search_l3s_search_srv/encodes/dense_encoder \\\n",
    "        --output /home/peng_luh/__github/search_l3s/search_l3s_search_srv/indexes/dense/hnsw \\\n",
    "        --hnsw\n",
    "\"\"\"\n",
    "\n",
    "subprocess.call(cmd2, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder size: 9592 bytes (9.37 KB, 0.01 MB, 0.00 GB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "folder_path = \"/home/peng_luh/__github/search_l3s/search_l3s_search_srv/indexes/bm25/mls-tasks-1\"\n",
    "\n",
    "# Get the size of the folder in bytes\n",
    "folder_size = get_folder_size(folder_path)\n",
    "\n",
    "# Convert to appropriate units (KB, MB, GB, etc.)\n",
    "folder_size_kb = folder_size / 1024\n",
    "folder_size_mb = folder_size_kb / 1024\n",
    "folder_size_gb = folder_size_mb / 1024\n",
    "\n",
    "# Print the folder size\n",
    "print(f\"Folder size: {folder_size} bytes ({folder_size_kb:.2f} KB, {folder_size_mb:.2f} MB, {folder_size_gb:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"/home/peng_luh/__github/search_l3s/search_l3s_search_srv/encodes/dense/xlm_roberta_base/mls-tasks-0/data_encoded.jsonl\"):\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '/mls-api/tasks/418', 'contents': 'Kick-off Grundlagen der Sensorik - Schwingungssensor; Cover; Sicherheitshinweise; Einführung; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/417', 'contents': 'Grundlagen der Sensorik: Schwingungssensor - Betrieblicher Auftrag; Erläuterung; Aufgabenstellung; Vereinfachungen/Simulationen; Aufbau und Messanordnung; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/416', 'contents': 'Grundlagen der Sensorik: Schwingungssensor - Arbeitsplanung; Arbeitsvorbereitung; Eingesetzter Sensor; Datenblatt; Tastenprogrammierung und Grenzwerte festlegen\\n'}, {'id': '/mls-api/tasks/415', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.2: Operationsverstärker als Impedanzwandler und summierender Verstärker; Impedanzwandler; Impedanzwandler (Spannungsfolger); Summierender Verstärker; Summierer in der praktischen Übung; Summierer mit Gleich- und Wechselspannung\\n'}, {'id': '/mls-api/tasks/414', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.1: Operationsverstärker als Verstärker; Operationsverstärker; Operationsverstärker als invertierender Verstärker; Invertierender Verstärker in der praktischen Übung; Dreieckspannung am Eingang; Operationsverstärker als nicht invertierender Verstärker; Nicht invertierender Verstärker in der praktischen Übung; Wechselspannung am Eingang\\n'}, {'id': '/mls-api/tasks/413', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.7: Mitkopplung; Mitkopplung; Zweistufiger Verstärker mit Mitkopplung\\n'}, {'id': '/mls-api/tasks/412', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.6: Rückkopplung; Rückkopplung; Wechselstromgegenkopplung; Spannungsgegenkopplung; Zwei Verstärkerstufen\\n'}, {'id': '/mls-api/tasks/411', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.5: Gleichspannungsverstärker und Gegentaktverstärker; Gleichspannungsversträrker; Zweistufiger Gleichspannungsverstärker; Gegentaktverstärker; Gegentaktendstufe\\n'}, {'id': '/mls-api/tasks/410', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.4: Differenzverstärker; Differenzverstärker; Differenzverstärker für Gleichspannungen; Differenzverstärker für Wechselspannungen\\n'}, {'id': '/mls-api/tasks/409', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.3: Emittergekoppelte Verstärker und Phasenumkehrstufen; Emittergekoppelte Verstärker; Zwischenbasisschaltung; Emittergekoppelte Phasenumkehrstufe\\n'}, {'id': '/mls-api/tasks/408', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.2: Darlington-Verstärker; Darlington-Verstärker; Emitterschaltung; Kollektorschaltung\\n'}, {'id': '/mls-api/tasks/407', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.1: Mehrstufige Verstärker; Mehrstufige Verstärker; Zweistufiger Wechselspannungsverstärker\\n'}, {'id': '/mls-api/tasks/406', 'contents': 'Kick-off Schaltungen der Elektronik; Cover; Sicherheitshinweise; Einführung und Ablauf\\n'}, {'id': '/mls-api/tasks/405', 'contents': 'Grundlagen S7-1500 Versuch 1 - Transfersystem mit 2 Positionen; Aufbau; Ablaufbeschreibung; Variablentabelle; Ablaufgraph; SPS-Programm; Bausteinschnittstellen fcEndposition; Programm fcEndposition; Bausteinschnittstelle fbTransfersystem; Ablaufgraph fbTransfersystem; Programm fbTransfersystem\\n'}, {'id': '/mls-api/tasks/404', 'contents': 'Kick-off Grundlagen S7-1500; Cover; Sicherheitshinweise; Allgemeines; S7-1500 Familie\\n'}, {'id': '/mls-api/tasks/403', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 5.3: Zweirichtungsthyristor (Triac); Aufbau und Wirkungsweise; Untersuchung eines Triacs; Anschnittsteuerung mit Triac\\n'}, {'id': '/mls-api/tasks/402', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 5.2: Die Thyristortriode; Aufbau und Wirkungsweise; Untersuchung einer Thyristortriode; Verfahren zur Löschung einer Thyristortriode; Anschnittsteuerung mit Thyristortriode\\n'}, {'id': '/mls-api/tasks/401', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 5.1: Thyristoren (Diac); Aufbau und Wirkungsweise; Schaltvorgang eines Diacs; Diac als Sägezahngenerator und Impulsgenerator\\n'}, {'id': '/mls-api/tasks/400', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 4: Unijunktion-Transistor (UJT); Aufbau und Wirkungsweise; Schaltpunkte des Unijunktion-Transistors; Nichtlinearer Sägezahn; Linearer Sägezahn\\n'}, {'id': '/mls-api/tasks/399', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 3.2: Verstärkerstufen mit unipolaren Transistoren; Verstärkerstufen mit unipolaren Transistoren; Verstärkerstufe mit Sperrschicht-FET; Verstärkerstufe mit Isolierschicht-FET; Verstärkergrundschaltungen mit FET; Source-Schaltung; Gate-Schaltung; Drain-Schaltung; Zusammenfassung\\n'}, {'id': '/mls-api/tasks/398', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 3.1: Grundlagen zu unipolaren Transistoren; Aufbau, Wirkungsweise und Schaltzeichen; Sperrschicht FET; Kennlinien von Sperrschicht-FET; Isolierschicht-FET\\n'}, {'id': '/mls-api/tasks/397', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.3: Verstärkerstufen mit bipolaren Transistoren; Verstärkerstufen mit bipolaren Transistoren; Untersuchung einer Verstärkerstufe; Verstärkergrundschaltungen; Emitterschaltung; Basisschaltung; Kollektorschaltung; Zusammenfassung\\n'}, {'id': '/mls-api/tasks/396', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.2: Kennlinien bipolarer Transistoren; Kennlinien bipolarer Transistoren; Steuerkennlinie; Eingangs- und Ausgangskennlinien; Rückwirkungskennlinie\\n'}, {'id': '/mls-api/tasks/395', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 2.1: Grundlagen zu bipolaren Transistoren; Aufbau und Funktionsweise; Der Transistor als Diode; Wirkungen des Basisstroms auf den Kollektorstrom\\n'}, {'id': '/mls-api/tasks/394', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.4: Dioden mit besonderen Eigenschaften; Dioden mit besonderen Eigenschaften; Leuchtdioden\\n'}, {'id': '/mls-api/tasks/393', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.3: Zener-Dioden; Kennlinie der Zener-Diode; Gleichspannungsbegrenzung; Schaltung mehrerer Z-Dioden; Überspannungsschutz und Wechselspannungsbegrenzung; Spannungsstabilisierung\\n'}, {'id': '/mls-api/tasks/392', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.2: Gleichrichterschaltungen; Gleichrichterschaltungen; Einpuls-Mittelpunkt-Schaltung (M1); Zweipuls-Brückenschaltung (B2)\\n'}, {'id': '/mls-api/tasks/391', 'contents': 'Halbleiterbauelemente der Elektronik Versuch 1.1: Dioden; Strom in Halbleiterwerkstoffen; PN-Übergang; PN-Übergang; Dioden aus verschiedenen Halbleitermaterialien\\n'}, {'id': '/mls-api/tasks/390', 'contents': 'Kick-off Halbleiterbauelemente der Elektronik; Cover; Sicherheitshinweise; Einführung und Ablauf; Sichereres Experimentieren mit Strom und Spannung\\n'}, {'id': '/mls-api/tasks/389', 'contents': 'Regelungstechnik - Projekt 1: Einführung in die Regelungstechnik; Temperatursteuerung; Temperaturregelung; Regelkreise analysieren; Regelstreckenarten und Auswahl des Reglers; Die Einheitssprungfunktion\\n'}, {'id': '/mls-api/tasks/388', 'contents': 'Kick-off Regelungstechnik - Projekte; Cover; Sicherheitshinweise; Einführung und Ablauf; Versuchsaufbau; Messtechnik für die Projekte\\n'}, {'id': '/mls-api/tasks/387', 'contents': 'Wechselstromtechnik Versuch 10: Elektromotor; Funktionsprinzip; Gleichstrom-Kommutatormotor; Untersuchung Gleichstrommotor; Grundlagen zum Drehstrommotor; Der Synchronmotor; Untersuchung Synchronmotor\\n'}, {'id': '/mls-api/tasks/386', 'contents': 'Wechselstromtechnik Versuch 9: Transformatoren; Aufgaben und Funktionsweise; Realer vs. idealer Transformator; Spannungs-, Strom-, Widerstandstransformation (Übersetzungsverhältnis); Nachweis der Transformatorwirkung\\n'}, {'id': '/mls-api/tasks/385', 'contents': 'Wechselstromtechnik Versuch 8: RLC-Siebschaltungen (Filter); Filter und Übertragungsverhalten; Hochpass mit RC-Glied; Tiefpass mit RL-Glied\\n'}, {'id': '/mls-api/tasks/384', 'contents': 'Wechselstromtechnik Versuch 7: Schwingkreise; Entstehung und Resonanz; Reihen- und Parallelschwingkreis; Reihenschwingkreis; Parallelschwingkreis\\n'}, {'id': '/mls-api/tasks/383', 'contents': 'Wechselstromtechnik Versuch 6: Zusammenschaltung von Blind- und Wirkwiderständen; Arbeiten mit dem Zeigerdiagramm; RL-Reihenschaltung; RC-Reihenschaltung; RLC-Reihenschaltung\\n'}, {'id': '/mls-api/tasks/382', 'contents': 'Wechselstromtechnik Versuch 5.3: Schaltung mehrerer Spulen; Reihenschaltung von Spulen; Parallelschaltung von Spulen\\n'}, {'id': '/mls-api/tasks/381', 'contents': 'Wechselstromtechnik Versuch 5.2: Induktivität an sinusförmiger Wechselspannung; Phasenverschiebung; Induktiver Blindwiderstand; Wirk- und Blindleistung an der Spule\\n'}, {'id': '/mls-api/tasks/380', 'contents': 'Wechselstromtechnik Versuch 5.1: Elektromagnetismus und Spulen; Elektromagnetismus und Spulen; Versuch Spule und Elektromagnetismus; Kenngrößen von Spulen; Ein- und Ausschaltvorgang; Reaktion der Spule auf Rechteckspannungen\\n'}, {'id': '/mls-api/tasks/379', 'contents': 'Wechselstromtechnik Versuch 4.3: Schaltung mehrerer Kondensatoren; Reihenschaltung von Kondensatoren; Parallelschaltung von Kondensatoren\\n'}, {'id': '/mls-api/tasks/378', 'contents': 'Wechselstromtechnik Versuch 4.2: Der Kondensator an sinusförmiger Wechselspannung; Phasenverschiebung; Der kapazitive Blindwiderstand XC; Wirk- und Blindleistung am Kondensator\\n'}, {'id': '/mls-api/tasks/377', 'contents': 'Wechselstromtechnik Versuch 4.1: Der Kondensator; Aufbau und Kenngrößen; Arten und Aufgaben; Lade- und Entladevorgänge; Auf- und Entladung; Reaktion des Kondensators auf Rechteckspannungen\\n'}, {'id': '/mls-api/tasks/376', 'contents': 'Wechselstromtechnik Versuch 3.2: Fehler an Drehstromschaltungen; Messungen an einer defekten Sternschaltung; Messungen an einer defekten Dreieckschaltung\\n'}, {'id': '/mls-api/tasks/375', 'contents': 'Wechselstromtechnik Versuch 3.1: Dreiphasenwechselstrom (Drehstrom); Entstehung und Wirkungsweise; Messungen an Drehstromsystemen; Sternschaltung; Messungen an der Sternschaltung; Dreieckschaltung; Messungen an der Dreieckschaltung\\n'}, {'id': '/mls-api/tasks/374', 'contents': 'Wechselstromtechnik Versuch 2: Wirkleistung von Wechselspannungen; Herleitung der Wechselstromleistung; Wirkleistung der Sinuswechselspannung\\n'}, {'id': '/mls-api/tasks/373', 'contents': 'Wechselstromtechnik Versuch 1: Stromarten und ihre Kenngrößen; Stromarten; Kenngrößen von Sinusspannungen; Kenngrößen der Sinusspannung; Kenngrößen von Rechteckwechselspannungen; Kenngrößen von Dreieckwechselspannungen\\n'}, {'id': '/mls-api/tasks/372', 'contents': 'Kick-off Wechselstromtechnik; Cover; Sicherheitshinweise; Einführung und Ablauf; Sichereres Experimentieren mit Strom und Spannung\\n'}, {'id': '/mls-api/tasks/371', 'contents': 'Gleichstromtechnik Versuch 9: Leistungs-, Spannungs- und Stromanpassung; Herleitung und Bedeutung der Belastungsfälle; Praktische Übung zu den Belastungsfällen\\n'}, {'id': '/mls-api/tasks/370', 'contents': 'Gleichstromtechnik Versuch 8: Wirkungsgrad der elektrischen Leistung; Definition und Bedeutung des Wirkungsgrades; Praktische Übung zum Wirkungsgrad\\n'}, {'id': '/mls-api/tasks/369', 'contents': 'Gleichstromtechnik Versuch 7: Elektrische Leistung und Arbeit; Arbeit und Leistung im Stromkreis; Arbeit und Leistung im Stromkreis; Leistungshyperbel\\n'}, {'id': '/mls-api/tasks/368', 'contents': 'Gleichstromtechnik Versuch 6: Zusammenschaltung von Spannungsquellen; Darstellung von Spannungsquellen; Reihenschaltung von Spannungsquellen; Parallelschaltung von Spannungsquellen\\n'}, {'id': '/mls-api/tasks/367', 'contents': 'Gleichstromtechnik Versuch 5: Ersatzspannungsquelle; Ersatzspannungsquelle; Ersatzspannungsquellen\\n'}, {'id': '/mls-api/tasks/366', 'contents': 'Gleichstromtechnik Versuch 4: Spannungs- und Stromfehlerschaltung; Spannungs- und Stromfehlerschaltung; Anwendung von Spannungs- und Stromfehlerschaltung\\n'}, {'id': '/mls-api/tasks/365', 'contents': 'Gleichstromtechnik Versuch 3.6: Der Spannungsteiler; Der unbelastete Spannungsteiler; Unbelastete Spannungsteiler; Der belastete Spannungsteiler; Belastete Spannungsteiler\\n'}, {'id': '/mls-api/tasks/364', 'contents': 'Gleichstromtechnik Versuch 3.5: Kombinationen von Reihen- und Parallelschaltung; Kombinationen von Reihen und Parallelschaltung; Widerstandsnetzwek 1; Widerstandsnetzwerk 2\\n'}, {'id': '/mls-api/tasks/363', 'contents': 'Gleichstromtechnik Versuch 3.4: Parallelschaltung von Widerständen; Parallelschaltung von Widerständen; Untersuchung einer Parallelschaltung\\n'}, {'id': '/mls-api/tasks/362', 'contents': 'Gleichstromtechnik Versuch 3.3: Reihenschaltung von Widerständen; Reihenschaltung von Widerständen; Untersuchung einer Reihenschaltung\\n'}, {'id': '/mls-api/tasks/361', 'contents': 'Gleichstromtechnik Versuch 3.2: Elektrische Widerstände Teil 2; Der PTC-Widerstand (Kaltleiter); Spannungsabhängige Widerstände (VDR); Fotowiderstände (LDR)\\n'}, {'id': '/mls-api/tasks/360', 'contents': 'Gleichstromtechnik Versuch 3.1: Elektrische Widerstände Teil 1; Arten und Eigenschaften elektrischer Widerstände; Lineare Widerstände; Der NTC-Widerstand (Heißleiter)\\n'}, {'id': '/mls-api/tasks/359', 'contents': \"Gleichstromtechnik Versuch 2: Das Ohm'sche Gesetz; Das Ohm'sche Gesetz; Abhängigkeit des Stroms von der Spannung; Abhängigkeit des Stroms vom Widerstand\\n\"}, {'id': '/mls-api/tasks/358', 'contents': 'Gleichstromtechnik Versuch 1: Der elektrische Stromkreis; Bestandteile und Funktion; Elektrische Grundgrößen; Der Stromkreis im praktischen Versuch; Messungen im Grundstromkreis\\n'}, {'id': '/mls-api/tasks/357', 'contents': 'Kick-off Gleichstromtechnik; Cover; Sicherheitshinweise; Einführung und Ablauf; Sichereres Experimentieren mit Strom und Spannung\\n'}, {'id': '/mls-api/tasks/356', 'contents': 'Ihr Feedback an uns; Willkommen; Feedbackbogen\\n'}, {'id': '/mls-api/tasks/355', 'contents': 'Halbleitertechnik Versuch 4: Operationsverstärker; Aufbau und Wirkungsweise ; Invertierender Verstärker; Nichtinvertierender Verstärker\\n'}, {'id': '/mls-api/tasks/354', 'contents': 'Halbleitertechnik Versuch 3: Die Thyristortriode; Aufbau und Wirkungsweise; Zünd- und Löschvorgang; Verfahren zum Löschen\\n'}, {'id': '/mls-api/tasks/353', 'contents': 'Halbleitertechnik Versuch 2.2.: Verstärkerstufen; Verstärkerstufen; Arbeitspunkt einer Verstärkerstufe; Arbeitspunkt einer Verstärkerstufe\\n'}, {'id': '/mls-api/tasks/352', 'contents': 'Halbleitertechnik Versuch 2.1: Bipolare Transistoren; Aufbau und Funktionsweise; Diodenwirkung NPN-Transistor (1); Diodenwirkung NPN-Transistor (2); Wirkung von I_B auf I_C\\n'}, {'id': '/mls-api/tasks/351', 'contents': 'Halbleitertechnik Versuch 1.4: Leuchtdioden; Leuchtdioden; Lichtausbeute\\n'}, {'id': '/mls-api/tasks/350', 'contents': 'Halbleitertechnik Versuch 1.3: Die Zener-Diode; Kennlinie der Zener-Diode; Kennlinie im Sperrbetrieb; Gleichspannungsbegrenzungen mit der Z-Diode\\n'}, {'id': '/mls-api/tasks/349', 'contents': 'Halbleitertechnik Versuch 1.2: Gleichrichterschaltungen; Gleichrichterschaltung; Einpuls-Mittelpunkt-Schaltung (M1); Einpuls-Mittelpunkt-Schaltung M1 ohne und mit Glättungskondensator\\n'}, {'id': '/mls-api/tasks/348', 'contents': 'Halbleitertechnik Versuch 1.1: PN-Übergang als Diode; Wirkungsweise eines PN-Übergangs; PN-Übergang als Diode; PN-Übergang als Diode\\n'}, {'id': '/mls-api/tasks/347', 'contents': 'Montage- und Demontageautomat Versuch 5: Vollfunktion Montieren/Demontieren; Beschreibung; Erweiterungen des Aufbaus; Ablaufbeschreibung; Ablaufgraph; Programmerstellung in FUP\\n'}, {'id': '/mls-api/tasks/346', 'contents': 'Montage- und Demontageautomat Versuch 4: Einfahrt beidseitige Montage; Beschreibung; Erweiterungen des Aufbaus; Ablaufbeschreibung; Ablaufgraph; Programmerstellung in FUP\\n'}, {'id': '/mls-api/tasks/345', 'contents': 'Montage- und Demontageautomat Versuch 3: Demontagefunktion; Beschreibung; Einrichten; Aufbau; Ablaufbeschreibung; Ablaufgraph; Festlegung der Steuerung; Programmerstellung in FUP\\n'}, {'id': '/mls-api/tasks/344', 'contents': 'Montage- und Demontageautomat Versuch 2: Montagefunktion; Beschreibung; Einrichten; Aufbau; Ablaufbeschreibung; Ablaufgraph; Festlegung der Steuerung; Programmerstellung in FUP\\n'}, {'id': '/mls-api/tasks/343', 'contents': 'Kick-off Montage- und Demontageautomat; Cover; Sicherheitshinweise; Einführung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/342', 'contents': 'LOGO! 8 PLC Board Versuch 4.2: Aufgabe Geschwindigkeitssteuerung; Versuchsablauf; Geschwindigkeitssteuerung; Stromlaufplan und Programm; Versuchsaufbau\\n'}, {'id': '/mls-api/tasks/341', 'contents': 'LOGO! 8 PLC Board Versuch 4.1: Aufgabe Bandsteuerung; Versuchsablauf; Aufgabe Bandsteuerung Tippbetrieb; Stromlaufplan und Programm; Versuchsaufbau; Aufgabe Erweiterung Tippbetrieb; Stromlaufplan und Programm; Versuchsaufbau\\n'}, {'id': '/mls-api/tasks/340', 'contents': 'LOGO! 8 PLC Board Versuch 3: Aufgabe Biegemaschine; Versuchsablauf; Aufgabe Biegemaschine; Stromlaufplan und Programm; Versuchsaufbau\\n'}, {'id': '/mls-api/tasks/339', 'contents': 'LOGO! 8 PLC Board Versuch 2: Aufgabe Kugellagerpresse; Versuchsablauf; Betriebsmittelkennzeichnung; Aufgabe Kugellagerpresse; Stromlaufplan und Programm; Versuchsaufbau; Aufgabe Kugellagerpresse Erweiterung; Stromlaufplan und Programm; Versuchsaufbau; Ermittlung der Endlage des Zylinders; Stromlaufplan und Programm\\n'}, {'id': '/mls-api/tasks/338', 'contents': 'LOGO! 8 PLC Board Versuch 1: Erste Programme; Versuchsablauf; Menüsprache einstellen; UND-Schaltung; Programmierung der UND-Verknüpfung am Display; ODER-Schaltung; Netzwerkeinstellungen; Schaltprogramm laden; Schaltprogramm anpassen und simulieren; Schaltprogramm in die LOGO! laden und testen\\n'}, {'id': '/mls-api/tasks/337', 'contents': 'Grundlagen der Steuerungstechnik: Arbeitsvorbereitung; Steuern vs. Regeln; EVA-Prinzip; Steuerungsarten; Einsatzgebiete VPS und SPS; Arbeitsweise einer SPS; Not-Halt- und Not-Aus- Funktionen; Öffner und Schließer; Logische Operationen; Übersicht Logikgatter\\n'}, {'id': '/mls-api/tasks/336', 'contents': 'Kick-off LOGO! 8 PLC (Professional) Board 24V; Cover; Sicherheitshinweise; Einführung; Ablauf\\n'}, {'id': '/mls-api/tasks/335', 'contents': 'Regelungstechnik Versuch 4: Füllstandregelung mit stetigem Regler; Füllstandregelung; Funktionsweise der Füllstandstrecke; Regelkreis mit P-Regler; Reglereinstellugen für den PI-Regler; Füllstandregelung mit PI-Regler\\n'}, {'id': '/mls-api/tasks/334', 'contents': 'Regelungstechnik Versuch 3: Regelkreis mit unstetigem Regler; Zweipunktregler; Dreipunktregler; Hysterese des Zweipunktreglers; Temperaturregelung mit Zweipunktregler\\n'}, {'id': '/mls-api/tasks/333', 'contents': 'Regelungstechnik Versuch 2: Regelkreis mit stetigem Regler; Einteilung von Regelungen; Regelkreis analysieren; Regelstreckenarten und Auswahl des Reglers; Der P-Regler; Einstellregeln nach Ziegler / Nichols; Der PI-Regler; Der PID-Regler\\n'}, {'id': '/mls-api/tasks/332', 'contents': 'Regelungstechnik Versuch 1: Beispiel einer Drehzahlstrecke; Einführung in die Regelungstechnik; Begriffserläuterungen: Steuerstrecke; Drehzahlsteuerung; Begriffserläuterungen: Regelstrecke; Drehzahlregelung\\n'}, {'id': '/mls-api/tasks/331', 'contents': 'Kick-off Regelungstechnik - Grundlagen; Cover; Sicherheitshinweise; Einführung und Ablauf; Versuchsaufbau\\n'}, {'id': '/mls-api/tasks/330', 'contents': 'Elektrotechnik 1 Versuch 13: Elektromotor; Funktionsprinzip; Gleichstrom-Kommutatormotor; Untersuchung Gleichstrommotor; Grundlagen zum Drehstrommotor; Der Synchronmotor; Untersuchung Synchronmotor\\n'}, {'id': '/mls-api/tasks/329', 'contents': 'Elektrotechnik 1 Versuch 12: Transformatoren; Aufgaben und Funktionsweise; Realer vs. idealer Transformator; Spannungs-, Strom-, Widerstandstransformation (Übersetzungsverhältnis); Nachweis der Transformatorwirkung\\n'}, {'id': '/mls-api/tasks/328', 'contents': 'Elektrotechnik 1 Versuch 11: Elektromagnetismus und Spulen; Elektromagnetismus und Spulen; Kenngrößen von Spulen; Grundsätzliches zum Ein- und Ausschaltvorgang an der Spule; Versuch Spule und Elektromagnetismus; Phasenverschiebung; Induktiver Blindwiderstand\\n'}, {'id': '/mls-api/tasks/327', 'contents': 'Elektrotechnik 1 Versuch 10: Der Kondensator; Aufbau und Kenngrößen; Arten und Aufgaben; Lade- und Entladevorgänge; Auf- und Entladung; Phasenverschiebung\\n'}, {'id': '/mls-api/tasks/326', 'contents': 'Elektrotechnik 1 Versuch 9: Dreiphasenwechselstrom (Drehstrom); Entstehung und Wirkungsweise; Sternschaltung; Dreieckschaltung; Messungen an Drehstromsystemen; Messungen an der Sternschaltung; Messungen an der Dreieckschaltung\\n'}, {'id': '/mls-api/tasks/325', 'contents': 'Elektrotechnik 1 Versuch 8: Wirkleistung von Wechselspannungen; Herleitung der Wechselstromleistung; Wirkleistung der Sinuswechselspannung\\n'}, {'id': '/mls-api/tasks/324', 'contents': 'Elektrotechnik 1 Versuch 7: Stromarten und ihre Kenngrößen; Stromarten; Herleitung der Kenngrößen; Kenngrößen der Sinusspannung\\n'}, {'id': '/mls-api/tasks/323', 'contents': 'Elektrotechnik 1 Versuch 6: Wirkungsgrad; Definition und Bedeutung des Wirkungsgrades; Versuch\\n'}, {'id': '/mls-api/tasks/322', 'contents': 'Elektrotechnik 1 Versuch 5: Elektrische Leistung und Arbeit; Arbeit und Leistung im Stromkreis; Versuch\\n'}, {'id': '/mls-api/tasks/321', 'contents': 'Elektrotechnik 1 Versuch 4: Zusammenschaltung von Spannungsquellen; Symbolische Darstellung; Reihenschaltung; Versuch\\n'}, {'id': '/mls-api/tasks/320', 'contents': 'Elektrotechnik 1 Versuch 3.2: Verschaltung elektrischer Widerstände; Die Reihenschaltung von Widerständen; Nachweis der Eigenschaften einer Reihenschaltung von Widerständen; Die Parallelschaltung von Widerständen; Nachweis der Eigenschaften parallel geschalteter Widerstände; Unbelasteter Spannungsteiler; Belasteter Spannungsteiler; Festes Widerstandsverhältnis\\n'}, {'id': '/mls-api/tasks/319', 'contents': 'Elektrotechnik 1 Versuch 3.1: Eigenschaften elektrischer Widerstände; Arten und Eigenschaften elektrischer Widerstände; Lineare Kennlinie I=f(U); NTC-Kennlinien I = f (U) und R = f (U); Abhängigkeit des LDR von der Beleuchtungsstärke\\n'}, {'id': '/mls-api/tasks/318', 'contents': \"Elektrotechnik 1 Versuch 2: Ohm'sches Gesetz; Aussage und Bedeutung des Ohm’schen Gesetzes; Das ohmsche Gesetz im Praxisversuch; Untersuchung der Abhängigkeit des Stroms von der Spannung; Messung der Stromstärke über dem Widerstand\\n\"}, {'id': '/mls-api/tasks/317', 'contents': 'Elektrotechnik 1 Versuch 1: Der elektrische Stromkreis; Bestandteile und Funktion eines elektrischen Stromkreises; Beschreibung der elektrischen Grundgrößen; Der Stromkreis im praktischen Versuch; Messung von Spannung und Stromstärke\\n'}, {'id': '/mls-api/tasks/316', 'contents': 'Kick-off Grundlagen der Elektrotechnik Teil 1; Cover; Sicherheitshinweise; Einführung und Ablauf; Sicheres Experimentieren mit Strom und Spannung\\n'}, {'id': '/mls-api/tasks/315', 'contents': 'Grundlagen der Elektropneumatik: Aufgaben 6-10; Aufgabe 6: Spannvorrichtung (zeitabhängige Ablaufsteuerung); Aufgabe 7: Pneumatischer Vorschub (zeitabhängige Ablaufsteuerung); Aufgabe 8: Tauchbecken (Sicherheitsschaltung); Versuch 9: Positionierung / Erfassung; Aufgabe 10: Druckautomat\\n'}, {'id': '/mls-api/tasks/314', 'contents': 'Grundlagen der Elektropneumatik: Aufgaben 1-5; Versuchsaufbau; Aufgabe 1: Sicherheitstür; Aufgabe 2: Palettenlift; Aufgabe 3: Demontage; Aufgabe 4: Montage; Aufgabe 5: Werkstücklift (Parallelschaltung)\\n'}, {'id': '/mls-api/tasks/313', 'contents': 'Kick-off Grundlagen Elektropneumatik; Cover; Sicherheitshinweise; Projektvorstellung; Was ist Pneumatik?; Herstellen von Druckluft\\n'}, {'id': '/mls-api/tasks/312', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 3: Beschreiben und Lesen des Transponders; Codierung (1); Codierung (2); Beschreiben des Transponders in der Anlage; Lesen des Transponders\\n'}, {'id': '/mls-api/tasks/311', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 2: Materialeinflüsse; Luftschnittstellenmaterial; Applikationsmaterial\\n'}, {'id': '/mls-api/tasks/310', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 1: Lesebereich; Verwendete Materialien; Versuchsaufbau; Verbindung mit dem Reader (1); Verbindung mit dem Reader (2); Lesebereich ermitteln - 0°-Orientierung; Lesebereich ermitteln - 90°-Orientierung\\n'}, {'id': '/mls-api/tasks/309', 'contents': 'Grundlagen der Sensorik: RFID - Arbeitsvorbereitung Betrieblicher Auftrag; Vorüberlegungen (1); Vorüberlegungen (2); Vereinfachung in der Modellanlage\\n'}, {'id': '/mls-api/tasks/308', 'contents': 'Kick-off Grundlagen der Sensorik - RFID Identifikationsverfahren; Cover; Sicherheitshinweise; Einführung; Projektbeschreibung\\n'}, {'id': '/mls-api/tasks/307', 'contents': 'Grundlagen der Pneumatik: Aufgaben 6-10; Aufgabe 6 - Doppelschiebetür (zeitabhängige Ablaufsteuerung); Aufgabe 7 - Hubtisch (Ablaufsteuerung); Aufgabe 8 - Prägemaschine (Kaskadensteuerung); Aufgabe 9 - Montageautomat (Kaskadensteuerung); Aufgabe 10 - Umformmaschine (Ablaufsteuerung)\\n'}, {'id': '/mls-api/tasks/306', 'contents': 'Grundlagen der Pneumatik: Aufgaben 1-5; Versuchsaufbau; Aufgabe 1 - Dachfenster (Direktansteuerung); Aufgabe 2 - Presse 01 (Direktansteuerung); Aufgabe 3 - Presse 02 (UND-Verknüpfung); Aufgabe 4 - Falllager (Ablaufsteuerung); Aufgabe 5 - Schiebetür (zeitabhängige Ablaufsteuerung)\\n'}, {'id': '/mls-api/tasks/305', 'contents': 'Grundlagen der Pneumatik: Arbeitsvorbereitung; Pneumatische Bauteile; Referenzkennzeichung; Steuerungstechnik; Komponenten von Steuerungen und Schaltplan; Ablaufsteuerung mit GRAFCET\\n'}, {'id': '/mls-api/tasks/304', 'contents': 'Kick-off Grundlagen der Pneumatik; Cover; Sicherheitshinweise; Projektvorstellung; Was ist Pneumatik?; Herstellen von Druckluft\\n'}, {'id': '/mls-api/tasks/303', 'contents': 'Grundlagen der Elektropneumatik mit tec2SKILL® connect: Aufgaben 6-9; Aufgabe 6: Spannvorrichtung (zeitabhängige Ablaufsteuerung); Aufgabe 7: Pneumatischer Vorschub (zeitabhängige Ablaufsteuerung); Aufgabe 8: Tauchbecken (Sicherheitsschaltung); Aufgabe 9: Druckautomat\\n'}, {'id': '/mls-api/tasks/302', 'contents': 'Grundlagen der Elektropneumatik mit tec2SKILL® connect: Aufgaben 1-5; Aufgabe 1: Sicherheitstür; Aufgabe 2: Palettenlift; Aufgabe 3: Demontage; Aufgabe 4: Montage; Aufgabe 5: Werkstücklift (Parallelschaltung)\\n'}, {'id': '/mls-api/tasks/301', 'contents': 'Grundlagen der Elektropneumatik: Arbeitsvorbereitung; Pneumatische Bauteile; Elektropneumatische Bauteile; Referenzkennzeichung; Steuerungstechnik; Komponenten von Steuerungen und Schaltplan; Ablaufsteuerung mit GRAFCET\\n'}, {'id': '/mls-api/tasks/300', 'contents': 'Kick-off Elektropneumatik mit tec2SKILL® connect; Cover; Sicherheitshinweise; Projektvorstellung; Was ist Pneumatik?; Herstellen von Druckluft\\n'}, {'id': '/mls-api/tasks/299', 'contents': '43213SIOL Versuch 4: Sensoranordnung für vorbeifahrende Kunststoffe; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Messaufbau und Funktionstest; Nachweis der Funktion; Nachweis des Reduktionsfaktors\\n'}, {'id': '/mls-api/tasks/298', 'contents': '43213SIOL Versuch 3: Füllstanderfassung eines Tanks planen und ausführen; Auftrag; Simulation der Aufgabenstellung; Arbeitsplanung; Informationsbeschaffung und Sensorauswahl; Messaufbau und Funktionstest; Sensor programmieren; Analogausgang programmieren; Schaltausgang programmieren; Sensor über IO-Link programmieren (1); Sensor über IO-Link programmieren (2)\\n'}, {'id': '/mls-api/tasks/297', 'contents': '43213SIOL Versuch 2:  Füllstandserfassung eines Palettenlagers; Auftrag; Simulation der Aufgabenstellung; Arbeitsplanung; Informationsbeschaffung und Sensorauswahl; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/296', 'contents': '43213SIOL Versuch 1: Sensoranordnung für vorbeifahrende Metalle; Auftrag; Simulation der Aufgabenstellung; Arbeitsplanung; Informationsbeschaffung und Sensorauswahl; Messaufbau und Funktionstest; Nachweis der Funktion; Nachweis des Schaltabstands ; Nachweis des Reduktionsfaktors; Nachweis der Hyterese\\n'}, {'id': '/mls-api/tasks/295', 'contents': 'Analoge Sensorik Versuch 3:  Prüfung des Behälterdeckels; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Messgerät einstellen; Nachweis der Funktion; Nachweis des Schaltabstandes; Nachweis des Reduktionsfaktors\\n'}, {'id': '/mls-api/tasks/294', 'contents': 'Analoge Sensorik Versuch 2:  Füllstandserfassung eines Lagers für Behälter; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Ermittlung der Schallkeule; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/293', 'contents': 'Analoge Sensorik Versuch 1:  Füllstandserfassung eines Palettenlagers; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Nachweis der Reflektivität; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/292', 'contents': 'Arbeitsplanung Analoge Sensorik; Verfügbare Sensoren; Schritte der Arbeitsplanung\\n'}, {'id': '/mls-api/tasks/291', 'contents': 'ETS WebTECH®4U ; Begrüßung; Digitale Lerninhalte; Highlights im Überblick\\n'}, {'id': '/mls-api/tasks/290', 'contents': 'Grundlagen der Sensorik: Drehgeber - Versuch 3: Hochregallager CPS i40; Einführung; Versuchsaufbau Längsachse; Versuchsdurchführung Längsachse; Versuchsaufbau Palettenaufnehmer; Versuchsdurchführung Palettenaufnehmer\\n'}, {'id': '/mls-api/tasks/289', 'contents': 'Grundlagen der Sensorik: Drehgeber - Versuch 2: Seilzug-Encoder am Gabelstapler; Einführung; Versuchsbeschreibung und verwendete Materialien; Versuchsdurchführung\\n'}, {'id': '/mls-api/tasks/288', 'contents': 'Grundlagen der Sensorik: Drehgeber - Versuch 1: Messradsystem an einer Furnierschälmaschine; Einführung; Versuchsbeschreibung und verwendete Materialien; Versuchsdurchführung\\n'}, {'id': '/mls-api/tasks/287', 'contents': 'Grundlagen der Sensorik: Drehgeber - Erstinbetriebnahme des Messradaufbaus; Verkabelung; Sensor auslesen (1); Sensor auslesen (2); Messradaufsatz positionieren\\n'}, {'id': '/mls-api/tasks/286', 'contents': 'Grundlagen der Sensorik: Drehgeber - Arbeitsvorbereitung; Grundlagen und Verständnisfragen; Datenblatt\\n'}, {'id': '/mls-api/tasks/285', 'contents': 'Kick-off Grundlagen der Sensorik - Drehgeber; Cover; Sicherheitshinweise; Einführung; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/284', 'contents': 'Grundlagen der Sensorik: Schwingungssensor - Betrieblicher Auftrag; Erläuterung; Aufgabenstellung; Vereinfachungen/Simulationen; Aufbau und Messanordnung; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/283', 'contents': 'Grundlagen der Sensorik: Schwingungssensor - Arbeitsplanung; Arbeitsvorbereitung; Eingesetzter Sensor; Datenblatt; Tastenprogrammierung und Grenzwerte festlegen\\n'}, {'id': '/mls-api/tasks/282', 'contents': 'Kick-off Grundlagen der Sensorik - Schwingungssensor; Cover; Sicherheitshinweise; Einführung; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/281', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 2: Materialeinflüsse und Beschreiben des Transponders; Luftschnittstellenmaterial; Applikationsmaterial; Beschreiben des Transponders in der Anlage\\n'}, {'id': '/mls-api/tasks/280', 'contents': 'Grundlagen der Sensorik: RFID - Versuch 1: Lesebereich; Verwendete Materialien; Versuchsaufbau; Verbindung mit dem Reader; Lesebereich ermitteln - 0°-Orientierung; Lesebereich ermitteln - 90°-Orientierung\\n'}, {'id': '/mls-api/tasks/279', 'contents': 'Grundlagen der Sensorik: RFID - Arbeitsvorbereitung Betrieblicher Auftrag; Vorüberlegungen (1); Vorüberlegungen (2); Vereinfachung in der Modellanlage; Codierung\\n'}, {'id': '/mls-api/tasks/278', 'contents': 'Kick-off Grundlagen der Sensorik - RFID Identifikationsverfahren; Cover; Sicherheitshinweise; Einführung; Projektbeschreibung\\n'}, {'id': '/mls-api/tasks/277', 'contents': 'Grundlagen der Sensorik: Pt100 - Versuch 2 Ermittlung der Widerstandskennlinie; Erläuterung; Widerstandsmessung; Widerstandskennlinie\\n'}, {'id': '/mls-api/tasks/276', 'contents': 'Grundlagen der Sensorik : Pt100 - Versuch 1 Temperaturmessung eines Kühlkreislaufes; Erläuterung; Simulation der Aufgabenstellung; Arbeitsplanung; Aufbau der Messanordnung; Messgerät einstellen; Nachweis der Funktion; Auswertung des Versuchs\\n'}, {'id': '/mls-api/tasks/275', 'contents': 'Grundlagen der Sensorik: Pt100 - Vorbereitung; Was ist Temperatur?; Temperatursensor Pt100; Temperatur-Stabsensor TT0281\\n'}, {'id': '/mls-api/tasks/274', 'contents': 'Kick-off Grundlagen der Sensorik - Platin Messwiderstand Pt100; Cover; Sicherheitshinweise; Einführung und Ablauf\\n'}, {'id': '/mls-api/tasks/273', 'contents': 'Grundlagen der Sensorik: Zylindersensoren - Versuch 2: Bohrtiefenmessung; Versuchsbeschreibung; Versuchsaufbau; Manuelle Parametrierung; Messung der Bohrtiefen; Parametrierung und Messung über IO-Link\\n'}, {'id': '/mls-api/tasks/272', 'contents': 'Grundlagen der Sensorik: Zylindersensoren - Versuch 1: Pneumatische Deckelmontage; Versuchsbeschreibung; Versuchsaufbau; Anschließen und Justieren des Sensors D-M9BL (SMC); Anschließen und Justieren des Sensors MZC1 (Sick)\\n'}, {'id': '/mls-api/tasks/271', 'contents': 'Grundlagen der Sensorik: Zylindersensoren - Arbeitsvorbereitung; Magnetische Zylindersensoren; Allgemeiner Aufbau; Montage; Verwendete Sensoren\\n'}, {'id': '/mls-api/tasks/270', 'contents': 'Kick-off: Grundlagen der Sensorik - Zylindersensoren; Cover; Sicherheitshinweise; Einführung und Ablauf\\n'}, {'id': '/mls-api/tasks/269', 'contents': 'Prüfung elektrischer Anlagen Versuch 3.3: Erstprüfung im IT-Netz; Arbeitsauftrag; Arbeitsplanung; Versuchsaufbau; Ergänzung des IT-Systems mit RCD-Schutzschaltern\\n'}, {'id': '/mls-api/tasks/268', 'contents': 'Prüfung elektrischer Anlagen Versuch 3.2: Erstprüfung im TT-Netz; Arbeitsauftrag; Versuchsaufbau; Prüfung der Erd- und Potentialausgleichsverbindung; Durchführung der Erstprüfung; Messung der Fehlerspannung bzw. des Erdungswiderstands\\n'}, {'id': '/mls-api/tasks/267', 'contents': 'Prüfung elektrischer Anlagen Versuch 3.1: Erstprüfung im TN-Netz; Arbeitsauftrag; Versuchsaufbau; Messen des Erdungswiderstands\\n'}, {'id': '/mls-api/tasks/266', 'contents': 'Elektroenergieversorgung und Sicherheit von Betriebsmitteln Versuch 2.4: Prüfungen und Messungen an RCD-Schutzeinrichtungen / Drehfeldrichtung; Prüfungen und Messungen an RCD-Schutzeinrichtungen; Versuchsdurchführung; Drehfeldrichtung\\n'}, {'id': '/mls-api/tasks/265', 'contents': 'Elektroenergieversorgung und Sicherheit von Betriebsmitteln Versuch 2.3: Isolationswiderstand und Schleifenwiderstand; Isolationswiderstand; Messung Isolationswiderstand; Schleifenwiderstand; Messung Schleifenwiderstand im TN-S-Netz; Messung Schleifenwiderstand im TT-Netz\\n'}, {'id': '/mls-api/tasks/264', 'contents': 'Elektroenergieversorgung und Sicherheit von Betriebsmitteln Versuch 2.2: Hauptpotenzialausgleich; Hauptpotenzialausgleich; Messung\\n'}, {'id': '/mls-api/tasks/263', 'contents': 'Elektroenergieversorgung und Sicherheit von Betriebsmitteln Versuch 2.1: Hausanschluss, Leitungen, Zählerplatz; Der Hausanschluss; Leitungen; Zählerplatz\\n'}, {'id': '/mls-api/tasks/262', 'contents': 'Netzsysteme und Schutzmaßnahmen Versuch 1.5: Das IT-System; Das IT-System; Aufgabe\\n'}, {'id': '/mls-api/tasks/261', 'contents': 'Netzsysteme und Schutzmaßnahmen Versuch 1.4: Erdungswiderstand; Erdungswiderstand; Messung des Erdungswiderstands; Messung des Erdungswiderstands nach der Dreileitermethode; Messung des Erdungswiderstands mittels Fehlerschleifenimpedanz; Selektive Erdungswiderstandsmessung\\n'}, {'id': '/mls-api/tasks/260', 'contents': 'Netzsysteme und Schutzmaßnahmen Versuch 1.3: Automatische Abschaltung durch RCD-Schutzschalter; RCD-Schutzschalter; Typen und Auslöseverhalten von Fehlerstromschutzschaltern; Prüfung von RCD-Schutzschaltern; Messung im TN-S-Netz; Messung im TT-Netz\\n'}, {'id': '/mls-api/tasks/259', 'contents': 'Netzsysteme und Schutzmaßnahmen Versuch 1.2: Schutz gegen elektrischen Schlag; Schutz gegen elektrischen Schlag; Fehlerarten; Geforderte Abschaltzeit; Ermitteln des benötigten Abschaltstroms; Messübung zum TN-S-Netz; Messübung zum TT-Netz\\n'}, {'id': '/mls-api/tasks/258', 'contents': 'Netzsysteme und Schutzmaßnahmen Versuch 1.1: Netzsysteme; Kennzeichnung von Netzsystemen; Prinzipschaltbild eines Netzsystems; Messübung TN-C-Netz; Messübung TN-S-Netz; Messübung TT-Netz; Messübung IT-Netz\\n'}, {'id': '/mls-api/tasks/257', 'contents': 'Kick-off Netzsysteme und Schutzmaßnahmen; Cover; Sicherheitshinweise; Inhaltsverzeichnis; Benötigte Hardware\\n'}, {'id': '/mls-api/tasks/256', 'contents': 'Elektromotoren 1 - Versuch 3: Gleichstrom-Doppelschlussmaschine; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/255', 'contents': 'Elektromotoren 1 - Versuch 2: Gleichstrom-Reihenschlussmaschine; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/254', 'contents': 'Elektromotoren 1 - Versuch 1: Gleichstrom-Nebenschlussmaschine; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Auswertung der Ergebnisse; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/253', 'contents': 'Kick-off  Elektromotoren Teil 1: Gleichstrommotoren; Cover; Sicherheitshinweise; Einführung und Ablauf\\n'}, {'id': '/mls-api/tasks/252', 'contents': 'Digitaltechnik Versuch 13: Digital-Analog-Umsetzer; Digital-Analog-Umsetzer; Untersuchung eines Digital-Analog-Umsetzers\\n'}, {'id': '/mls-api/tasks/251', 'contents': 'Digitaltechnik Versuch 12: Analog-Digital-Umsetzer; Analog-Digital-Umsetzer; Untersuchung eines Analog-Digital-Umsetzers\\n'}, {'id': '/mls-api/tasks/250', 'contents': 'Digitaltechnik Versuch 11: Multiplexer / Demultiplexer; Multiplexer / Demultiplexer; Multiplexer-Demultiplexer-Strecke\\n'}, {'id': '/mls-api/tasks/249', 'contents': 'Digitaltechnik Versuch 10: Schieberegister; Schieberegister; Untersuchung eines Schieberegisters\\n'}, {'id': '/mls-api/tasks/248', 'contents': 'Digitaltechnik Versuch 9: Zählerschaltungen; Asynchrone Zähler; Asynchroner Modulo-n-Zähler; Synchrone Zähler\\n'}, {'id': '/mls-api/tasks/247', 'contents': 'Digitaltechnik Versuch 8.2: Kippstufen Teil 2; Zweiflankengesteuerte Flifplops; Monostabile Kippstufen; Untersuchung eines Monoflops; Verzögerungsschaltungen; Astabile Kippschaltungen\\n'}, {'id': '/mls-api/tasks/246', 'contents': 'Digitaltechnik Versuch 8.1: Kippstufen Teil 1; Kippstufen; Bistabile Kippschaltungen; Untersuchung eines RS-Flipflops; Synchrone Flipflops; Untersuchung synchroner Flipflops\\n'}, {'id': '/mls-api/tasks/245', 'contents': 'Digitaltechnik Versuch 7.2: Rechenschaltungen Teil 2; Subtrahierer für Dualzahlen; Subtraktionschaltung; Komparatoren\\n'}, {'id': '/mls-api/tasks/244', 'contents': 'Digitaltechnik Versuch 7.1: Rechenschaltungen Teil 1; Addierschaltungen; Aufbau der Addierschaltungen\\n'}, {'id': '/mls-api/tasks/243', 'contents': 'Digitaltechnik Versuch 6: Codes und Codeumsetzer; Was ist ein Code? ; Zahlencodes; Alphanumerische Codes; 7-Segment-Codeumsetzer; Wasserstandsanzeige\\n'}, {'id': '/mls-api/tasks/242', 'contents': 'Digitaltechnik Versuch 5.2: Schaltungssynthese Teil 2; Steuerung einer Treppenhausbeleuchtung; Auswahlverfahren für eine Arbeitsstelle; Kontrolle eines Stromnetzes; \"Zwei-aus-drei\"-Schaltung\\n'}, {'id': '/mls-api/tasks/241', 'contents': 'Digitaltechnik Versuch 5.1: Schaltungssynthese Teil 1; Schaltungssynthese, DNF und KNF; Das KV-Diagramm; Schaltungsentwurf Normalformen; Beispiel: Discofahrt\\n'}, {'id': '/mls-api/tasks/240', 'contents': 'Digitaltechnik Versuch 4.2: Boolesche Schaltalgebra Teil 2; De Morgansche Gesetze; Untersuchung der De Morganschen Gesetze Teil 1/2; Untersuchung der De Morganschen Gesetze Teil 2/2\\n'}, {'id': '/mls-api/tasks/239', 'contents': 'Digitaltechnik Versuch 4.1: Boolesche Schaltalgebra Teil 1; Boolesche Schaltalgebra; Untersuchung der Gesetze der booleschen Schaltalgebra Teil 1/2; Untersuchung der Gesetzte der booleschen Algebra Teil 2/2\\n'}, {'id': '/mls-api/tasks/238', 'contents': 'Digitaltechnik Versuch 3: Logische Schaltkreise in der Praxis; Grundlagen; Elektrische Daten der TTL-Familie; Nicht benutzte EIngänge; Fan-Out und Fan-In; Ausgangsbeschaltung\\n'}, {'id': '/mls-api/tasks/237', 'contents': 'Digitaltechnik Versuch 2.2: Zusammengesetzte Grundbausteine Teil 2; Die Antivalenz-Funktion (XOR); Untersuchung der Antivalenz-Funktion; Alternative Schaltung für die Äquivalenz-Funktion; Die Äquivalenz-Funktion (XNOR); Untersuchung der Äquivalenz-Funktion; Alternative Schaltung für die Äquivalenz-Funktion\\n'}, {'id': '/mls-api/tasks/236', 'contents': 'Digitaltechnik Versuch 2.1: Zusammengesetzte Grundbausteine Teil 1; Die NAND-Funktion; Untersuchung der NAND-Funktion; Logische Funktionen überprüfen; Die NOR-Funktion; Untersuchung der NOR-Funktion; Zusammengesetzte Funktion aus NOR-Gattern\\n'}, {'id': '/mls-api/tasks/235', 'contents': 'Digitaltechnik Versuch 1: Logische Grundschaltungen; Logische Aussagen, Schaltungen und Zustände; Logik des Digital Trainer Boards; Die NICHT-Funktion; Untersuchung der NICHT-Funktion; Die UND-Funktion; Untersuchung der UND-Funktion; Die ODER-Funktion; Untersuchung der ODER-Funktion\\n'}, {'id': '/mls-api/tasks/234', 'contents': 'Kick-off Grundlagen der Digitaltechnik; Cover; Sicherheitshinweise; Einführung; Ablauf\\n'}, {'id': '/mls-api/tasks/233', 'contents': 'S7-1500 mit tec2SKILL® connect Versuch 4: Montagestation; Aufbau; Ablaufbeschreibung; Variablentabelle; Aufbauplan; Ablaufgraph; SPS-Programm; Bausteinschnittstelle fbMontage; Ablaufgraph fbMontage; Programm fbMontage\\n'}, {'id': '/mls-api/tasks/232', 'contents': 'Testprogramm mit Programmvariablen; Programmiervariablen festlegen (1); Programmiervariablen festlegen (2)\\n'}, {'id': '/mls-api/tasks/231', 'contents': 'Erstellen eines Testprogramms; Erstellen eines einfachen Testprogramms; PLC-Variablentabelle; Programmbausteine einfügen; Programmablauf\\n'}, {'id': '/mls-api/tasks/230', 'contents': 'Kick-off Grundlagen S7-1500 mit tec2SKILL® connect; Cover; Sicherheitshinweise; Allgemeines; Hardware, Software und Voraussetzungen\\n'}, {'id': '/mls-api/tasks/229', 'contents': 'IO-Link Versuch 3: Vermessung eines Werkstückes; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor programmieren; Schaltausgang programmieren; Sensor über IO-Link programmieren; Werkstückvermessung; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/228', 'contents': 'IO-Link Versuch 2: Analoge Überwachung einer Werkzeuglöseeinheit; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Aufbau der Messanordnung; Sensor einstellen (Teach); Sensor über IO-Link programmieren; Messgerät einstellen; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/227', 'contents': 'IO-Link Versuch 1: Füllstanderfassung eines Tanks planen und ausführen; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan ; Messaufbau und Funktionstest; Sensor programmieren; Analogausgang programmieren; Schaltausgang programmieren; Sensor über IO-Link programmieren (1); Sensor über IO-Link programmieren (2)\\n'}, {'id': '/mls-api/tasks/226', 'contents': 'Kick-off IO-Link; Cover; Sicherheitshinweise; Einführung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/225', 'contents': 'Stirnradgetriebe ETS6 Versuch 3: Ausgleich Axialspiel (optional); Arbeitsschritt 1-4; Arbeitsschritt 5-7\\n'}, {'id': '/mls-api/tasks/224', 'contents': 'Stirnradgetriebe ETS6 Versuch 2: Montageanleitung 3-stufig ; Einbau Lager; Baugruppe Ritzelwelle 5; Baugruppe Ritzelwelle 3; Baugruppe Antriebswelle (1); Baugruppe Antriebswelle (2); Montage Verschlusskappe; Baugruppe antriebsseitiger Deckel (1); Baugruppe antriebsseitiger Deckel (2); Montage Baugruppe antriebseitiger Deckel; Montage Verschluss- und Entlüftungsschraube\\n'}, {'id': '/mls-api/tasks/223', 'contents': 'Stirnradgetriebe ETS6 Versuch 1: Montageanleitung 2-stufig ; Einbau Lager & Baugruppe Ritzelwelle; Baugruppe Ritzelwelle; Baugruppe Antriebswelle (1); Baugruppe Antriebswelle (2); Montage Verschlusskappe; Baugruppe antriebsseitiger Deckel (1); Baugruppe antriebsseitiger Deckel (2); Montage Baugruppe Antriebsdeckel; Montage Verschluss- und Entlüftungsschraube; Montage der Abdeckung\\n'}, {'id': '/mls-api/tasks/222', 'contents': 'Kick-off Montageanleitung Stirnradgetriebe 2/3-stufig ETS6; Cover; Sicherheitshinweise; Einführung und Ablauf\\n'}, {'id': '/mls-api/tasks/221', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 6: Wartung und Instandhaltung; Wartung und Instandhaltung\\n'}, {'id': '/mls-api/tasks/220', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 5: Montage und Demontage; Montagetechnik; Montagestruktur; Montageplanung\\n'}, {'id': '/mls-api/tasks/219', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 4: Antriebstechnik; Elektrische Drehstromantriebe mit festen Drehzahlen; Energiefluss; Kupplungen; Physik der Antriebstechnik; Antriebsauslegung\\n'}, {'id': '/mls-api/tasks/218', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 3: Zahnradgetriebekonstruktion; Zahnradgetriebekonstruktion ; Lagerungen; Lagerlebensdauerbestimmung; Schmierung und Dichtung; Radialwellendichtringe\\n'}, {'id': '/mls-api/tasks/217', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 2: Zahnradgeometrie; Der Modul; Schrägverzahnungen; Profilüberdeckung; Stirnradgetriebemotor; Zahnradbauformen; Verzahnungen\\n'}, {'id': '/mls-api/tasks/216', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 Aufgabe 1: Zahnräder und Zahnradgetriebe; Getriebemotor und Getriebearten; Physikalische Grundlagen von Stirnradgetrieben; Drehmoment und Leistung; Übersetzung des Drehmomentes; Wirkungsgrad\\n'}, {'id': '/mls-api/tasks/215', 'contents': 'Kick-off: Stirnradgetriebe 2/3-stufig ETS6; Cover; Sicherheitshinweise; Einführung; Demo-Getriebekoffer ETS6\\n'}, {'id': '/mls-api/tasks/214', 'contents': 'Additive Fertigung 3D-Druck - Aufgabe Zahnradkonfigurator; Getriebe ETS6; Zahnradkonfigurator/-generator (1); Zahnradkonfigurator/-generator (2); Ultimaker Cura (1); Ultimaker Cura (2); Montage\\n'}, {'id': '/mls-api/tasks/213', 'contents': 'Additive Fertigung 3D-Druck - Grundlagen; Additive Fertigungsverfahren; Vor- und Nachteile der Additiven Fertigung; Was ist Rapid Prototyping?; Was ist Rapid Tooling?; Was ist Rapid Manufacturing?\\n'}, {'id': '/mls-api/tasks/212', 'contents': 'Kick-off Additive Fertigung 3D-Druck ETS6; Cover; Sicherheitshinweise; Was ist Additive Fertigung?; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/211', 'contents': 'Versuch 4.2.: DC-Transfersystem mit tec2SKILL® connect - LOGO! - Programm Ablauf Werkstücktransport; Ablaufbeschreibung ; Zuordnungsliste; Ablaufgraph; SPS-Programm (1); SPS-Programm (2); Test\\n'}, {'id': '/mls-api/tasks/210', 'contents': 'Versuch 4.1.: DC-Transfersystem mit tec2SKILL® connect - LOGO! - Werkstücktransport; Aufgabe; Technologieschema; Aufbauplan; Stromlaufplan; Einführungsprogramm - Ablaufbeschreibung; Zuordnungsliste; Ablaufgraph; SPS-Programm; Test\\n'}, {'id': '/mls-api/tasks/209', 'contents': 'Versuch 3: DC-Transfersystem mit tec2SKILL® connect - LOGO! - Geschwindigkeitssteuerung; Aufgabe; Technologieschema; Aufbauplan; Stromlaufplan; Zuordnungsliste; Ablaufgraph; SPS-Programm (1); SPS-Programm (2); Reset-Funktion\\n'}, {'id': '/mls-api/tasks/208', 'contents': 'Versuch 2: DC-Transfersystem mit tec2SKILL® connect - LOGO! - Erweiterung Tippbetrieb; Aufgabe; Zuordnungsliste; SPS-Programm; Ablaufgraph; SPS-Programm mit Ablaufsteuerung; Test\\n'}, {'id': '/mls-api/tasks/207', 'contents': 'Versuch 1: DC-Transfersystem mit tec2SKILL® connect - LOGO! - Tippbetrieb; Aufgabe; Technologieschema; Aufbauplan PLC Board 24 V; Aufbauplan PLC Professional Board; Stromlaufplan; Zuordnungsliste; SPS-Programm\\n'}, {'id': '/mls-api/tasks/206', 'contents': 'Arbeitsplanung DC-Transfersystem mit tec2SKILL® connect - LOGO!; Inbetriebnahme; Betriebsmittelkennzeichnung; E/A-Belegung\\n'}, {'id': '/mls-api/tasks/205', 'contents': 'Kick-off: DC-Transfersystem mit tec2SKILL® connect - LOGO!; Cover; Sicherheitshinweise; Projektvorstellung; Digitales Modell mit tec2SKILL® connect\\n'}, {'id': '/mls-api/tasks/204', 'contents': 'IO-Link Versuch 3: Vermessung eines Werkstückes; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor programmieren; Schaltausgang programmieren; Sensor über IO-Link programmieren (1); Sensor über IO-Link programmieren (2); Werkstückvermessung\\n'}, {'id': '/mls-api/tasks/203', 'contents': 'IO-Link Versuch 2: Analoge Überwachung einer Werkzeuglöseeinheit; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Aufbau der Messanordnung; Sensor einstellen (Teach); Sensor über IO-Link programmieren (1); Sensor über IO-Link programmieren (2); Messgerät einstellen; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/202', 'contents': 'IO-Link Versuch 1: Füllstanderfassung eines Tanks planen und ausführen; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan ; Messaufbau und Funktionstest; Sensor programmieren; Analogausgang programmieren; Schaltausgang programmieren; Sensor über IO-Link programmieren (1); Sensor über IO-Link programmieren (2)\\n'}, {'id': '/mls-api/tasks/201', 'contents': 'Arbeitsplanung IO-Link; Verfügbare Sensoren; Schritte der Arbeitsplanung\\n'}, {'id': '/mls-api/tasks/200', 'contents': 'Kick-off IO-Link; Cover; Sicherheitshinweise; Einführung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/199', 'contents': 'alt-Grundlagen der Halbleitertechnik Versuch 4: Operationsverstärker ; Versuch 4.0.: Invertierender Verstärker (1); Versuch 4.0.: Invertierender Verstärker (2); Versuch 4.1.: Operationsverstärker als nichtinvertierender Verstärker (1); Versuch 4.1.: Operationsverstärker als nichtinvertierender Verstärker (2)\\n'}, {'id': '/mls-api/tasks/198', 'contents': 'alt-Grundlagen der Halbleitertechnik Versuch 3: Die Thyristortriode ; Versuch 3.0.: Zünd- und Löschvorgang an einer Thyristortriode TIC106; Versuch 3.1.: Verfahren zum Löschen einer Thyristortriode; Versuch 3.1.: Verfahren zum Löschen einer Thyristortriode (2)\\n'}, {'id': '/mls-api/tasks/197', 'contents': 'alt-Grundlagen der Halbleitertechnik Versuch 2: Bipolare Transistoren; Versuch 2.0.: Aufbau und Funktionsweise von bipolaren Transistoren (1);    Versuch 2.0.: Aufbau und Funktionsweise von bipolaren Transistoren (2); Versuch 2.1.: Wirkungen des Basisstroms auf den Kollektorstrom; Versuch 2.2.: Der Arbeitspunkt einer Verstärkerstufe\\n'}, {'id': '/mls-api/tasks/196', 'contents': 'alt-Grundlagen der Halbleitertechnik Versuch 1: Dioden und Gleichrichterschaltungen; Versuch 1.0: PN-Übergang als Diode ; Versuch 1.1: Einpuls-Mittelpunkt-Schaltung M1 ohne und mit Glättungskondensator; Versuch 1.2: Die Kennlinien einer Z-Diode; Versuch 1.3: Gleichspannungsbegrenzungen mit der Z-Diode; Versuch 1.4: Leuchtdioden\\n'}, {'id': '/mls-api/tasks/195', 'contents': 'Kick-off Grundlagen der Elektrotechnik Teil 2: Grundlagen der Halbleitertechnik; Cover; Sicherheitshinweise; Sicheres Experimentieren mit Strom und Spannung (Allgemeines); Funktion der Strombegrenzung; Feste Gleichspannung einstellen; Strom in Halbleiterwerkstoffen; Versuche\\n'}, {'id': '/mls-api/tasks/194', 'contents': 'Digitale Sensorik Versuch 5: Sensoranordnung zur Aussortierung weißer und sehr heller Kunststoffe; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Aufbau der Messanordnung; Nachweis der Funktion ; Einfluss der Objektfarbe auf den Tastbereich\\n'}, {'id': '/mls-api/tasks/193', 'contents': 'Digitale Sensorik Versuch 4: Sensoranordnung zur Größensortierung von Metallteilen; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Aufbau der Messanordnung; Nachweis der Funktion; Einfluss der Ausrichtung des Retrospiegels; Einfluss spiegelnder oder transparenter Objekte auf das Sensorverhalten\\n'}, {'id': '/mls-api/tasks/192', 'contents': 'Digitale Sensorik Versuch 3: Sensoranordnung zur Unterscheidung von Kunststoff und Metallteilen; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Nachweis der Funktion\\n'}, {'id': '/mls-api/tasks/191', 'contents': 'Digitale Sensorik Versuch 2: Sensoranordnung für vorbeifahrende Kunststoffe; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Nachweis der Funktion; Nachweis des Reduktionsfaktors\\n'}, {'id': '/mls-api/tasks/190', 'contents': 'Digitale Sensorik Versuch 1: Sensoranordnung für vorbeifahrende Metalle; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Nachweis der Funktion; Nachweis des Schaltabstands ; Nachweis des Reduktionsfaktors; Nachweis der Hyterese\\n'}, {'id': '/mls-api/tasks/189', 'contents': 'Arbeitsplanung Digitale Sensorik; Verfügbare Sensoren; Schritte der Arbeitsplanung\\n'}, {'id': '/mls-api/tasks/188', 'contents': 'Kick-off Digitale Sensorik; Cover; Sicherheitshinweise; Einführung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/187', 'contents': 'Netzanalyse Versuch 6: Untersuchung von Gleichrichterschaltungen; Aufgabe; B6U-Brücken-Gleichrichtschaltung; M3U-Brücken-Gleichrichtschaltung\\n'}, {'id': '/mls-api/tasks/186', 'contents': 'Netzanalyse Versuch 5: Entstehung von Oberschwingungen - Messtechnische Untersuchung ; Aufgabe; Sternschaltung bei Belastung mit nichtlinearem Verbraucher; Sternschaltung bei Belastung mit mehreren nichtlinearen Verbrauchern; Ergebnisanalyse\\n'}, {'id': '/mls-api/tasks/185', 'contents': 'Neutralleiterbelastung Versuch 4: Ohm’scher, induktiver bzw. kapazitiver (linearer) Verbraucher ; Aufgabe; Messungen\\n'}, {'id': '/mls-api/tasks/184', 'contents': 'Neutralleiterbelastung Versuch 3: Störungen an der Sternschaltung ; Aufgabe; Außenleiterausfall; Außenleiter- und Neutralleiterausfall; Unsymmetrische Last und Außenleiterausfall; Unsymmetrische Last, Außen- und Neutralleiterausfall\\n'}, {'id': '/mls-api/tasks/183', 'contents': 'Neutralleiterbelastung Versuch 2: Sternschaltung bei unsymmetrischer Belastung; Aufgabe; Hinweise; Messungen mit Neutralleiter; Messungen ohne Neutralleiter\\n'}, {'id': '/mls-api/tasks/182', 'contents': 'Neutralleiterbelastung Versuch 1: Sternschaltung bei symmetrischer Belastung; Aufgabe; Hinweise; Messungen mit Neutralleiter; Messungen ohne Neutralleiter\\n'}, {'id': '/mls-api/tasks/181', 'contents': 'Kick-off Neutralleiterbelastung - Netzanalyse; Cover; Sicherheitshinweise; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/180', 'contents': 'Elektrotechnik 1 Versuch 13: Elektromotor; Untersuchung eines permanenterregten Gleichstrommotors; Untersuchung eines Synchronmotors\\n'}, {'id': '/mls-api/tasks/179', 'contents': 'Elektrotechnik 1 Versuch 12: Transformatoren; Praktischer Nachweis der Transformatorwirkung\\n'}, {'id': '/mls-api/tasks/178', 'contents': 'Elektrotechnik 1 Versuch 11: Elektromagnetismus und Spulen; Elektromagnetismus; Phasenverschiebung zwischen Spannung und Strom; Der induktive Blindwiderstand XL\\n'}, {'id': '/mls-api/tasks/177', 'contents': 'Elektrotechnik 1 Versuch 10: Der Kondensator; Grundsätzliches zu Lade- und Entladevorgängen; Phasenverschiebung zwischen Strom und Spannung\\n'}, {'id': '/mls-api/tasks/176', 'contents': 'Elektrotechnik 1 Versuch 9: Dreiphasenwechselstrom (Drehstrom); Messungen an Drehstromsystemen; Messungen an symmetrischer und unsymmetrischer Sternschaltung; Messungen an symmetrischer und unsymmetrischer Dreieckschaltung\\n'}, {'id': '/mls-api/tasks/175', 'contents': 'Elektrotechnik 1 Versuch 8: Wirkleistung von Wechselspannungen; Wirkleistung der Sinuswechselspannung in der praktischen Übung\\n'}, {'id': '/mls-api/tasks/174', 'contents': 'Elektrotechnik 1 Versuch 7: Stromarten und ihre Kenngrößen; Kenngrößen der Sinusspannung in der praktischen Übung\\n'}, {'id': '/mls-api/tasks/173', 'contents': 'Elektrotechnik 1 Versuch 6: Wirkungsgrad; Praktische Uebung zum Wirkungsgrad\\n'}, {'id': '/mls-api/tasks/172', 'contents': 'Elektrotechnik 1 Versuch 5: Elektrische Leistung und Arbeit; Praktische Übungen zu Leistung und Arbeit im Stromkreis\\n'}, {'id': '/mls-api/tasks/171', 'contents': 'Elektrotechnik 1 Versuch 4: Zusammenschaltung von Spannungsquellen; Reihenschaltung von Spannungsquellen im Versuch\\n'}, {'id': '/mls-api/tasks/170', 'contents': 'Elektrotechnik 1 Versuch 3: Elektrische Widerstände; Aufnahme der Kennlinie I=f(U); Aufnahme der NTC-Kennlinien I = f (U) und R = f (U); Untersuchung der Abhängigkeit des LDR von der Beleuchtungsstärke; Nachweis der Eigenschaften einer Reihenschaltung von Widerständen; Nachweis der Eigenschaften parallel geschalteter Widerstände; Der unbelastete Spannungsteiler; Eigenschaften belasteter Spannungsteiler\\n'}, {'id': '/mls-api/tasks/169', 'contents': 'Elektrotechnik 1 Versuch 2: Ohmsches Gesetz; Das ohmsche Gesetz im Praxisversuch; Untersuchung der Abhängigkeit des Stroms von der Spannung; Aufgaben / Fragen\\n'}, {'id': '/mls-api/tasks/168', 'contents': 'Elektrotechnik 1 Versuch 1: Der elektrische Stromkreis; Der Stromkreis im praktischen Versuch; Aufgaben / Fragen\\n'}, {'id': '/mls-api/tasks/167', 'contents': 'Elektromotoren 2 - Versuch 6: Drehstrom-Synchronreluktanzmaschine; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung der Anlauf-Kennlinien\\n'}, {'id': '/mls-api/tasks/166', 'contents': 'Elektromotoren 2 - Versuch 5: Lastsimulation mit Drehstrom-Asynchronmotoren; Einführung; Lastsimulation mit konstantem Drehmoment (1); Lastsimulation mit konstantem Drehmoment (2); Lastsimulation mit linearem Lastmoment (1); Lastsimulation mit linearem Lastmoment (2); Lastsimulation mit quadratischem Lastmoment; Lastsimulation mit quadratischem Lastmoment (2)\\n'}, {'id': '/mls-api/tasks/165', 'contents': 'Elektromotoren 2 - Versuch 4: Drehstrom-Schleifringläufer; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien; Messung von Kennlinien in Sternschaltung\\n'}, {'id': '/mls-api/tasks/164', 'contents': 'Elektromotoren 2 - Versuch 3: IE4 Asynchronmaschine; Einführung 1; Einführung 2; Aufbau; Elektrischer Anschluss; Manueller Betrieb; Automatische Aufzeichnung einer Kennlinie; Sternschaltung (1); Sternschaltung (2)\\n'}, {'id': '/mls-api/tasks/163', 'contents': 'Elektromotoren 2 - Versuch 2: Drehstrom-Asynchronmaschine; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien; Messung von Kennlinien in Sternschaltung\\n'}, {'id': '/mls-api/tasks/162', 'contents': 'Elektromotoren 2 - Versuch 1: Einphasen-Wechselstrommotor; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/161', 'contents': 'Kick-off  Elektromotoren Teil 2: Wechsel- und Drehstrommotoren; Cover; Sicherheitshinweise; Einführung und Ablauf\\n'}, {'id': '/mls-api/tasks/160', 'contents': 'Kopiervorlage Versuche 56226 Elektromotoren; step; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt\\n'}, {'id': '/mls-api/tasks/159', 'contents': 'Elektromotoren 1 - Versuch 5: Schrittmotor; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/158', 'contents': 'Elektromotoren 1 - Versuch 4: Bürstenloser Gleichstrommotor (BLDC); Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/157', 'contents': 'Elektromotoren 1 - Versuch 3: Gleichstrom-Doppelschlussmaschine; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/156', 'contents': 'Elektromotoren 1 - Versuch 2: Gleichstrom-Reihenschlussmaschine; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/155', 'contents': 'Elektromotoren 1 - Versuch 1: Fremderregte Gleichstrom-Nebenschlussmaschine; Einführung; Versuchsprinzip; Aufbau; Elektrischer Anschluss; Messungen im stationären Betrieb; Auswertung der Ergebnisse; Messung von Kennlinien\\n'}, {'id': '/mls-api/tasks/154', 'contents': 'Einführung und Grundlagen; Magnetisches Feld; Durchflutungsgesetz; Induktionsgesetz; Lorentzkraft; Aufbau einer rotierenden elektrischen Maschine; Verständnisfragen\\n'}, {'id': '/mls-api/tasks/153', 'contents': 'Kick-off  Elektromotoren Teil 1: Gleichstrommotoren; Cover; Sicherheitshinweise; Einführung und Ablauf\\n'}, {'id': '/mls-api/tasks/152', 'contents': 'Analoge Sensorik Versuch 3:  Prüfung des Behälterdeckels; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Messgerät einstellen; Nachweis der Funktion; Nachweis des Schaltabstandes; Nachweis des Reduktionsfaktors\\n'}, {'id': '/mls-api/tasks/151', 'contents': 'Analoge Sensorik Versuch 2:  Füllstandserfassung eines Lagers für Behälter; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Ermittlung der Schallkeule; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/150', 'contents': 'Analoge Sensorik Versuch 1:  Füllstandserfassung eines Palettenlagers; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Nachweis der Reflektivität; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/149', 'contents': 'Arbeitsplanung Analoge Sensorik; Verfügbare Sensoren; Schritte der Arbeitsplanung\\n'}, {'id': '/mls-api/tasks/148', 'contents': 'Kick-off Analoge Sensorik; Cover; Sicherheitshinweise; Einführung und Ablauf; Projektvorstellung\\n'}, {'id': '/mls-api/tasks/147', 'contents': 'Grundlagen: Laser-Abstandssensor; Funktionsprinzip; Einsatzarten von optischen Sensoren\\n'}, {'id': '/mls-api/tasks/146', 'contents': 'Analoge Sensorik Versuch 1:  Füllstandserfassung eines Palettenlagers; Auftrag; Simulation der Aufgabenstellung; Informationsbeschaffung und Sensorauswahl; Stromlaufplan; Messaufbau und Funktionstest; Sensor einstellen (Teach); Nachweis der Funktion; Nachweis der Hysterese; Nachweis der Reflektivität; Detektionsverhalten bei Verkippung\\n'}, {'id': '/mls-api/tasks/145', 'contents': 'Kick-off; Analyse\\n'}, {'id': '/mls-api/tasks/144', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 7; 7. Aufgabe 4: Werkstücktransport  7.1 Aufgabenstellung; 7.2 Voraussetzung; 7.3 Technologieschema und Aufbauplan; 7.4 Aufbauplan; 7.5 Stromlaufplan; 7.6 Aufgabe 4.1: Einführunsprogramm; 7.7 Aufgabe 4.2: Programm Ablauf Werkstücktransport\\n'}, {'id': '/mls-api/tasks/143', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 6; 6. Aufgabe 3: Geschwindigkeitssteuerung 6.1 Aufgabenstellung; 6.2 Voraussetzungen; 6.3 Technologieschema; 6.4 Aufbauplan; 6.5 Stromlaufplan; 6.6 Variablentabelle; 6.7 Ablaufgraph; 6.8 SPS-Programm\\n'}, {'id': '/mls-api/tasks/142', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 5; 5. Aufgabe 2: Erweiterung Tippbetrieb; 5.1 Aufgabenstellung; 5.2 Variablentabelle; 5.3 Ablaufgraph; 5.4 SPS-Programm\\n'}, {'id': '/mls-api/tasks/141', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 4; 4. Aufgabe 1: Tippbetrieb 4.1 Aufgabenstellung; 4.2 Voraussetzung ; 4.3 Technologieschema; 4.4 Aufbauplan; 4.5 Stromlaufplan; 4.6 Variablentabelle; 4.7 SPS-Programm \\n'}, {'id': '/mls-api/tasks/140', 'contents': 'Transfersystem mit Gleichstrom 4.0 Teil 3; 3. Hinweise zur Programmierung; 3.1 E/A- und Programmvariablen; 3.2 Benennung der Programmvariablen; 3.3 Beibehaltung positiver Logik\\n'}, {'id': '/mls-api/tasks/139', 'contents': 'Transfersystem mit Gleichsstromantrieb 4.0 Teil 1; Cover und Sicherheitshinweise; 1. Elektrische Inbetriebnahme 1.1 Fertigungslinie mit Förderband; 1.2 Inbetriebnahme; 1.3 Kontrolle\\n'}, {'id': '/mls-api/tasks/138', 'contents': 'Stirnradgetriebe ETS6 4.0 Teil 7; 6. Wartung und Instandhaltung 6.1 Allgemein; 6.2 Ziele der Instandhaltung; 6.3 Instandhaltung\\n'}, {'id': '/mls-api/tasks/137', 'contents': 'Stirnradgetriebe ETS6 4.0 Teil 6; 5. Montage und Demontage 5.1 Montagetechnik; 5.2 Montagestruktur; 5.3 Montageplanung; 5.4 3-stufiges Getriebe Montageplanung\\n'}, {'id': '/mls-api/tasks/136', 'contents': 'Stirnradgetriebe ETS6 4.0 Teil 5; 4. Antriebstechnik 4.1 Elektrische Drehstromantriebe mit festen Drehzahlen; 4.2 Energiefluss; 4.3 Kupplungen; 4.4 Physik der Antriebstechnik\\n'}, {'id': '/mls-api/tasks/135', 'contents': 'Stirnradgetriebe ETS6 4. Teil 4; 3. Zahnradgetriebekonstruktion; 3.1 Lagerung\\n'}, {'id': '/mls-api/tasks/134', 'contents': 'Stirnradgetriebe ETS6 4.0 Teil 3; 2. Zahnradgeometrie 2.1 Grundlagen- der Modul; 2.2 Schrägverzahnung; 2.3 Profilüberdeckung; 2.4 Stirnradgetriebemotor; 2.5 Zahnradbauformen; 2.6 Verzahnung\\n'}, {'id': '/mls-api/tasks/133', 'contents': 'Stirnradgetriebe 2/3-stufig ETS6 4.0 Teil 2; 1. Zahnräder und Zahnradgetriebe 1.1 Getriebe; 1.2 Getriebemotor; 1.3 Getriebearten; 1.4 Physikalische Grundlagen von Stirnradgetrieben; 1.5 Drehmoment und Leistung; 1.6 Übersetzung des Drehmomentes; 1.7 Wirkungsgrad\\n'}, {'id': '/mls-api/tasks/132', 'contents': 'Stirnradgetriebe 2/3-stufig ETS 6 4.0 Teil 1; Cover und Sicherheitshinweise; Vorwort und Unterrichtlicher Einsatz; Grundlegendes; Schnittdarstellungen\\n'}, {'id': '/mls-api/tasks/131', 'contents': 'Grundlagen der Sensorik Analog 4.1 Teil 11; 6. Dritter betrieblicher Auftrag: Sensoranordnung für die Prüfung des Behälterdeckels planen und ausführen; 6.1 Aufgabenstellung; 6.2 Vereinfachungen/ Simulationen; 6.3 Arbeitsplanung; 6.4 Stromlaufplan; 6.5 Aufbau der Messanordnung; 6.5.1 Messgerät einstellen; 6.6 Nachweis der Funktion; 6.6.1 Auswertung des Versuchs; 6.7 Aufgabenstellung\\n'}, {'id': '/mls-api/tasks/130', 'contents': 'Grundlagen der Sensorik Analog 4.1 Teil 10; 5. Zweiter betrieblicher Auftrag: Sensoranordnung für die Füllstandserfassung eines Lagers für Behälter planen und ausführen; 5.1 Aufgabenstellung; 5.2 Vereinfachungen/ Simulationen; 5.3 Arbeitsplanung; 5.4 Stromlaufplan; 5.5  Aufbau der Messanordnung; 5.5.1 Sensor einstellen (Teach); 5.5.2 Messgerät einstellen; 5.6 Nachweis der Funktion; 5.6.1 Auswertung des Versuchs\\n'}, {'id': '/mls-api/tasks/129', 'contents': 'Grundlagen der Sensorik Analog 4.1 Teil 8; 3.3 Laser-Abstandssensor; 3.3.1 Funktionsprinzip; 3.3.2 Einsatzarten von optischen Sensoren; 3.3.3 Kontrollfragen und Umgang mit dem Datenblatt\\n'}, {'id': '/mls-api/tasks/128', 'contents': 'Grundlagen der Sensorik Analog 4.1 Teil 7; 3.2 Ultraschallsensor; 3.2.1 Funktionsprinzip ; 3.2.2 Die Schallkeule eines Ultraschallsensors; 3.2.3 Auswertung der Messergebnisse ; 3.2.4 Einflussgrößen auf die Messgenauigkeit des Ultraschallsensors; 3.2.5 Kontrollfragen und Umgang mit dem Datenblatt\\n'}, {'id': '/mls-api/tasks/127', 'contents': 'Grundlagen der Sensorik 4.1 Teil 6; 3. Sensoren der betrieblichen Aufträge; 3.1 Induktiver Näherungssensor; 3.1.1 Funktionsprinzip; 3.1.2 Kontrollfragen und Umgang mit dem Datenblatt\\n'}, {'id': '/mls-api/tasks/126', 'contents': 'Grundlagen: Charakterisierung von Messeigenschaften; Messbereich und Genauigkeit der Messung; Linearitätsfehler; Empfindlichkeit und Auflösung; Schaltabstände und Reduktionsfaktor; Mess-/ Schaltfrequenz; Schalthysterese; Ansprechkurve\\n'}, {'id': '/mls-api/tasks/125', 'contents': 'Grundlagen der Sensorik 4.1 Teil 1; Sicherheitshinweise; 1. Einführung\\n'}, {'id': '/mls-api/tasks/124', 'contents': 'Prüfung elektrischer Geräte 4.4 Teil 6; 4.3 Wiederholungsprüfung einer Bohrmaschine; Part 2\\n'}, {'id': '/mls-api/tasks/123', 'contents': 'Prüfung elektrischer Geräte Teil 13; 4.10 Prüfung einer Waschmaschine; Part 2\\n'}, {'id': '/mls-api/tasks/122', 'contents': 'Prüfung elektrischer Geräte Teil 14; 5. Fehlertabellen; 5.1 Bügeleisen; 5.2 Tauchsiedler; 5.3 Bohrmaschine; 5.4 PC; 5.5 Kabeltrommel; 5.6 Kaffeeautomat; 5.7 Herd; 5.8 Radio; 5.9 Netzgerät\\n'}, {'id': '/mls-api/tasks/121', 'contents': 'Prüfung elektrischer Geräte Teil 12; 4.9 Wiederholungsprüfung eines Netzgerätes; Part 2\\n'}, {'id': '/mls-api/tasks/120', 'contents': 'Prüfung elektrischer Geräte Teil 11; 4.8 Wiederholungsprüfung eines Radios ; Part 2\\n'}, {'id': '/mls-api/tasks/119', 'contents': 'Prüfung elektrischer Geräte Teil 10; 4.7 Prüfung eines Elektroherdes nach einer Reparatur; Part 2\\n'}, {'id': '/mls-api/tasks/118', 'contents': 'Prüfung elektrischer Geräte 4.0 Teil 9; 4.6 Wiederholungsprüfung eines Kaffeeautomaten; Part 2\\n'}, {'id': '/mls-api/tasks/117', 'contents': 'Prüfung elektrischer Geräte Teil 8; 4.5 Wiederholungsprüfung einer Kabeltrommel; Part 2\\n'}, {'id': '/mls-api/tasks/116', 'contents': 'Prüfung elektrischer Geräte Teil 7; 4.4 Wiederholungsprüfung eines PCs; Part 2; Neuer Arbeitsschritt; Neuer Arbeitsschritt; Neuer Arbeitsschritt\\n'}, {'id': '/mls-api/tasks/115', 'contents': 'Prüfung elektrischer Geräte 4.4 Teil 5; 4.2 Prüfung eines Tauchsieders; Part 2\\n'}, {'id': '/mls-api/tasks/114', 'contents': 'Prüfung elektrischer Geräte 4.4 Teil 4 (kopiert); 4. Aufgaben; 4.1 Wiederholungsprüfung eines Bügeleisens; Part 2\\n'}, {'id': '/mls-api/tasks/113', 'contents': 'Prüfung elektrischer Geräte Version 4.4 Teil 3; 3. Definitionen / 3.1 Ortsfeste Betriebsmittel; 3.2 Ortsveränderliche Verbraucher; 3.3 Aktive und passive Messung; 3.4 Definitionen der Schutzklassen\\n'}, {'id': '/mls-api/tasks/112', 'contents': 'Prüfung elektrischer Geräte Version 4.4 Teil 1; Deckblatt/ Sicherheitshinweise; 1. Einleitung; 1.1 Anforderungen an den Prüfer; 1.2 - 1.4 ; 1.5 Prüffristen nach DGUV Vorschrift 3\\n'}, {'id': '/mls-api/tasks/46', 'contents': 'Vorstellung Projekt Presse futurelearning (Demo) [0]; Start; informieren Pressenfuß / BG1; informieren Verbindungsteil_innen; Funktionsbeschreibung Verbindungsteil_innen; Funktionsbeschreibung Lösungsvorschlag; technische Darstellung Verbindungsteil_innen; informieren Körnen; planen Verbindungsteil_innen; Arbeitsschrittkarten Verbindungsteil_innen; entscheiden Verbindungsteil_innen\\n'}, {'id': '/mls-api/tasks/45', 'contents': 'Verbindungsplatte [2_3]; Start; informieren technische Darstellungen; informieren Verfahrenshinweise; planen Verbindungsplatte; entscheiden Verbindungsplatte; Arbeitsplan Verbindungsplatte; durchführen Verbindungsplatte; kontrollieren Verbindungsplatte; Erfolgskonrolle Verbindungsplatte; Lernprozess bewerten\\n'}, {'id': '/mls-api/tasks/44', 'contents': 'Pressensäule / BG2 Montage [2_8]; Start; informieren technische Darstellungen; informieren Montage Pressensäule (BG2); planen Montage Pressensäule (BG2); entscheiden Montage Pressensäule (BG2); Montageanleitung Pressensäule (BG2); durchführen Montage Pressensäule (GB2); kontrollieren Montage Pressensäule (BG2); Erfolgskongrolle Montage Pressensäule (BG2); Lernprozess bewerten\\n'}, {'id': '/mls-api/tasks/43', 'contents': 'Gewindespindel [2_7]; Start; informieren Funktion Gewindespindel; informieren technische Darstellungen; informieren Verfahrenshinweise; planen Gewindespindel; entscheiden Gewindespindel; Arbeitsplan Gewindespindel; durchführen Gewindespindel; kontrollieren Gewindespindel; Erfolgskontrolle Gewindespindel\\n'}, {'id': '/mls-api/tasks/42', 'contents': 'Säule [2_6]; Start; informieren Funktion Säule; informieren technische Darstellungen; informieren Verfahrenshinweise; informieren Messen III; planen Säule; entscheiden Säule; Arbeitsplan Säule; durchführen Säule; kontrollieren Säule\\n'}, {'id': '/mls-api/tasks/41', 'contents': 'Halterung [2_5]; Start; Funktionsbeschreibung (Lösungsvorschlag); informieren technische Darstellungen; informieren Verfahrenshinweise; informieren Drehen I; informieren Drehen II; informieren Arbeitssicherheit Drehen; informieren Außengewinde schneiden; planen Halterung; Arbeitsschrittkarten Halterung\\n'}, {'id': '/mls-api/tasks/40', 'contents': 'Deckplatte [2_4]; Start; informieren technische Darstellungen; informieren Verfahrenshinweise; planen Deckplatte; entscheiden Deckplatte; Arbeitsplan Deckplatte; durchführen Deckplatte; kontrollieren Deckplatte; Erfolgskontrolle Deckplatte; Lernprozess bewerten\\n'}, {'id': '/mls-api/tasks/39', 'contents': 'Seitenplatten [2_2]; Start; Funktionsbeschreibung (Lösungsvorschlag); informieren technische Darstellungen; informieren Verfahrenshinweise; informieren Fräsen I; informieren Fräsen II; informieren Kantentaster; informieren Arbeitssicherheit Fräsen I; planen Seitenplatten; Arbeitsschrittkarten Seitenplatten\\n'}, {'id': '/mls-api/tasks/38', 'contents': 'Pressensäule / BG2 [2_1] - informieren; informieren\\n'}, {'id': '/mls-api/tasks/37', 'contents': 'Gesamtmontage Presse [6_1]; Arbeitsschritt Montage Gessamtprojekt Presse; planen Montage Gessamtprojekt Presse; Montageplan Gessamtprojekt Presse; durchführen Montage Gessamtprojekt Presse; Erfolgskontrolle Gessamtprojekt Presse; \"Ich kann ...\"-Liste überfachliche Kompetenzen; \"Ich kann ...\"-Liste fachliche Kompetenzen\\n'}, {'id': '/mls-api/tasks/36', 'contents': 'Tischplatte / BG5 [5_1]; informieren Tischplatte; planen Tischplatte; Arbeitsplan Tischplatte; durchführen Tischplatte; Erfolgskontrolle Tischplatte; \"Ich kann ...\"-Liste überfachliche Kompetenzen; \"Ich kann ...\"-Liste fachliche Kompetenzen\\n'}, {'id': '/mls-api/tasks/35', 'contents': 'elektrotechnische Erweiterung [4_2]; informieren elektrotechnische Erweiterung\\n'}, {'id': '/mls-api/tasks/34', 'contents': 'Pressenkopf / BG4 [4_1] ; informieren Pressenkopf (BG4); planen Bauteile Pressenkopf (BG4); Arbeitsplan leer; durchführen Bauteile Pressenkopf (BG4); Erfolgskontrolle leer; planen Montage Pressenkopf (BG4); Montageplan Pressenkopf  (BG4); durchführen Montage Pressenkopf (BG4); Erfolgskontrolle Montage Pressenkopf  (BG4); \"Ich kann ...\"-Liste überfachliche Kompetenzen\\n'}, {'id': '/mls-api/tasks/33', 'contents': 'Verbindungsteil_außen [1_9] - bewerten; Lernprozess bewerten; \"Ich kann ...\"-Liste überfachliche Kompetenzen; \"Ich kann ...\"-Liste fachliche Kompetenzen\\n'}, {'id': '/mls-api/tasks/32', 'contents': 'Verbindungsteil_außen [1_8] - durchführen und kontrollieren; durchführen Verbindungsteil_außen ; kontrollieren Verbindungsteil_außen; Ergebniskontrolle Verbindungsteil_außen; Bohrplatte Verbindungsteil_außen\\n'}, {'id': '/mls-api/tasks/31', 'contents': 'Verbindungsteil_außen [1_7] - planen und entscheiden; planen Verbindungsteil_außen; entscheiden Verbindungsteil_außen; Arbeitsplan Verbindungsteil_außen\\n'}, {'id': '/mls-api/tasks/30', 'contents': 'Verbindungsteil_außen [1_6] - informieren; Start; informieren Funktion Verbindungsteil_außen; informieren technische Darstellung; informieren Verfahrenshinweise; informieren Sägen\\n'}, {'id': '/mls-api/tasks/29', 'contents': 'Pressenfuß / BG1 Montage  [1_15]; Start; informieren Funktion Pressenfuß; informieren Montage Pressenfuß; Lösung Montageanforderungen; informieren technische Darstellungen; informieren Reiben; informieren Lehren; informieren Fügen; planen Montage Pressenfuß (BG1); entscheiden Montage Pressenfuß (BG1)\\n'}, {'id': '/mls-api/tasks/28', 'contents': 'Trägerplatte [1_14]; Start; informieren Funktion Trägerplatte; informieren technische Darstellungen; informieren Verfahrenshinweise; planen Trägerplatte; entscheiden Trägerplatte; Arbeitsplan Trägerplatte; durchführen Trägerplatte; kontrollieren Trägerplatte; Erfolgskontrolle Trägerplatte\\n'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks-test/json/tasks2.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peng_luh/.pyenv/versions/3.9.5/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/peng_luh/.pyenv/versions/3.9.5/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/__main__.py\", line 118, in <module>\n",
      "    encoder = init_encoder(args.encoder.encoder, args.encoder.encoder_class, device=args.encoder.device)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/__main__.py\", line 60, in init_encoder\n",
      "    return encoder_class(**kwargs)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/_auto.py\", line 28, in __init__\n",
      "    self.model.to(self.device)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 1811, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1145, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1143, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peng_luh/.pyenv/versions/3.9.5/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/peng_luh/.pyenv/versions/3.9.5/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/__main__.py\", line 118, in <module>\n",
      "    encoder = init_encoder(args.encoder.encoder, args.encoder.encoder_class, device=args.encoder.device)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/__main__.py\", line 60, in init_encoder\n",
      "    return encoder_class(**kwargs)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/encode/_auto.py\", line 28, in __init__\n",
      "    self.model.to(self.device)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 1811, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1145, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1143, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import transformers\n",
    "\n",
    "cmd = \"\"\"\n",
    "    python -m pyserini.encode \\\n",
    "        input   --corpus /home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks-test/jsonl/data.jsonl \\\n",
    "                --fields text \\\n",
    "                --delimiter \";\" \\\n",
    "                --shard-id 0 \\\n",
    "                --shard-num 1 \\\n",
    "        output  --embeddings /home/peng_luh/__git/search_l3s/search_l3s_search_srv/encodes/dense/xlm_roberta_base/mls-tasks-test \\\n",
    "                --to-faiss \\\n",
    "        encoder --encoder xlm-roberta-large \\\n",
    "                --fields text \\\n",
    "                --batch 32 \\\n",
    "                --fp16\n",
    "\"\"\"\n",
    "\n",
    "subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_german_uncased\n",
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/jsonl/data.jsonl\n",
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/encodes/dense/bert_german_uncased/mls-tasks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search_l3s_search.api.encoder.logic import BertGermanUncasedDenseEncoder\n",
    "\n",
    "enc = BertGermanUncasedDenseEncoder()\n",
    "\n",
    "enc.print_model_name()\n",
    "\n",
    "enc.dataset_encoder(dataset_name=\"mls-tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/jsonl/data.jsonl\n",
      "/home/peng_luh/__git/search_l3s/search_l3s_search_srv/encodes/dense/bert_german_uncased/mls-tasks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search_l3s_search.api.encoder.logic import BertGermanUncasedDenseEncoder\n",
    "\n",
    "enc = BertGermanUncasedDenseEncoder()\n",
    "\n",
    "print(len(enc.query_encoder(\"Beispiel\")))\n",
    "\n",
    "enc.dataset_encoder(dataset_name=\"mls-tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "def hnsw_indexer(encode_cat, model_name, dataset_name):\n",
    "        dataset_encode_path = os.path.join(os.getcwd(),\n",
    "                                            f\"encodes/{encode_cat}/{model_name}/{dataset_name}\"\n",
    "                                        )\n",
    "        if not os.path.exists(dataset_encode_path):\n",
    "            raise FileNotFoundError\n",
    "        \n",
    "        output_path = os.path.join(os.getcwd(), f\"indexes/{encode_cat}/{model_name}/hnsw/{dataset_name}\")\n",
    "        # print(output_path)\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        \n",
    "        hnsw_cmd = f\"\"\"\n",
    "            python -m pyserini.index.faiss \\\n",
    "                --input {dataset_encode_path} \\\n",
    "                --output {output_path} \\\n",
    "                --hnsw\n",
    "        \"\"\"\n",
    "        \n",
    "        subprocess.call(hnsw_cmd, shell=True)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 768)\n",
      "hnsw_add_vertices: adding 326 elements on top of 0 (preset_levels=0)\n",
      "  max_level = 0\n",
      "Adding 326 elements at level 0\n",
      "Done in 40.108 ms\n",
      "326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hnsw_indexer(encode_cat=\"dense\", model_name=\"bert_german_uncased\", dataset_name=\"mls-tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search.faiss import FaissSearcher\n",
    "import json\n",
    "\n",
    "def dense_retrieval(query):\n",
    "        model_name = \"bert_german_uncased\"\n",
    "        dataset_name = \"mls-tasks\"\n",
    "        index_method = \"hnsw\"\n",
    "        \n",
    "        dataset_file_path = os.path.join(os.getcwd(), f\"datasets/{dataset_name}/jsonl/data.jsonl\")\n",
    "        \n",
    "        prebuilt_index_path = os.path.join(os.getcwd(), f\"indexes/dense/{model_name}/{index_method}/{dataset_name}\")\n",
    "\n",
    "        search_engine = FaissSearcher(\n",
    "            prebuilt_index_path,\n",
    "            \"dbmdz/bert-base-german-uncased\"\n",
    "        )\n",
    "                \n",
    "        hits = search_engine.search(query)\n",
    "        results=[]\n",
    "        \n",
    "        # if hits:\n",
    "        #     for i in range(0, len(hits)):\n",
    "        #         temp = ast.literal_eval(hits[i].raw)\n",
    "        #         temp['score'] = f'{hits[i].score:.4f}'\n",
    "        #         results.append(temp)\n",
    "        \n",
    "        for i in range(0, 10):\n",
    "            docid = hits[i].docid\n",
    "            with open(dataset_file_path, \"r\") as dataset:\n",
    "                for line in dataset:\n",
    "                    json_obj = json.loads(line)\n",
    "                    if int(docid) == json_obj[\"id\"]:\n",
    "                        temp = dict()\n",
    "                        temp[\"@id\"] = json_obj[\"@id\"]\n",
    "                        temp[\"contents\"] = json_obj[\"contents\"]\n",
    "                        temp[\"score\"] = f\"{hits[i].score:.5f}\"\n",
    "                        results.append(temp)\n",
    "            \n",
    "            # print(f'{i+1:2} {hits[i].docid:7} {hits[i].score:.5f}')\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_331 = [0.22154638171195984, -0.03536605462431908, -0.2912493050098419, 0.5319214463233948, -0.36612260341644287, 0.03568511828780174, 0.27370965480804443, 0.00978295411914587, -0.045464105904102325, -0.267067551612854, 0.6439609527587891, -0.1166854053735733, -0.7110666632652283, 0.9173524379730225, 0.4479750990867615, 0.22522468864917755, -0.5504530668258667, -0.3796117305755615, -0.41885364055633545, -0.5035166144371033, 0.18854443728923798, 0.23881149291992188, 1.1101657152175903, -0.9617190361022949, -0.006559269968420267, 0.2220858633518219, -0.22361570596694946, -0.18334241211414337, -0.03386091813445091, 0.6254233717918396, 0.40355944633483887, -0.6828979253768921, 0.5137401819229126, 0.5067671537399292, -0.3722723424434662, 0.2831169664859772, -0.24351198971271515, 0.3541296720504761, 0.5935749411582947, -0.11793436110019684, 0.2677404582500458, -0.2652527391910553, 0.5108146071434021, -0.5921666622161865, -0.17076407372951508, -0.4888835847377777, -0.048121627420186996, -1.0304791927337646, -0.02815260738134384, -0.24148282408714294, -0.6323826313018799, 0.08970674127340317, 0.46729499101638794, -0.27126574516296387, -0.16023801267147064, 0.2958875894546509, 0.2974606454372406, 0.6791817545890808, -0.027798665687441826, 0.8141459822654724, 0.7901440858840942, -0.19421859085559845, -0.06948456913232803, -0.021152153611183167, 0.36398953199386597, -0.4986671507358551, -0.3841012120246887, -1.1012091636657715, -0.18721577525138855, 0.05288136005401611, -0.16339851915836334, 0.2620474696159363, 0.4209460914134979, -3.2898201942443848, 0.13884419202804565, 0.49751394987106323, 1.4624335765838623, 0.4739340543746948, 0.32848060131073, -0.6530799865722656, 0.07329990714788437, 0.031008083373308182, -0.8977426886558533, 0.06638327240943909, 0.011134698055684566, 0.6172598600387573, -1.379198670387268, 0.2541881799697876, 0.2216394692659378, -0.4148119390010834, 0.2917603552341461, -0.3300979435443878, -0.03924437239766121, -0.9383015036582947, -0.020288363099098206, -0.07907771319150925, 0.09857144951820374, -0.3385886549949646, -0.4194817841053009, 0.32148635387420654, -0.07520481944084167, -0.2854905426502228, -0.20120887458324432, -0.3893740475177765, 0.23189781606197357, 0.20734094083309174, 0.22193670272827148, 0.46635064482688904, 0.9917510747909546, -0.3811907470226288, -0.08535239845514297, -0.13135433197021484, 0.3366360664367676, 0.8447031378746033, 0.5194770097732544, 0.4730754792690277, -0.10181786119937897, 0.4108662009239197, 0.563346803188324, -0.004596702288836241, 0.10382963716983795, 0.1976446956396103, -0.4171176552772522, -0.01944463886320591, -0.6670040488243103, -0.20813995599746704, 0.25109803676605225, 0.29040631651878357, 0.19775390625, -0.806316077709198, -1.5847177505493164, 0.287110298871994, 0.6104015111923218, 0.06437893956899643, -0.37466368079185486, 0.3771003782749176, 0.137516051530838, 0.3757713735103607, 1.0917292833328247, -0.17437972128391266, 0.26122725009918213, -0.004995782393962145, -0.5880810618400574, 0.6752739548683167, 0.1093020811676979, 0.2423037886619568, -0.3378508687019348, -0.10573738068342209, -0.3565458357334137, -14.043425559997559, 0.47333618998527527, 0.9879235625267029, -0.5170160531997681, -1.191133975982666, 0.4889661371707916, 0.25763139128685, -0.03934541717171669, -0.4841372072696686, -0.06555373221635818, 0.05024592950940132, -0.8585819602012634, -0.1499122679233551, -0.47456884384155273, -0.8169113993644714, 0.4768712818622589, -0.09233439713716507, -0.06613187491893768, 0.37947332859039307, -0.5797991156578064, 0.2505777180194855, 0.47341272234916687, 0.35033443570137024, -1.1364407539367676, 0.2004738301038742, -0.08153394609689713, -0.34715622663497925, -0.33537548780441284, 0.47172775864601135, 0.05629431828856468, -0.7562210559844971, 0.2860223650932312, 0.33384695649147034, 0.7083267569541931, -0.13190196454524994, 1.2097312211990356, -0.28878292441368103, -0.10386764258146286, -0.5908347964286804, 0.47809305787086487, 0.2522825598716736, 0.03384004160761833, 0.1476939618587494, 0.16521002352237701, -0.037338756024837494, 0.4095965027809143, -0.3498218357563019, 0.03930428624153137, -0.04635385423898697, 0.9078057408332825, 0.2618737518787384, 0.5488669872283936, 0.015335286036133766, -0.29952970147132874, -0.506941556930542, -0.010026415809988976, -0.06746960431337357, 0.15556350350379944, 0.2657564580440521, -1.2192751169204712, 0.18280719220638275, -0.06940429657697678, -0.2720226049423218, -0.5463625192642212, 0.43049514293670654, -0.3362327814102173, 0.08873749524354935, 0.24111127853393555, 0.13457022607326508, 1.2211908102035522, 0.4936220943927765, 0.2184792459011078, 0.36253029108047485, 0.45400264859199524, 0.2977726459503174, -0.10401637107133865, 0.18768416345119476, 0.21402980387210846, 0.22453179955482483, 0.03527450934052467, -0.09471135586500168, -0.191964790225029, -0.40598565340042114, -0.009422004222869873, 0.235077366232872, -0.913417398929596, 0.2609175741672516, 0.4095500111579895, 0.2356719821691513, -0.1571531444787979, 0.8467679023742676, 0.038500506430864334, -0.271562397480011, 0.318322092294693, -0.3009224534034729, 0.0237403754144907, 0.45458608865737915, -0.06051953136920929, -0.25164952874183655, 0.33925238251686096, 0.2361641526222229, -0.39735147356987, 0.08137153089046478, -0.19485220313072205, -0.3810477554798126, 0.009734799154102802, -0.25898462533950806, 0.7409868836402893, -0.07437841594219208, 0.0029077017679810524, 0.47381719946861267, 0.2935835123062134, 0.11488308012485504, 0.2173895388841629, -0.5445263981819153, -0.261358380317688, -0.09375723451375961, -0.2329961657524109, -0.3792358636856079, 0.8232138752937317, -0.15006932616233826, 0.020131032913923264, 0.01216090191155672, -0.6171147227287292, 0.1832321286201477, 0.5187524557113647, 0.011182336136698723, -0.009324604645371437, 0.27990487217903137, 0.20388612151145935, 0.5358164310455322, 0.07206989079713821, 0.9242681264877319, -0.263177752494812, 0.6874938607215881, 0.3132344186306, 0.1495007425546646, 0.01707719825208187, 0.3223930895328522, -0.650538980960846, -0.14148642122745514, -0.4693257212638855, 0.09812896698713303, 0.0019449596293270588, 0.05856376886367798, -0.8004976511001587, -0.468003511428833, 0.42769551277160645, -0.3013893663883209, -0.0921923890709877, 0.14745904505252838, 0.6136793494224548, 0.6398677825927734, -0.12428512424230576, -0.12186910957098007, -0.6339580416679382, -0.3424898386001587, -0.2910423278808594, 0.32909417152404785, -0.08585228025913239, 0.13842763006687164, 0.411792516708374, 0.534913957118988, 0.42631080746650696, -0.22637243568897247, -0.08645687997341156, 0.13470439612865448, -0.8058285713195801, 0.2505238950252533, -0.0877099558711052, 0.2665371298789978, -0.3572221100330353, 0.37013161182403564, -0.7641989588737488, 0.8427732586860657, -0.36719581484794617, 0.017611632123589516, -0.28877130150794983, 1.0331522226333618, -0.7090998888015747, -0.08541853725910187, -0.14591820538043976, -0.16174393892288208, 0.8785203099250793, -0.6647529006004333, -1.1045868396759033, 0.010873427614569664, 0.01748516783118248, -0.38860464096069336, -0.4298636019229889, -0.500834584236145, 0.7375121116638184, -0.07536491006612778, 0.6416773796081543, -0.386107474565506, -0.19342394173145294, -0.46380215883255005, -0.04931049421429634, 0.43778252601623535, 0.32846617698669434, -0.04507628455758095, 0.9580941200256348, 1.0597399473190308, 0.0874054878950119, -0.41313958168029785, 0.5303297638893127, 0.11317025125026703, -0.3927030563354492, -0.5442252159118652, 0.7966984510421753, -0.1298971176147461, -0.20649994909763336, -0.946942150592804, 0.021568890661001205, 1.1890907287597656, -1.2584587335586548, -0.33032625913619995, -0.5287941098213196, 0.1044955775141716, 0.6208651065826416, 0.3320682644844055, 0.3645220100879669, 0.31699275970458984, -0.254189670085907, -0.5772091150283813, 0.09218815714120865, -0.20067502558231354, -0.1096423864364624, -0.4546753466129303, -0.22713476419448853, -0.07566504925489426, -0.12437400221824646, 0.597306489944458, -0.27569589018821716, -0.33553454279899597, 0.6672300100326538, -0.37848639488220215, 0.1949804127216339, -0.18572303652763367, -0.10126736015081406, -0.1346205174922943, -0.13155597448349, -1.0336236953735352, 0.10716253519058228, -0.5330153107643127, 0.7319086194038391, 0.5263681411743164, -0.23031586408615112, -0.5921040773391724, 0.0830376073718071, -0.050373226404190063, -0.21228475868701935, -0.7342960834503174, -0.39397627115249634, 0.06279758363962173, -0.04762892797589302, -0.17493334412574768, -0.5439286828041077, 0.3184834122657776, -0.5473164916038513, 0.15268610417842865, 0.18267792463302612, 0.21561913192272186, 0.5564021468162537, 0.05969442427158356, -0.3835783302783966, -1.075946569442749, -0.23557469248771667, 0.19136376678943634, -0.289767324924469, -0.08182723820209503, -0.3794582486152649, 0.06350813806056976, 0.6975003480911255, -0.15292294323444366, 0.343221515417099, 0.22280757129192352, -0.513473629951477, -0.30218952894210815, -0.42250365018844604, 0.1660229116678238, -0.30724847316741943, 0.21209849417209625, -0.8669721484184265, 0.9081754684448242, 0.45162251591682434, 1.4697083234786987, 0.3743985593318939, 0.1878405511379242, -0.16802945733070374, 0.44648921489715576, 1.2136332988739014, 0.09858949482440948, 0.31655964255332947, 0.07666774094104767, 0.19530776143074036, 0.10853416472673416, -0.09794075787067413, 0.1263394057750702, 0.004142037592828274, -0.6776214838027954, -0.3137854039669037, 0.1892148107290268, 0.06586449593305588, 0.03050629049539566, 0.2779353857040405, -0.26581695675849915, -0.12435257434844971, -0.11469384282827377, 0.19596610963344574, 0.4760918617248535, 0.16739672422409058, 0.36044934391975403, 0.20693767070770264, 0.600701630115509, 0.05300360918045044, -0.6535438299179077, 0.29670313000679016, -0.2649935483932495, 0.3100591003894806, -0.16534222662448883, 0.603947103023529, -0.1965954452753067, 0.22026464343070984, 0.5556516051292419, 0.3796635568141937, -1.0347172021865845, -0.6868613362312317, -0.5368090867996216, -0.1719871312379837, 0.12198743224143982, -0.5445279479026794, -0.16824106872081757, 0.0002375345939071849, -0.18796195089817047, -0.45415955781936646, -0.42497947812080383, -0.4615939259529114, -0.20420196652412415, 0.3073006570339203, 0.030007638037204742, -0.7294412851333618, -0.3453335165977478, -0.5656929016113281, -0.5996313095092773, -0.30348968505859375, -0.20380379259586334, 0.007559905294328928, -0.45595479011535645, -0.07570259273052216, 0.03928603231906891, -0.1769038885831833, -0.13529008626937866, 1.1439050436019897, -0.33488404750823975, -0.41670677065849304, 0.3602760434150696, -0.0847148448228836, -0.25955817103385925, -0.2038497030735016, -0.2561943531036377, 1.0978432893753052, 0.20240794122219086, 0.461073637008667, 0.1298782080411911, -0.3727109432220459, 0.7304834127426147, 0.5297349691390991, -0.551512598991394, 0.7137865424156189, 0.10095083713531494, -0.013575551100075245, -0.20321029424667358, -0.4811446964740753, -0.2997974455356598, -0.37714141607284546, -1.0301226377487183, 0.022593699395656586, 0.6810116171836853, -0.05781028792262077, 0.24921448528766632, 0.5631072521209717, 0.5052714943885803, -0.5453206896781921, 0.1162337139248848, 0.2852400839328766, -0.1939760446548462, 0.4778609573841095, 0.17707528173923492, 0.20232945680618286, 0.6441445350646973, -0.32558736205101013, -0.3608724772930145, -0.3715103566646576, 0.11373715102672577, 0.04518590122461319, 0.7240031361579895, -0.08473435789346695, 0.9469995498657227, 0.2008855640888214, -0.01693122088909149, 0.30899757146835327, 0.5058563947677612, 0.5853034853935242, -0.7788946032524109, -0.32663822174072266, 0.720164954662323, -0.05127892270684242, 0.09994880855083466, 0.20955879986286163, 0.28164759278297424, 1.2397141456604004, 0.22406895458698273, -0.16704663634300232, 0.23139506578445435, 0.16772791743278503, 0.12261948734521866, 0.4314460754394531, -0.45407983660697937, -0.44550782442092896, 0.15390868484973907, 0.0610174685716629, 0.41923561692237854, -0.49442362785339355, 0.48522162437438965, -0.7421517372131348, 0.03433595970273018, 0.0006315102800726891, -0.41982829570770264, -0.1552351415157318, 0.13251811265945435, -0.6308271288871765, -1.5918852090835571, -0.48867014050483704, 0.8102247714996338, -0.68392413854599, 0.13340236246585846, -0.40186306834220886, 0.7239654064178467, 0.45854106545448303, -0.34783491492271423, 0.6744083166122437, 0.004725173115730286, -0.13768263161182404, 0.11462234705686569, 0.6968070864677429, 0.754035234451294, 0.2863507568836212, 1.0739479064941406, -0.04527704790234566, 0.42607423663139343, -0.16836144030094147, 0.8456312417984009, 0.2766447067260742, -0.5625872611999512, 0.539954423904419, 0.11684135347604752, 0.5189899802207947, -0.43748271465301514, 0.20900914072990417, 1.0194834470748901, 0.22133643925189972, 0.2640106678009033, -0.41443586349487305, 0.5090633630752563, -0.37466493248939514, -0.06732446700334549, 0.8816194534301758, 0.19706715643405914, 0.33617717027664185, -0.3937286138534546, 0.26783373951911926, -0.6894789934158325, 0.843172013759613, 0.2604798674583435, 0.6511631608009338, 0.5821529626846313, 0.3069513142108917, 0.17376618087291718, 0.18571771681308746, 0.32309484481811523, 0.47388768196105957, -0.3340679407119751, -0.10960562527179718, 0.34419724345207214, -0.1232864260673523, -0.443847119808197, 0.7879575490951538, 0.3149968683719635, 0.1349290907382965, -0.5409595966339111, 0.151164710521698, -0.14085401594638824, 0.276419460773468, 0.3630043566226959, -0.449211061000824, -0.6947718262672424, 0.5284052491188049, -0.39295142889022827, 0.4084552824497223, 0.5665998458862305, 0.7901442050933838, -0.25017213821411133, 0.22328875958919525, -0.11152839660644531, 0.6064267158508301, 0.3957063853740692, -0.03258167579770088, -0.03688677400350571, -0.7916764616966248, 0.18453571200370789, -0.10405879467725754, -0.2748679518699646, -0.02709329128265381, -0.6729950308799744, 1.5267003774642944, 0.5404310822486877, 0.6259427070617676, 0.07243498414754868, 0.03122643753886223, 0.832466185092926, 0.05452905222773552, -0.28396075963974, 0.22088930010795593, -0.16975024342536926, -0.35301029682159424, -0.07598623633384705, 0.07032258808612823, -0.8090739846229553, -0.14253629744052887, 0.76167231798172, -0.04696652293205261, -1.210944652557373, 0.4921262860298157, 0.16249603033065796, -0.12937864661216736, 0.8671388030052185, -0.40338319540023804, 0.3843778073787689, -0.7210575938224792, -0.3896016776561737, -0.012906895019114017, -0.26147031784057617, 0.10315210372209549, -0.6329640746116638, -0.5726400017738342, 1.100956678390503, -0.3385281562805176, 0.1337314248085022, -0.4345676898956299, 0.6876882910728455, 0.04344357177615166, -0.17304807901382446, 0.25321730971336365, -0.8290703296661377, 1.0179016590118408, 0.26629671454429626, 0.31281203031539917, -0.030012033879756927, 0.654255747795105, -1.029093861579895, 0.5767906904220581, -0.47162967920303345, -0.026003235951066017, 0.29319819808006287, -0.6430271863937378, -0.09829962253570557, -0.6163454055786133, 0.2679811716079712, 0.12214057892560959, 0.4514056146144867, 0.244789257645607, 0.33376190066337585, -0.13890382647514343, 0.15278877317905426, 0.29844173789024353, -0.147852823138237, -0.3871980309486389, -0.5550984144210815, -0.38286474347114563, -0.255177766084671, -0.1669131964445114, -0.59510737657547, -0.09419433772563934, -0.09870947152376175, 0.5180899500846863, 0.027720343321561813, 0.06511766463518143, -0.1658174693584442, 0.4609411656856537, -1.0799025297164917, -0.5820200443267822, -0.12321826815605164, -1.3496798276901245, -0.5268656611442566, 0.3543970286846161, -0.10355700552463531, 0.13736726343631744, -0.2346586436033249, -0.01607373170554638, 1.2557207345962524, -0.18556655943393707, 0.19090339541435242, 0.6681014895439148, 0.2220887839794159, -0.16175973415374756, -0.0326644666492939, -0.5007616877555847, -0.38724035024642944, 0.3141181170940399, -0.1938156634569168, 0.17886663973331451, 0.19278892874717712, -0.38518935441970825, -0.7564964294433594, 0.39979851245880127, 0.2148739993572235, 0.533394992351532, -1.0600650310516357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102, 17756, 232, 15008, 7591, 11634, 232, 12298, 3464, 18666, 3464, 4367, 1176, 875, 3464, 5091, 136, 11137, 3464, 21074, 21094, 103]\n",
      "[0.22154638171195984, -0.03536605462431908, -0.2912493050098419, 0.5319214463233948, -0.36612260341644287, 0.03568511828780174, 0.27370965480804443, 0.00978295411914587, -0.045464105904102325, -0.267067551612854, 0.6439609527587891, -0.1166854053735733, -0.7110666632652283, 0.9173524379730225, 0.4479750990867615, 0.22522468864917755, -0.5504530668258667, -0.3796117305755615, -0.41885364055633545, -0.5035166144371033, 0.18854443728923798, 0.23881149291992188, 1.1101657152175903, -0.9617190361022949, -0.006559269968420267, 0.2220858633518219, -0.22361570596694946, -0.18334241211414337, -0.03386091813445091, 0.6254233717918396, 0.40355944633483887, -0.6828979253768921, 0.5137401819229126, 0.5067671537399292, -0.3722723424434662, 0.2831169664859772, -0.24351198971271515, 0.3541296720504761, 0.5935749411582947, -0.11793436110019684, 0.2677404582500458, -0.2652527391910553, 0.5108146071434021, -0.5921666622161865, -0.17076407372951508, -0.4888835847377777, -0.048121627420186996, -1.0304791927337646, -0.02815260738134384, -0.24148282408714294, -0.6323826313018799, 0.08970674127340317, 0.46729499101638794, -0.27126574516296387, -0.16023801267147064, 0.2958875894546509, 0.2974606454372406, 0.6791817545890808, -0.027798665687441826, 0.8141459822654724, 0.7901440858840942, -0.19421859085559845, -0.06948456913232803, -0.021152153611183167, 0.36398953199386597, -0.4986671507358551, -0.3841012120246887, -1.1012091636657715, -0.18721577525138855, 0.05288136005401611, -0.16339851915836334, 0.2620474696159363, 0.4209460914134979, -3.2898201942443848, 0.13884419202804565, 0.49751394987106323, 1.4624335765838623, 0.4739340543746948, 0.32848060131073, -0.6530799865722656, 0.07329990714788437, 0.031008083373308182, -0.8977426886558533, 0.06638327240943909, 0.011134698055684566, 0.6172598600387573, -1.379198670387268, 0.2541881799697876, 0.2216394692659378, -0.4148119390010834, 0.2917603552341461, -0.3300979435443878, -0.03924437239766121, -0.9383015036582947, -0.020288363099098206, -0.07907771319150925, 0.09857144951820374, -0.3385886549949646, -0.4194817841053009, 0.32148635387420654, -0.07520481944084167, -0.2854905426502228, -0.20120887458324432, -0.3893740475177765, 0.23189781606197357, 0.20734094083309174, 0.22193670272827148, 0.46635064482688904, 0.9917510747909546, -0.3811907470226288, -0.08535239845514297, -0.13135433197021484, 0.3366360664367676, 0.8447031378746033, 0.5194770097732544, 0.4730754792690277, -0.10181786119937897, 0.4108662009239197, 0.563346803188324, -0.004596702288836241, 0.10382963716983795, 0.1976446956396103, -0.4171176552772522, -0.01944463886320591, -0.6670040488243103, -0.20813995599746704, 0.25109803676605225, 0.29040631651878357, 0.19775390625, -0.806316077709198, -1.5847177505493164, 0.287110298871994, 0.6104015111923218, 0.06437893956899643, -0.37466368079185486, 0.3771003782749176, 0.137516051530838, 0.3757713735103607, 1.0917292833328247, -0.17437972128391266, 0.26122725009918213, -0.004995782393962145, -0.5880810618400574, 0.6752739548683167, 0.1093020811676979, 0.2423037886619568, -0.3378508687019348, -0.10573738068342209, -0.3565458357334137, -14.043425559997559, 0.47333618998527527, 0.9879235625267029, -0.5170160531997681, -1.191133975982666, 0.4889661371707916, 0.25763139128685, -0.03934541717171669, -0.4841372072696686, -0.06555373221635818, 0.05024592950940132, -0.8585819602012634, -0.1499122679233551, -0.47456884384155273, -0.8169113993644714, 0.4768712818622589, -0.09233439713716507, -0.06613187491893768, 0.37947332859039307, -0.5797991156578064, 0.2505777180194855, 0.47341272234916687, 0.35033443570137024, -1.1364407539367676, 0.2004738301038742, -0.08153394609689713, -0.34715622663497925, -0.33537548780441284, 0.47172775864601135, 0.05629431828856468, -0.7562210559844971, 0.2860223650932312, 0.33384695649147034, 0.7083267569541931, -0.13190196454524994, 1.2097312211990356, -0.28878292441368103, -0.10386764258146286, -0.5908347964286804, 0.47809305787086487, 0.2522825598716736, 0.03384004160761833, 0.1476939618587494, 0.16521002352237701, -0.037338756024837494, 0.4095965027809143, -0.3498218357563019, 0.03930428624153137, -0.04635385423898697, 0.9078057408332825, 0.2618737518787384, 0.5488669872283936, 0.015335286036133766, -0.29952970147132874, -0.506941556930542, -0.010026415809988976, -0.06746960431337357, 0.15556350350379944, 0.2657564580440521, -1.2192751169204712, 0.18280719220638275, -0.06940429657697678, -0.2720226049423218, -0.5463625192642212, 0.43049514293670654, -0.3362327814102173, 0.08873749524354935, 0.24111127853393555, 0.13457022607326508, 1.2211908102035522, 0.4936220943927765, 0.2184792459011078, 0.36253029108047485, 0.45400264859199524, 0.2977726459503174, -0.10401637107133865, 0.18768416345119476, 0.21402980387210846, 0.22453179955482483, 0.03527450934052467, -0.09471135586500168, -0.191964790225029, -0.40598565340042114, -0.009422004222869873, 0.235077366232872, -0.913417398929596, 0.2609175741672516, 0.4095500111579895, 0.2356719821691513, -0.1571531444787979, 0.8467679023742676, 0.038500506430864334, -0.271562397480011, 0.318322092294693, -0.3009224534034729, 0.0237403754144907, 0.45458608865737915, -0.06051953136920929, -0.25164952874183655, 0.33925238251686096, 0.2361641526222229, -0.39735147356987, 0.08137153089046478, -0.19485220313072205, -0.3810477554798126, 0.009734799154102802, -0.25898462533950806, 0.7409868836402893, -0.07437841594219208, 0.0029077017679810524, 0.47381719946861267, 0.2935835123062134, 0.11488308012485504, 0.2173895388841629, -0.5445263981819153, -0.261358380317688, -0.09375723451375961, -0.2329961657524109, -0.3792358636856079, 0.8232138752937317, -0.15006932616233826, 0.020131032913923264, 0.01216090191155672, -0.6171147227287292, 0.1832321286201477, 0.5187524557113647, 0.011182336136698723, -0.009324604645371437, 0.27990487217903137, 0.20388612151145935, 0.5358164310455322, 0.07206989079713821, 0.9242681264877319, -0.263177752494812, 0.6874938607215881, 0.3132344186306, 0.1495007425546646, 0.01707719825208187, 0.3223930895328522, -0.650538980960846, -0.14148642122745514, -0.4693257212638855, 0.09812896698713303, 0.0019449596293270588, 0.05856376886367798, -0.8004976511001587, -0.468003511428833, 0.42769551277160645, -0.3013893663883209, -0.0921923890709877, 0.14745904505252838, 0.6136793494224548, 0.6398677825927734, -0.12428512424230576, -0.12186910957098007, -0.6339580416679382, -0.3424898386001587, -0.2910423278808594, 0.32909417152404785, -0.08585228025913239, 0.13842763006687164, 0.411792516708374, 0.534913957118988, 0.42631080746650696, -0.22637243568897247, -0.08645687997341156, 0.13470439612865448, -0.8058285713195801, 0.2505238950252533, -0.0877099558711052, 0.2665371298789978, -0.3572221100330353, 0.37013161182403564, -0.7641989588737488, 0.8427732586860657, -0.36719581484794617, 0.017611632123589516, -0.28877130150794983, 1.0331522226333618, -0.7090998888015747, -0.08541853725910187, -0.14591820538043976, -0.16174393892288208, 0.8785203099250793, -0.6647529006004333, -1.1045868396759033, 0.010873427614569664, 0.01748516783118248, -0.38860464096069336, -0.4298636019229889, -0.500834584236145, 0.7375121116638184, -0.07536491006612778, 0.6416773796081543, -0.386107474565506, -0.19342394173145294, -0.46380215883255005, -0.04931049421429634, 0.43778252601623535, 0.32846617698669434, -0.04507628455758095, 0.9580941200256348, 1.0597399473190308, 0.0874054878950119, -0.41313958168029785, 0.5303297638893127, 0.11317025125026703, -0.3927030563354492, -0.5442252159118652, 0.7966984510421753, -0.1298971176147461, -0.20649994909763336, -0.946942150592804, 0.021568890661001205, 1.1890907287597656, -1.2584587335586548, -0.33032625913619995, -0.5287941098213196, 0.1044955775141716, 0.6208651065826416, 0.3320682644844055, 0.3645220100879669, 0.31699275970458984, -0.254189670085907, -0.5772091150283813, 0.09218815714120865, -0.20067502558231354, -0.1096423864364624, -0.4546753466129303, -0.22713476419448853, -0.07566504925489426, -0.12437400221824646, 0.597306489944458, -0.27569589018821716, -0.33553454279899597, 0.6672300100326538, -0.37848639488220215, 0.1949804127216339, -0.18572303652763367, -0.10126736015081406, -0.1346205174922943, -0.13155597448349, -1.0336236953735352, 0.10716253519058228, -0.5330153107643127, 0.7319086194038391, 0.5263681411743164, -0.23031586408615112, -0.5921040773391724, 0.0830376073718071, -0.050373226404190063, -0.21228475868701935, -0.7342960834503174, -0.39397627115249634, 0.06279758363962173, -0.04762892797589302, -0.17493334412574768, -0.5439286828041077, 0.3184834122657776, -0.5473164916038513, 0.15268610417842865, 0.18267792463302612, 0.21561913192272186, 0.5564021468162537, 0.05969442427158356, -0.3835783302783966, -1.075946569442749, -0.23557469248771667, 0.19136376678943634, -0.289767324924469, -0.08182723820209503, -0.3794582486152649, 0.06350813806056976, 0.6975003480911255, -0.15292294323444366, 0.343221515417099, 0.22280757129192352, -0.513473629951477, -0.30218952894210815, -0.42250365018844604, 0.1660229116678238, -0.30724847316741943, 0.21209849417209625, -0.8669721484184265, 0.9081754684448242, 0.45162251591682434, 1.4697083234786987, 0.3743985593318939, 0.1878405511379242, -0.16802945733070374, 0.44648921489715576, 1.2136332988739014, 0.09858949482440948, 0.31655964255332947, 0.07666774094104767, 0.19530776143074036, 0.10853416472673416, -0.09794075787067413, 0.1263394057750702, 0.004142037592828274, -0.6776214838027954, -0.3137854039669037, 0.1892148107290268, 0.06586449593305588, 0.03050629049539566, 0.2779353857040405, -0.26581695675849915, -0.12435257434844971, -0.11469384282827377, 0.19596610963344574, 0.4760918617248535, 0.16739672422409058, 0.36044934391975403, 0.20693767070770264, 0.600701630115509, 0.05300360918045044, -0.6535438299179077, 0.29670313000679016, -0.2649935483932495, 0.3100591003894806, -0.16534222662448883, 0.603947103023529, -0.1965954452753067, 0.22026464343070984, 0.5556516051292419, 0.3796635568141937, -1.0347172021865845, -0.6868613362312317, -0.5368090867996216, -0.1719871312379837, 0.12198743224143982, -0.5445279479026794, -0.16824106872081757, 0.0002375345939071849, -0.18796195089817047, -0.45415955781936646, -0.42497947812080383, -0.4615939259529114, -0.20420196652412415, 0.3073006570339203, 0.030007638037204742, -0.7294412851333618, -0.3453335165977478, -0.5656929016113281, -0.5996313095092773, -0.30348968505859375, -0.20380379259586334, 0.007559905294328928, -0.45595479011535645, -0.07570259273052216, 0.03928603231906891, -0.1769038885831833, -0.13529008626937866, 1.1439050436019897, -0.33488404750823975, -0.41670677065849304, 0.3602760434150696, -0.0847148448228836, -0.25955817103385925, -0.2038497030735016, -0.2561943531036377, 1.0978432893753052, 0.20240794122219086, 0.461073637008667, 0.1298782080411911, -0.3727109432220459, 0.7304834127426147, 0.5297349691390991, -0.551512598991394, 0.7137865424156189, 0.10095083713531494, -0.013575551100075245, -0.20321029424667358, -0.4811446964740753, -0.2997974455356598, -0.37714141607284546, -1.0301226377487183, 0.022593699395656586, 0.6810116171836853, -0.05781028792262077, 0.24921448528766632, 0.5631072521209717, 0.5052714943885803, -0.5453206896781921, 0.1162337139248848, 0.2852400839328766, -0.1939760446548462, 0.4778609573841095, 0.17707528173923492, 0.20232945680618286, 0.6441445350646973, -0.32558736205101013, -0.3608724772930145, -0.3715103566646576, 0.11373715102672577, 0.04518590122461319, 0.7240031361579895, -0.08473435789346695, 0.9469995498657227, 0.2008855640888214, -0.01693122088909149, 0.30899757146835327, 0.5058563947677612, 0.5853034853935242, -0.7788946032524109, -0.32663822174072266, 0.720164954662323, -0.05127892270684242, 0.09994880855083466, 0.20955879986286163, 0.28164759278297424, 1.2397141456604004, 0.22406895458698273, -0.16704663634300232, 0.23139506578445435, 0.16772791743278503, 0.12261948734521866, 0.4314460754394531, -0.45407983660697937, -0.44550782442092896, 0.15390868484973907, 0.0610174685716629, 0.41923561692237854, -0.49442362785339355, 0.48522162437438965, -0.7421517372131348, 0.03433595970273018, 0.0006315102800726891, -0.41982829570770264, -0.1552351415157318, 0.13251811265945435, -0.6308271288871765, -1.5918852090835571, -0.48867014050483704, 0.8102247714996338, -0.68392413854599, 0.13340236246585846, -0.40186306834220886, 0.7239654064178467, 0.45854106545448303, -0.34783491492271423, 0.6744083166122437, 0.004725173115730286, -0.13768263161182404, 0.11462234705686569, 0.6968070864677429, 0.754035234451294, 0.2863507568836212, 1.0739479064941406, -0.04527704790234566, 0.42607423663139343, -0.16836144030094147, 0.8456312417984009, 0.2766447067260742, -0.5625872611999512, 0.539954423904419, 0.11684135347604752, 0.5189899802207947, -0.43748271465301514, 0.20900914072990417, 1.0194834470748901, 0.22133643925189972, 0.2640106678009033, -0.41443586349487305, 0.5090633630752563, -0.37466493248939514, -0.06732446700334549, 0.8816194534301758, 0.19706715643405914, 0.33617717027664185, -0.3937286138534546, 0.26783373951911926, -0.6894789934158325, 0.843172013759613, 0.2604798674583435, 0.6511631608009338, 0.5821529626846313, 0.3069513142108917, 0.17376618087291718, 0.18571771681308746, 0.32309484481811523, 0.47388768196105957, -0.3340679407119751, -0.10960562527179718, 0.34419724345207214, -0.1232864260673523, -0.443847119808197, 0.7879575490951538, 0.3149968683719635, 0.1349290907382965, -0.5409595966339111, 0.151164710521698, -0.14085401594638824, 0.276419460773468, 0.3630043566226959, -0.449211061000824, -0.6947718262672424, 0.5284052491188049, -0.39295142889022827, 0.4084552824497223, 0.5665998458862305, 0.7901442050933838, -0.25017213821411133, 0.22328875958919525, -0.11152839660644531, 0.6064267158508301, 0.3957063853740692, -0.03258167579770088, -0.03688677400350571, -0.7916764616966248, 0.18453571200370789, -0.10405879467725754, -0.2748679518699646, -0.02709329128265381, -0.6729950308799744, 1.5267003774642944, 0.5404310822486877, 0.6259427070617676, 0.07243498414754868, 0.03122643753886223, 0.832466185092926, 0.05452905222773552, -0.28396075963974, 0.22088930010795593, -0.16975024342536926, -0.35301029682159424, -0.07598623633384705, 0.07032258808612823, -0.8090739846229553, -0.14253629744052887, 0.76167231798172, -0.04696652293205261, -1.210944652557373, 0.4921262860298157, 0.16249603033065796, -0.12937864661216736, 0.8671388030052185, -0.40338319540023804, 0.3843778073787689, -0.7210575938224792, -0.3896016776561737, -0.012906895019114017, -0.26147031784057617, 0.10315210372209549, -0.6329640746116638, -0.5726400017738342, 1.100956678390503, -0.3385281562805176, 0.1337314248085022, -0.4345676898956299, 0.6876882910728455, 0.04344357177615166, -0.17304807901382446, 0.25321730971336365, -0.8290703296661377, 1.0179016590118408, 0.26629671454429626, 0.31281203031539917, -0.030012033879756927, 0.654255747795105, -1.029093861579895, 0.5767906904220581, -0.47162967920303345, -0.026003235951066017, 0.29319819808006287, -0.6430271863937378, -0.09829962253570557, -0.6163454055786133, 0.2679811716079712, 0.12214057892560959, 0.4514056146144867, 0.244789257645607, 0.33376190066337585, -0.13890382647514343, 0.15278877317905426, 0.29844173789024353, -0.147852823138237, -0.3871980309486389, -0.5550984144210815, -0.38286474347114563, -0.255177766084671, -0.1669131964445114, -0.59510737657547, -0.09419433772563934, -0.09870947152376175, 0.5180899500846863, 0.027720343321561813, 0.06511766463518143, -0.1658174693584442, 0.4609411656856537, -1.0799025297164917, -0.5820200443267822, -0.12321826815605164, -1.3496798276901245, -0.5268656611442566, 0.3543970286846161, -0.10355700552463531, 0.13736726343631744, -0.2346586436033249, -0.01607373170554638, 1.2557207345962524, -0.18556655943393707, 0.19090339541435242, 0.6681014895439148, 0.2220887839794159, -0.16175973415374756, -0.0326644666492939, -0.5007616877555847, -0.38724035024642944, 0.3141181170940399, -0.1938156634569168, 0.17886663973331451, 0.19278892874717712, -0.38518935441970825, -0.7564964294433594, 0.39979851245880127, 0.2148739993572235, 0.533394992351532, -1.0600650310516357]\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m results \u001b[39m=\u001b[39m dense_retrieval(query)\n\u001b[1;32m     15\u001b[0m pprint(results)\n",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m, in \u001b[0;36mdense_retrieval\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     11\u001b[0m prebuilt_index_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindexes/dense/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mindex_method\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m enc \u001b[39m=\u001b[39m BertGermanUncasedDenseEncoder()\n\u001b[0;32m---> 14\u001b[0m search_engine \u001b[39m=\u001b[39m FaissSearcher(\n\u001b[1;32m     15\u001b[0m     prebuilt_index_path,\n\u001b[1;32m     16\u001b[0m     enc\u001b[39m.\u001b[39;49mquery_encoder \u001b[39m# \"dbmdz/bert-base-german-uncased\"\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m hits \u001b[39m=\u001b[39m search_engine\u001b[39m.\u001b[39msearch(query)\n\u001b[1;32m     20\u001b[0m results\u001b[39m=\u001b[39m[]\n",
      "File \u001b[0;32m~/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/search/faiss/_searcher.py:360\u001b[0m, in \u001b[0;36mFaissSearcher.__init__\u001b[0;34m(self, index_dir, query_encoder, prebuilt_index_name)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_encoder \u001b[39m=\u001b[39m query_encoder\n\u001b[1;32m    359\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_encoder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_encoder_from_str(query_encoder)\n\u001b[1;32m    361\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_index(index_dir)\n\u001b[1;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimension \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39md\n",
      "File \u001b[0;32m~/__git/search_l3s/search_l3s_search_srv/.venv/lib/python3.9/site-packages/pyserini/search/faiss/_searcher.py:512\u001b[0m, in \u001b[0;36mFaissSearcher._init_encoder_from_str\u001b[0;34m(encoder)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_init_encoder_from_str\u001b[39m(encoder):\n\u001b[0;32m--> 512\u001b[0m     encoder_lower \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m    513\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdpr\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m encoder_lower:\n\u001b[1;32m    514\u001b[0m         \u001b[39mreturn\u001b[39;00m DprQueryEncoder(encoder_dir\u001b[39m=\u001b[39mencoder)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# 331\n",
    "query = \"Kick-off Regelungstechnik - Grundlagen; Cover; Sicherheitshinweise; Einf\\u00fchrung und Ablauf; Versuchsaufbau\"\n",
    "embdding_query = enc.query_encoder(query)\n",
    "print(embdding_query)\n",
    "\n",
    "if embedding_331 == embdding_query:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "    \n",
    "    \n",
    "results = dense_retrieval(query)\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(326, 768)\n"
     ]
    }
   ],
   "source": [
    "# fetch the embedding as list\n",
    "import json, numpy\n",
    "\n",
    "sentence_embedding = []\n",
    "\n",
    "with open(\"./encodes/dense/bert_german_uncased/mls-tasks/data_encoded.jsonl\") as data:\n",
    "    for line in data:\n",
    "        json_obj = json.loads(line)\n",
    "        sentence_embedding.append(json_obj[\"vector\"])\n",
    "\n",
    "print(type(sentence_embedding))\n",
    "\n",
    "print(numpy.array(sentence_embedding).shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "sentence_embedding = numpy.array(sentence_embedding)\n",
    "index = faiss.IndexFlatL2(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(numpy.float32(sentence_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 71  72  73  74 185  78 143 123 266 137]]\n",
      "[[ 0.        7.625406  8.257185 10.935714 46.676605 49.768665 55.11333\n",
      "  55.84443  55.84443  56.041443]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 10\n",
    "\n",
    "xq = numpy.float32(numpy.array([enc.query_encoder(\"Montage- und Demontageautomat Versuch 5: Vollfunktion Montieren/Demontieren; Beschreibung; Erweiterungen des Aufbaus; Ablaufbeschreibung; Ablaufgraph; Programmerstellung in FUP\")]))\n",
    "\n",
    "# Distance, Labels\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mls-api/tasks/347\n"
     ]
    }
   ],
   "source": [
    "embd = sentence_embedding[71].tolist()\n",
    "\n",
    "with open(\"./encodes/dense/bert_german_uncased/mls-tasks/data_encoded.jsonl\") as data:\n",
    "    for line in data:\n",
    "        json_obj = json.loads(line)\n",
    "        if json_obj[\"vector\"] == embd:\n",
    "            print(json_obj[\"@id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'id': '/mls-api/tasks/356', 'contents': 'Ihr Feedback an uns; Willkommen; Feedbackbogen'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks/json/data.json\")\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "lst = [62, 114, 206, 105, 118, 218, 192, 270, 230, 133]\n",
    "\n",
    "print(data[62])\n",
    "\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[418, 417, 416, 415, 414, 413, 412, 411, 410, 409, 408, 407, 406, 405, 404, 403, 402, 401, 400, 399, 398, 397, 396, 395, 394, 393, 392, 391, 390, 389, 388, 387, 386, 385, 384, 383, 382, 381, 380, 379, 378, 377, 376, 375, 374, 373, 372, 371, 370, 369, 368, 367, 366, 365, 364, 363, 362, 361, 360, 359, 358, 357, 356, 355, 354, 353, 352, 351, 350, 349, 348, 347, 346, 345, 344, 343, 342, 341, 340, 339, 338, 337, 336, 335, 334, 333, 332, 331, 330, 329, 328, 327, 326, 325, 324, 323, 322, 321, 320, 319, 318, 317, 316, 315, 314, 313, 312, 311, 310, 309, 308, 307, 306, 305, 304, 303, 302, 301, 300, 299, 298, 297, 296, 295, 294, 293, 292, 291, 290, 289, 288, 287, 286, 285, 284, 283, 282, 281, 280, 279, 278, 277, 276, 275, 274, 273, 272, 271, 270, 269, 268, 267, 266, 265, 264, 263, 262, 261, 260, 259, 258, 257, 256, 255, 254, 253, 252, 251, 250, 249, 248, 247, 246, 245, 244, 243, 242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232, 231, 230, 229, 228, 227, 226, 225, 224, 223, 222, 221, 220, 219, 218, 217, 216, 215, 214, 213, 212, 211, 210, 209, 208, 207, 206, 205, 204, 203, 202, 201, 200, 199, 198, 197, 196, 195, 194, 193, 192, 191, 190, 189, 188, 187, 186, 185, 184, 183, 182, 181, 180, 179, 178, 177, 176, 175, 174, 173, 172, 171, 170, 169, 168, 167, 166, 165, 164, 163, 162, 161, 160, 159, 158, 157, 156, 155, 154, 153, 152, 151, 150, 149, 148, 147, 146, 145, 144, 143, 142, 141, 140, 139, 138, 137, 136, 135, 134, 133, 132, 131, 130, 129, 128, 127, 126, 125, 124, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28]\n"
     ]
    }
   ],
   "source": [
    "o = open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/indexes/dense/bert_german_uncased/flat/mls-tasks/docid\")\n",
    "\n",
    "docid = o.read()\n",
    "\n",
    "print(docid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<faiss.swigfaiss.IndexHNSWFlat; proxy of <Swig Object of type 'faiss::IndexHNSWFlat *' at 0x7f33ec3a6900> >\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "d = 128  # vector size\n",
    "M = 32   # number of neighbours add to each vertex on insertion\n",
    "\n",
    "\n",
    "index = faiss.IndexHNSWFlat(d, M)\n",
    "print(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.hnsw.max_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = faiss.vector_to_array(index.hnsw.levels)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.bincount(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598 410 812\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "x = 4000\n",
    "\n",
    "f1 = int((x*0.083 + 175)*1.18)\n",
    "f2 = int((x*0.057 + 120)*1.18)\n",
    "\n",
    "f3 = int((x*0.109 + 230)*(1.22))\n",
    "\n",
    "print(f1, f2, f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m x \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m j \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(s, (\u001b[39mbytes\u001b[39m, \u001b[39mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not list"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x = [\"key\", \"key\", \"key\"]\n",
    "\n",
    "j = json.loads(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_title</th>\n",
       "      <th>tasksteps_ids</th>\n",
       "      <th>task_text</th>\n",
       "      <th>taskSet_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>418</td>\n",
       "      <td>Kick-off Grundlagen der Sensorik - Schwingungs...</td>\n",
       "      <td>[2092, 2093, 2094, 2095]</td>\n",
       "      <td>1. Cover:  Willkommen zum Projekt Grundlagen...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417</td>\n",
       "      <td>Grundlagen der Sensorik: Schwingungssensor - B...</td>\n",
       "      <td>[2087, 2088, 2089, 2090, 2091]</td>\n",
       "      <td>1. Erläuterung:  Sensoranordnung für die Be...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>416</td>\n",
       "      <td>Grundlagen der Sensorik: Schwingungssensor - A...</td>\n",
       "      <td>[2083, 2084, 2085, 2086]</td>\n",
       "      <td>1. Arbeitsvorbereitung:  Arbeitsvorbereitung...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>415</td>\n",
       "      <td>Halbleiterbauelemente der Elektronik Versuch 2...</td>\n",
       "      <td>[2078, 2079, 2080, 2081, 2082]</td>\n",
       "      <td>1. Impedanzwandler:  Operationsverstärker a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>414</td>\n",
       "      <td>Halbleiterbauelemente der Elektronik Versuch 2...</td>\n",
       "      <td>[2071, 2072, 2073, 2074, 2075, 2076, 2077]</td>\n",
       "      <td>1. Operationsverstärker:  Operationsverstär...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                         task_title   \n",
       "0      418  Kick-off Grundlagen der Sensorik - Schwingungs...  \\\n",
       "1      417  Grundlagen der Sensorik: Schwingungssensor - B...   \n",
       "2      416  Grundlagen der Sensorik: Schwingungssensor - A...   \n",
       "3      415  Halbleiterbauelemente der Elektronik Versuch 2...   \n",
       "4      414  Halbleiterbauelemente der Elektronik Versuch 2...   \n",
       "\n",
       "                                tasksteps_ids   \n",
       "0                    [2092, 2093, 2094, 2095]  \\\n",
       "1              [2087, 2088, 2089, 2090, 2091]   \n",
       "2                    [2083, 2084, 2085, 2086]   \n",
       "3              [2078, 2079, 2080, 2081, 2082]   \n",
       "4  [2071, 2072, 2073, 2074, 2075, 2076, 2077]   \n",
       "\n",
       "                                           task_text  taskSet_ids  \n",
       "0    1. Cover:  Willkommen zum Projekt Grundlagen...            5  \n",
       "1    1. Erläuterung:  Sensoranordnung für die Be...            5  \n",
       "2    1. Arbeitsvorbereitung:  Arbeitsvorbereitung...            5  \n",
       "3    1. Impedanzwandler:  Operationsverstärker a...            5  \n",
       "4    1. Operationsverstärker:  Operationsverstär...            5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls_dataset.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# len(dataset.iloc[0][\"task_text\"].translate(str.maketrans('', '', string.punctuation)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kickoff', 'Analyse']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"Elektrotechnik 1 Versuch 8: Wirkleistung von Wechselspannungen; Herleitung der Wechselstromleistung; Wirkleistung der Sinuswechselspannung\"\n",
    "y = \"Kick-off LOGO! 8 PLC (Professional) Board 24V; Cover; Sicherheitshinweise; Einführung; Ablauf\"\n",
    "z = \"Kick-off; Analyse\"\n",
    "\n",
    "\n",
    "z.translate(str.maketrans('', '', string.punctuation)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kick-off analyse'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re    \n",
    "re.sub(r\"\\p{P}(?<!-)\", \"\", z).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kick-off'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Kick-off\"\n",
    "query.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() argument 1 must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m punctuation_marks \u001b[39m=\u001b[39m string\u001b[39m.\u001b[39;49mpunctuation\u001b[39m.\u001b[39;49mreplace([\u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m], [\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m punctuation_marks\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() argument 1 must be str, not list"
     ]
    }
   ],
   "source": [
    "punctuation_marks = string.punctuation.replace([\"-\", \"+\"], [\"\",\"\"])\n",
    "punctuation_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "input_path = \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks-full/json/data.json\"\n",
    "\n",
    "with open(input_path) as file:\n",
    "    data_json = json.load(file)\n",
    "    print(len(data_json))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2178/1768385597.py:4: RuntimeWarning: divide by zero encountered in log2\n",
      "  np.log2(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.log2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 418,\n",
       " 'contents': 'Kick-off Grundlagen der Sensorik - Schwingungssensor; Cover; Sicherheitshinweise; Einführung; Projektvorstellung.   1. Cover:  Willkommen zum Projekt Grundlagen der Sensorik - Schwingungssensor Lesen Sie bitte die nachfolgenden Sicherheitshinweise sowie die einleitenden Hinweise zum Projektablauf aufmerksam durch, bevor Sie mit der Bearbeitung der Betrieblichen Aufträge in den Versuchen starten. 2. Sicherheitshinweise:  Sicherheitshinweise Achtung! Beachten Sie beim Aufbau und bei der Erprobung der Geräte alle erforderlichen Sicherheitsbestimmungen, die Laborordnung und die erforderlichen Schutzmaßnahmen! Verdrahten Sie den Laborversuch grundsätzlich im stromlosen Zustand! Bei Anschluss der Versorgungsspannungen auf richtige Polarität und Spannungshöhe prüfen! © Copyright: ETS DIDACTIC GMBH Im Hüttental 11 | 85125 Kinding  | Germany Alle Rechte vorbehalten. Das Werk und seine Teile sind urheberrechtlich geschützt. Jede Nutzung in anderen als den gesetzlich zugelassenen Fällen bedarf der vorherigen schriftlichen Einwilligung des Herausgebers. Hinweis zu § 60a/b UrhG: Weder das Werk noch seine Teile dürfen ohne eine solche Einwilligung in ein Netzwerk eingestellt werden. Dies gilt auch für Intranets von Schulen und sonstigen Institutionen. Ausdrücklich hiervon ausgenommen sind die Arbeitsblätter für Schüler. Diese dürfen innerhalb der Institution, die dieses Handbuch erworben hat, zur Unterrichtsgestaltung in unveränderter Form beliebig vervielfältigt werden. Falls Änderungen durch eine nicht von der ETS DIDACTIC GMBH autorisierte Stelle vorgenommen werden, erlöschen hierdurch die Produzentenhaftung und ein etwaiger Garantieanspruch. 3. Einführung:  Einführung Sensoren bilden zusammen mit Aktoren eine wichtige Grundlage für die Automatisierung von technischen Anwendungen. Die nachfolgende Abbildung  zeigt eine hierarchische Darstellung der verschiedenen Ebenen der automatisierten Produktion. Sensoren und Aktoren befinden sich hier auf der Feldebene, also der untersten Ebene des Automatisierungssystems. Im Feld messen Sensoren physikalische Prozessgrößen und -zustände und wandeln diese in elektrische Größen um. Die Daten der Feldebene werden an die Steuerungsebene (z. B. SPS) gesendet, welche über die Aktoren den Prozess führen kann. Automatisierungspyramide In vielen Anwendungen und Prozessen ist es wichtig, Schwingungen zu Überwachen und Störungen zu erkennen oder zum Zweck der Prozessführung zu messen. Allen Störungen ist gemeinsam, dass ihre Ursache Schwingungen und Stöße sind. Dies führt zu Rissentstehung und Materialversagen. Werden diese kontinuierlich oder in festen Abständen gemessen, werden Fehlfunktion, Abnutzung und Schäden erkannt und können behoben werden. Ein gängiges Beispiel hierfür ist die frühzeitige Erfassung von Störungen in Abluft– und Belüftungsanlagen. Die Instandhaltung und Instandsetzung bei Maschinen und Anlagen kann durch das frühzeitige Erkennen von Störungen erheblich verbessert werden. Eine ständige Maschinen– und Anlagenverfügbarkeit zeigt das hohe Marktpotential für die Schwingungssensorik. Je nach Anwendungsbeispiel liegen allerdings sehr unterschiedliche Anforderungen an Bandbreite, Empfindlichkeit, Dynamikbereich, Frequenzbereich, Null–g–Spannung, Spannungsrauschdichte oder der verfügbaren Schnittstellen vor. Dementsprechend sind am Markt eine Reihe von Sensoren und Messgeräten verfügbar, die in ihrer Funktionsweise recht unterschiedlich sind. Dieses Handbuch betrachtet die Schwingungsmessung mit mikromechanischem Beschleunigungssensor und einem kapazitiven Messprinzip. 4. Projektvorstellung:  Sensoranordnung für die Beschleunigungserfassung eines Lüftermotors In einem großen Unternehmen werden Magnesium–Druckgussteile mit Magnesium–Druckgussmaschinen hergestellt. Diese Maschinen befinden sich in großen Hallen. In den Hallen befinden sich große Abluft– und Belüftungsanlagen, die den in der Luft befindlichen Magnesiumstaub abtransportieren und Frischluft zuführen. Es ist unbedingt erforderlich, dass die Abluftanlagen vorhanden und zu jeder Zeit betriebsbereit sind. Aus den Hallen muss immer ausreichend Magnesiumstaub abtransportiert und in gleichem Maße Frischluft zugeführt werden. Trotz der Belüftung lagert sich der Magnesiumstaub aus der Luft an Maschinen und Anlagen ab. Von der Ablagerung ist auch die Abluft– und Belüftungsanlage betroffen. Der Magnesiumstaub kann sich in kleinen Schlitzen und Öffnungen ablagern. Gelangt der Staub in die Lagerung des Lüfterrades, hat das zur Folge, dass der Lüftermotor Unwucht bekommt und sich mit der Zeit selbst beschädigt und ausfällt. Aus Gründen des Maschinen– und Arbeitsschutzes, sowie zur Erhaltung und Bereitschaft der Anlagen, muss eine hohe Ausfallsicherheit der Abluft– und Belüftungsanlage gewährleistet werden. Belüftungsanlage Der Inhaber des Unternehmens möchte seine Maschinen mit Überwachungssensorik ausstatten. Er möchte mit dieser Umbaumaßnahme am Belüftungssystem beginnen und aufgrund der oben genannten Gründe einen Schwingungssensor einbauen lassen. Dieser Schwingungssensor überwacht die Schwingungen des Lüftermotors und hilft dabei Schäden frühzeitig zu erkennen und diese dann zu beheben. Um mehr über die Funktion und die Eigenschaften des Sensors zu erfahren, erarbeiten Sie in der Arbeitsplanung die Grundlagen und die wichtigsten Fakten aus dem Datenblatt, bevor Sie mit der Umsetzung des betrieblichen Auftrags starten. Hinweis zur Bearbeitung der Versuche: Vertiefende theoretische Grundlagen und Datenblätter finden Sie in jedem Arbeitsschritt im Menübereich \"Aufgabendokumente\". Nutzen Sie diese, um sich das nötige Wissen für die Lösung der Aufgabenstellung und zur Beantwortung der Fragen in den Formularen anzueignen. Sie können nun mit der Bearbeitung der Versuchsreihe starten.',\n",
       " '@id': '/mls-api/tasks/418',\n",
       " 'vector': [-0.23397259414196014,\n",
       "  0.001961972564458847,\n",
       "  -0.2923840284347534,\n",
       "  0.0534830205142498,\n",
       "  0.39756500720977783,\n",
       "  -0.33446967601776123,\n",
       "  -0.08210780471563339,\n",
       "  -0.3477711081504822,\n",
       "  -0.32556578516960144,\n",
       "  0.4367249011993408,\n",
       "  0.02068767324090004,\n",
       "  -0.08982595801353455,\n",
       "  -0.5004345774650574,\n",
       "  -0.05643752962350845,\n",
       "  0.15576183795928955,\n",
       "  -0.29474562406539917,\n",
       "  -0.22783485054969788,\n",
       "  0.16589096188545227,\n",
       "  -0.167149156332016,\n",
       "  0.4394269585609436,\n",
       "  -0.1095946729183197,\n",
       "  0.2904982566833496,\n",
       "  0.20733784139156342,\n",
       "  0.08173305541276932,\n",
       "  -0.2305852770805359,\n",
       "  -0.6876134872436523,\n",
       "  0.005882482975721359,\n",
       "  0.024752076715230942,\n",
       "  -0.1117842048406601,\n",
       "  0.1674138605594635,\n",
       "  -0.16023418307304382,\n",
       "  -0.22512993216514587,\n",
       "  -0.12321048974990845,\n",
       "  -0.07023351639509201,\n",
       "  -0.1305537223815918,\n",
       "  0.23852881789207458,\n",
       "  -0.18474802374839783,\n",
       "  -0.17363613843917847,\n",
       "  0.1004435271024704,\n",
       "  0.40952378511428833,\n",
       "  0.17966648936271667,\n",
       "  -0.14482209086418152,\n",
       "  -0.39692193269729614,\n",
       "  0.06586640328168869,\n",
       "  -0.05528634041547775,\n",
       "  -0.11461374163627625,\n",
       "  -0.26342418789863586,\n",
       "  0.26095128059387207,\n",
       "  0.25012364983558655,\n",
       "  -0.14315280318260193,\n",
       "  -0.09079969674348831,\n",
       "  0.17666122317314148,\n",
       "  0.059969186782836914,\n",
       "  -0.41984453797340393,\n",
       "  -0.41061660647392273,\n",
       "  -0.5272654891014099,\n",
       "  0.24278762936592102,\n",
       "  0.13818413019180298,\n",
       "  0.5549348592758179,\n",
       "  0.050782058387994766,\n",
       "  -0.011110091581940651,\n",
       "  0.10407377034425735,\n",
       "  0.21823793649673462,\n",
       "  0.001048397272825241,\n",
       "  -0.20731544494628906,\n",
       "  -0.1093936562538147,\n",
       "  -0.07832364737987518,\n",
       "  -0.023584062233567238,\n",
       "  -0.09301923960447311,\n",
       "  0.022349655628204346,\n",
       "  -0.1652240753173828,\n",
       "  0.1017749160528183,\n",
       "  0.029259493574500084,\n",
       "  1.583893060684204,\n",
       "  0.06368415057659149,\n",
       "  0.09809239208698273,\n",
       "  0.17870764434337616,\n",
       "  0.0579647421836853,\n",
       "  0.0638885349035263,\n",
       "  -0.08959425985813141,\n",
       "  0.13828830420970917,\n",
       "  0.5913723707199097,\n",
       "  -0.4779823422431946,\n",
       "  0.1839367151260376,\n",
       "  -0.19579002261161804,\n",
       "  -0.04341045394539833,\n",
       "  -0.042339712381362915,\n",
       "  0.09586165100336075,\n",
       "  0.02407248318195343,\n",
       "  0.12468114495277405,\n",
       "  0.5505087971687317,\n",
       "  0.2748557925224304,\n",
       "  0.07234157621860504,\n",
       "  -0.1493176966905594,\n",
       "  -0.16424353420734406,\n",
       "  0.03474477678537369,\n",
       "  0.1590965837240219,\n",
       "  0.19320985674858093,\n",
       "  -0.29997289180755615,\n",
       "  0.17628315091133118,\n",
       "  -0.008341025561094284,\n",
       "  0.29207757115364075,\n",
       "  -0.14000429213047028,\n",
       "  0.08899363875389099,\n",
       "  0.3293606638908386,\n",
       "  0.01680077239871025,\n",
       "  -0.033098720014095306,\n",
       "  0.05634232237935066,\n",
       "  0.5792769193649292,\n",
       "  0.08179229497909546,\n",
       "  0.20332936942577362,\n",
       "  -0.07008957862854004,\n",
       "  0.36660486459732056,\n",
       "  0.11142581701278687,\n",
       "  -0.05612131208181381,\n",
       "  -0.18285131454467773,\n",
       "  0.273044228553772,\n",
       "  0.013185529969632626,\n",
       "  -0.253260999917984,\n",
       "  0.33173251152038574,\n",
       "  0.14423726499080658,\n",
       "  -0.1542455554008484,\n",
       "  -0.4071362614631653,\n",
       "  -0.23550376296043396,\n",
       "  0.19598335027694702,\n",
       "  -0.2783644199371338,\n",
       "  -0.02708980068564415,\n",
       "  -0.03278901055455208,\n",
       "  -0.07104521989822388,\n",
       "  -0.054457131773233414,\n",
       "  -1.6219217777252197,\n",
       "  0.016486750915646553,\n",
       "  -0.5269484519958496,\n",
       "  -0.04681304842233658,\n",
       "  0.3392181694507599,\n",
       "  -0.22523552179336548,\n",
       "  -0.11376477777957916,\n",
       "  0.06005805358290672,\n",
       "  -0.011225903406739235,\n",
       "  -0.09763652086257935,\n",
       "  0.22293956577777863,\n",
       "  -0.30538108944892883,\n",
       "  0.06857191771268845,\n",
       "  0.41467857360839844,\n",
       "  0.051725953817367554,\n",
       "  -0.019689345732331276,\n",
       "  -0.011746153235435486,\n",
       "  0.15867482125759125,\n",
       "  -2.3350119590759277e-05,\n",
       "  -9.86550521850586,\n",
       "  0.19401061534881592,\n",
       "  0.12042303383350372,\n",
       "  -0.1763516664505005,\n",
       "  0.08747698366641998,\n",
       "  0.24896100163459778,\n",
       "  -0.4951018691062927,\n",
       "  -0.12948216497898102,\n",
       "  -0.013422787189483643,\n",
       "  0.0755142867565155,\n",
       "  -0.1104414090514183,\n",
       "  0.3247520923614502,\n",
       "  -0.7601195573806763,\n",
       "  0.22301100194454193,\n",
       "  -0.2578120827674866,\n",
       "  0.05118823051452637,\n",
       "  -0.25727158784866333,\n",
       "  0.3050767183303833,\n",
       "  -0.3731132447719574,\n",
       "  0.054243553429841995,\n",
       "  0.1276644617319107,\n",
       "  -0.1367059051990509,\n",
       "  -0.16033601760864258,\n",
       "  -0.0007144436240196228,\n",
       "  0.21188168227672577,\n",
       "  -0.2849499583244324,\n",
       "  -0.2943952679634094,\n",
       "  0.320565402507782,\n",
       "  0.024103857576847076,\n",
       "  -0.10451889783143997,\n",
       "  -0.13015395402908325,\n",
       "  -0.12872761487960815,\n",
       "  0.02584252692759037,\n",
       "  -0.02955501526594162,\n",
       "  0.1621234118938446,\n",
       "  0.27323389053344727,\n",
       "  0.01783139631152153,\n",
       "  0.03373289480805397,\n",
       "  -0.2373603731393814,\n",
       "  -0.25147581100463867,\n",
       "  0.2816198468208313,\n",
       "  -0.2082151472568512,\n",
       "  0.06488154828548431,\n",
       "  -0.006280761212110519,\n",
       "  0.0907595157623291,\n",
       "  0.29319578409194946,\n",
       "  -0.2815212607383728,\n",
       "  -0.5479307770729065,\n",
       "  -0.03044319711625576,\n",
       "  0.05901702120900154,\n",
       "  -0.030091479420661926,\n",
       "  -0.12262396514415741,\n",
       "  0.23984897136688232,\n",
       "  -0.04710277169942856,\n",
       "  0.18279066681861877,\n",
       "  0.07377471774816513,\n",
       "  -0.2823213040828705,\n",
       "  0.44852811098098755,\n",
       "  0.5545382499694824,\n",
       "  0.4912019670009613,\n",
       "  0.0647280290722847,\n",
       "  -0.08675886690616608,\n",
       "  0.07703939080238342,\n",
       "  -0.08113657683134079,\n",
       "  0.004480436444282532,\n",
       "  -0.09239211678504944,\n",
       "  -0.4501953423023224,\n",
       "  0.11377568542957306,\n",
       "  0.19021303951740265,\n",
       "  0.36091935634613037,\n",
       "  0.25335991382598877,\n",
       "  -0.12440961599349976,\n",
       "  0.046364184468984604,\n",
       "  0.11856638640165329,\n",
       "  0.6388301253318787,\n",
       "  0.6604452133178711,\n",
       "  -0.06745859980583191,\n",
       "  0.538331151008606,\n",
       "  0.10415817052125931,\n",
       "  -0.19268450140953064,\n",
       "  0.3254756033420563,\n",
       "  -0.14891576766967773,\n",
       "  -0.2445884793996811,\n",
       "  -0.11477042734622955,\n",
       "  0.05147390067577362,\n",
       "  -0.04948093742132187,\n",
       "  -0.028265882283449173,\n",
       "  -0.031568244099617004,\n",
       "  0.08060689270496368,\n",
       "  0.19966058433055878,\n",
       "  -0.16579630970954895,\n",
       "  0.2472236454486847,\n",
       "  0.0680239200592041,\n",
       "  0.2920002341270447,\n",
       "  0.07894881069660187,\n",
       "  0.4805757701396942,\n",
       "  0.4201979637145996,\n",
       "  -0.15145108103752136,\n",
       "  0.18227210640907288,\n",
       "  -0.31104105710983276,\n",
       "  0.5815688371658325,\n",
       "  -0.15714916586875916,\n",
       "  -0.2809906303882599,\n",
       "  0.5168477296829224,\n",
       "  -0.1252167820930481,\n",
       "  0.028518298640847206,\n",
       "  0.08539886772632599,\n",
       "  -0.2883344888687134,\n",
       "  0.10407023876905441,\n",
       "  0.15575580298900604,\n",
       "  0.10991127789020538,\n",
       "  -0.24298730492591858,\n",
       "  -0.2082456797361374,\n",
       "  -0.0012180472258478403,\n",
       "  -0.14546474814414978,\n",
       "  0.250183641910553,\n",
       "  -0.0015375912189483643,\n",
       "  -0.19628870487213135,\n",
       "  -0.1362454891204834,\n",
       "  -0.16696539521217346,\n",
       "  0.08710464835166931,\n",
       "  0.29821091890335083,\n",
       "  -0.1569683849811554,\n",
       "  0.2955257296562195,\n",
       "  0.11022411286830902,\n",
       "  0.3572767674922943,\n",
       "  0.2489359974861145,\n",
       "  0.17937669157981873,\n",
       "  -0.3223208785057068,\n",
       "  0.19366750121116638,\n",
       "  0.18815070390701294,\n",
       "  -0.36160582304000854,\n",
       "  -0.5800444483757019,\n",
       "  -0.04642592743039131,\n",
       "  0.05377881973981857,\n",
       "  -0.022926602512598038,\n",
       "  -0.22837883234024048,\n",
       "  0.25430870056152344,\n",
       "  -0.06950847804546356,\n",
       "  0.05334281921386719,\n",
       "  0.1940269023180008,\n",
       "  -0.010763265192508698,\n",
       "  0.12981382012367249,\n",
       "  0.1997237205505371,\n",
       "  0.2957714796066284,\n",
       "  -0.19555097818374634,\n",
       "  0.008737428113818169,\n",
       "  0.1102977842092514,\n",
       "  0.0431896448135376,\n",
       "  -0.010691750794649124,\n",
       "  0.1334613859653473,\n",
       "  0.13193468749523163,\n",
       "  0.07570376992225647,\n",
       "  -0.09639755636453629,\n",
       "  0.13405467569828033,\n",
       "  -0.09165631234645844,\n",
       "  -0.325654000043869,\n",
       "  -0.10331371426582336,\n",
       "  -0.25085240602493286,\n",
       "  0.03906633332371712,\n",
       "  -0.43706995248794556,\n",
       "  0.33588606119155884,\n",
       "  0.11286412179470062,\n",
       "  -0.018782198429107666,\n",
       "  0.02391253411769867,\n",
       "  -0.021028239279985428,\n",
       "  0.24805086851119995,\n",
       "  -0.33879613876342773,\n",
       "  0.040610089898109436,\n",
       "  0.3949131965637207,\n",
       "  0.18946748971939087,\n",
       "  0.3839702606201172,\n",
       "  0.193303644657135,\n",
       "  -0.07606644928455353,\n",
       "  0.4233071804046631,\n",
       "  -0.3046295940876007,\n",
       "  0.15998591482639313,\n",
       "  0.008910410106182098,\n",
       "  0.21029147505760193,\n",
       "  -0.47668957710266113,\n",
       "  0.18947437405586243,\n",
       "  -0.2701929211616516,\n",
       "  -0.049119655042886734,\n",
       "  -0.13984157145023346,\n",
       "  0.10367724299430847,\n",
       "  -0.1639977991580963,\n",
       "  0.23999229073524475,\n",
       "  0.13758288323879242,\n",
       "  0.1058364063501358,\n",
       "  0.4675375819206238,\n",
       "  -0.2693970799446106,\n",
       "  -0.04131605103611946,\n",
       "  0.0945783257484436,\n",
       "  -0.10054606944322586,\n",
       "  0.6822524070739746,\n",
       "  -0.05054362863302231,\n",
       "  0.06336858868598938,\n",
       "  -0.06488688290119171,\n",
       "  -0.23686859011650085,\n",
       "  -0.12870091199874878,\n",
       "  0.44405224919319153,\n",
       "  0.041575487703084946,\n",
       "  -0.017690686509013176,\n",
       "  1.0821415185928345,\n",
       "  -0.08656942844390869,\n",
       "  -0.07710424810647964,\n",
       "  0.13082516193389893,\n",
       "  0.05542978644371033,\n",
       "  -0.20484982430934906,\n",
       "  0.27363547682762146,\n",
       "  -0.17144615948200226,\n",
       "  0.07247880101203918,\n",
       "  -0.014464028179645538,\n",
       "  0.1773921549320221,\n",
       "  0.1724327802658081,\n",
       "  -0.18967604637145996,\n",
       "  -0.12627935409545898,\n",
       "  -0.08155182749032974,\n",
       "  0.6595968008041382,\n",
       "  0.1862863302230835,\n",
       "  0.540442943572998,\n",
       "  0.17501938343048096,\n",
       "  0.20045723021030426,\n",
       "  0.19276517629623413,\n",
       "  0.09559512138366699,\n",
       "  -0.13161928951740265,\n",
       "  0.08056812733411789,\n",
       "  -0.2670394778251648,\n",
       "  -0.4530145525932312,\n",
       "  -0.07057980448007584,\n",
       "  0.360873281955719,\n",
       "  0.07291948795318604,\n",
       "  0.0408560186624527,\n",
       "  -0.10668091475963593,\n",
       "  -0.2313006967306137,\n",
       "  0.36994004249572754,\n",
       "  -0.051975637674331665,\n",
       "  0.11448092758655548,\n",
       "  -0.11864086985588074,\n",
       "  -0.07530109584331512,\n",
       "  -0.10943777114152908,\n",
       "  0.13242363929748535,\n",
       "  -0.06208087131381035,\n",
       "  -0.45482730865478516,\n",
       "  0.20724919438362122,\n",
       "  -0.10354135185480118,\n",
       "  -0.19780196249485016,\n",
       "  0.03709154576063156,\n",
       "  -0.3817937970161438,\n",
       "  -0.11861926317214966,\n",
       "  -0.07860788702964783,\n",
       "  0.08973635733127594,\n",
       "  -0.09655513614416122,\n",
       "  0.0838179960846901,\n",
       "  -0.4645019471645355,\n",
       "  -0.29694414138793945,\n",
       "  -0.6823688745498657,\n",
       "  -0.13002356886863708,\n",
       "  -0.12651576101779938,\n",
       "  0.3495938777923584,\n",
       "  0.07707411050796509,\n",
       "  0.20074854791164398,\n",
       "  -0.3328016400337219,\n",
       "  -0.055105652660131454,\n",
       "  0.010075528174638748,\n",
       "  -0.12740829586982727,\n",
       "  -1.1147511005401611,\n",
       "  0.36853399872779846,\n",
       "  -0.25549089908599854,\n",
       "  0.11005155742168427,\n",
       "  -0.3598264455795288,\n",
       "  0.055501993745565414,\n",
       "  -0.09724512696266174,\n",
       "  -0.2512027323246002,\n",
       "  -0.5894033908843994,\n",
       "  -0.1626494824886322,\n",
       "  -0.061683110892772675,\n",
       "  0.12458532303571701,\n",
       "  -0.16046063601970673,\n",
       "  -0.05556325986981392,\n",
       "  0.27781999111175537,\n",
       "  -0.26305609941482544,\n",
       "  -0.22082039713859558,\n",
       "  -0.19183191657066345,\n",
       "  -0.11195547878742218,\n",
       "  0.44662871956825256,\n",
       "  0.7276146411895752,\n",
       "  0.12343153357505798,\n",
       "  0.024479122832417488,\n",
       "  0.41906237602233887,\n",
       "  0.0615069754421711,\n",
       "  0.1000194251537323,\n",
       "  -0.3095342814922333,\n",
       "  0.46760761737823486,\n",
       "  0.15951451659202576,\n",
       "  0.013850957155227661,\n",
       "  -0.01708805188536644,\n",
       "  0.07514828443527222,\n",
       "  0.11611093580722809,\n",
       "  0.0904102474451065,\n",
       "  -0.3556387424468994,\n",
       "  -0.27091333270072937,\n",
       "  -0.029167089611291885,\n",
       "  -0.32146066427230835,\n",
       "  -0.15296921133995056,\n",
       "  -0.027973804622888565,\n",
       "  0.2579583525657654,\n",
       "  -0.10843327641487122,\n",
       "  0.09507468342781067,\n",
       "  -0.0017867833375930786,\n",
       "  0.3472125232219696,\n",
       "  0.32289353013038635,\n",
       "  0.3127884864807129,\n",
       "  0.4953122138977051,\n",
       "  -0.18701741099357605,\n",
       "  0.26130586862564087,\n",
       "  0.28278404474258423,\n",
       "  -0.1691308170557022,\n",
       "  -0.06733802706003189,\n",
       "  0.12142132222652435,\n",
       "  -0.3857285976409912,\n",
       "  -0.21814566850662231,\n",
       "  -0.16533538699150085,\n",
       "  0.08715379983186722,\n",
       "  -0.1750299632549286,\n",
       "  0.1492917239665985,\n",
       "  -0.27600014209747314,\n",
       "  -0.29946255683898926,\n",
       "  -0.32362210750579834,\n",
       "  -0.24111051857471466,\n",
       "  -0.12874123454093933,\n",
       "  -0.46300244331359863,\n",
       "  0.14855776727199554,\n",
       "  0.2707788944244385,\n",
       "  -0.05995751917362213,\n",
       "  0.007007911801338196,\n",
       "  -0.031064270064234734,\n",
       "  0.22067975997924805,\n",
       "  0.03821023553609848,\n",
       "  -0.16824811697006226,\n",
       "  -0.050340019166469574,\n",
       "  -0.462230384349823,\n",
       "  0.22176238894462585,\n",
       "  0.3089487552642822,\n",
       "  0.0375995859503746,\n",
       "  0.06179189309477806,\n",
       "  -0.3204769194126129,\n",
       "  0.04647821933031082,\n",
       "  0.33049774169921875,\n",
       "  0.011469706892967224,\n",
       "  0.3649965226650238,\n",
       "  0.14955750107765198,\n",
       "  -0.14867308735847473,\n",
       "  0.44041740894317627,\n",
       "  0.3832675516605377,\n",
       "  -0.0003601163625717163,\n",
       "  -0.0520346537232399,\n",
       "  -0.032674163579940796,\n",
       "  0.20643779635429382,\n",
       "  -0.08178162574768066,\n",
       "  -0.054178934544324875,\n",
       "  -0.10455542802810669,\n",
       "  0.11448433995246887,\n",
       "  -0.1547037661075592,\n",
       "  0.15660633146762848,\n",
       "  0.1661348044872284,\n",
       "  0.18796414136886597,\n",
       "  0.49886131286621094,\n",
       "  0.027665765956044197,\n",
       "  0.14015404880046844,\n",
       "  0.20612752437591553,\n",
       "  0.029639028012752533,\n",
       "  0.17737862467765808,\n",
       "  0.05848325043916702,\n",
       "  -0.173565074801445,\n",
       "  -0.00018484145402908325,\n",
       "  -0.3329562246799469,\n",
       "  0.33847904205322266,\n",
       "  -0.21160756051540375,\n",
       "  -0.11197952926158905,\n",
       "  0.0705932229757309,\n",
       "  -0.062047816812992096,\n",
       "  -0.2141319066286087,\n",
       "  -0.3457079827785492,\n",
       "  0.3986383080482483,\n",
       "  0.09312543272972107,\n",
       "  -0.3591322898864746,\n",
       "  0.06899004429578781,\n",
       "  0.0845077633857727,\n",
       "  0.14862793684005737,\n",
       "  0.14183753728866577,\n",
       "  -1.124879002571106,\n",
       "  0.001299375668168068,\n",
       "  0.20149873197078705,\n",
       "  0.027347996830940247,\n",
       "  0.16208328306674957,\n",
       "  0.25314319133758545,\n",
       "  0.04073964059352875,\n",
       "  0.15914812684059143,\n",
       "  -0.11074405908584595,\n",
       "  0.034820012748241425,\n",
       "  0.3462222218513489,\n",
       "  -0.11308414489030838,\n",
       "  -0.07181894779205322,\n",
       "  -0.03198408707976341,\n",
       "  0.19547201693058014,\n",
       "  -0.03135927766561508,\n",
       "  -0.015266941860318184,\n",
       "  -0.16693870723247528,\n",
       "  0.26807689666748047,\n",
       "  0.09360232949256897,\n",
       "  -0.23995187878608704,\n",
       "  -0.007265560328960419,\n",
       "  -0.1672515571117401,\n",
       "  -0.013950835913419724,\n",
       "  -0.29782021045684814,\n",
       "  0.456473708152771,\n",
       "  0.08344005048274994,\n",
       "  0.25781768560409546,\n",
       "  -0.10178449749946594,\n",
       "  0.15292277932167053,\n",
       "  -0.26736271381378174,\n",
       "  0.021156545728445053,\n",
       "  -0.05649162456393242,\n",
       "  -0.13310958445072174,\n",
       "  0.16299286484718323,\n",
       "  0.0902075320482254,\n",
       "  -0.018088234588503838,\n",
       "  0.0926085114479065,\n",
       "  0.00797741487622261,\n",
       "  0.3941720128059387,\n",
       "  0.3445020914077759,\n",
       "  -0.06420513987541199,\n",
       "  -0.06340649724006653,\n",
       "  0.3935243487358093,\n",
       "  -0.028813838958740234,\n",
       "  0.021365061402320862,\n",
       "  -0.2832292318344116,\n",
       "  -0.24730552732944489,\n",
       "  0.11942075192928314,\n",
       "  -0.23595985770225525,\n",
       "  -0.09092018008232117,\n",
       "  -0.0905189961194992,\n",
       "  -0.08063292503356934,\n",
       "  0.03176262229681015,\n",
       "  -0.12419968098402023,\n",
       "  0.022403262555599213,\n",
       "  0.11716118454933167,\n",
       "  0.21527798473834991,\n",
       "  -0.1704138219356537,\n",
       "  -0.04214831441640854,\n",
       "  -0.16138948500156403,\n",
       "  0.19292697310447693,\n",
       "  -0.014471776783466339,\n",
       "  -0.308505654335022,\n",
       "  0.17566117644309998,\n",
       "  0.02114851027727127,\n",
       "  0.09130197763442993,\n",
       "  0.03136906027793884,\n",
       "  -0.00102265365421772,\n",
       "  0.23341171443462372,\n",
       "  -0.3022589087486267,\n",
       "  0.010949751362204552,\n",
       "  0.09810008853673935,\n",
       "  1.4550468921661377,\n",
       "  0.22146832942962646,\n",
       "  0.06994572281837463,\n",
       "  0.053823575377464294,\n",
       "  0.1439700722694397,\n",
       "  0.07807566225528717,\n",
       "  0.10961215198040009,\n",
       "  -0.1754859983921051,\n",
       "  -0.23186033964157104,\n",
       "  -0.09301391243934631,\n",
       "  -0.39436075091362,\n",
       "  -0.19504332542419434,\n",
       "  0.03207885101437569,\n",
       "  -0.10045132040977478,\n",
       "  -0.10887113213539124,\n",
       "  0.08827297389507294,\n",
       "  0.42492765188217163,\n",
       "  -0.06557944416999817,\n",
       "  -0.3885299563407898,\n",
       "  -0.6469904184341431,\n",
       "  -0.2848351001739502,\n",
       "  -0.2713741064071655,\n",
       "  -0.3995663523674011,\n",
       "  0.152473583817482,\n",
       "  -0.13862848281860352,\n",
       "  0.8304586410522461,\n",
       "  -0.1987704485654831,\n",
       "  -0.2037767618894577,\n",
       "  -0.17729809880256653,\n",
       "  0.047917336225509644,\n",
       "  0.16820800304412842,\n",
       "  0.08383335173130035,\n",
       "  -0.10253508388996124,\n",
       "  -0.1600703001022339,\n",
       "  -0.11171700060367584,\n",
       "  0.4025431275367737,\n",
       "  -0.11895520240068436,\n",
       "  -0.024416271597146988,\n",
       "  -0.685060441493988,\n",
       "  0.0888679176568985,\n",
       "  0.06291866302490234,\n",
       "  0.2818947434425354,\n",
       "  -0.21484819054603577,\n",
       "  -0.14658376574516296,\n",
       "  -0.2220352739095688,\n",
       "  -0.0005122087895870209,\n",
       "  0.01994331181049347,\n",
       "  0.08300943672657013,\n",
       "  -0.08660340309143066,\n",
       "  0.15015794336795807,\n",
       "  0.305905818939209,\n",
       "  0.521682858467102,\n",
       "  0.41986626386642456,\n",
       "  -0.16207900643348694,\n",
       "  -0.2907133102416992,\n",
       "  0.0236450657248497,\n",
       "  0.35931700468063354,\n",
       "  0.7976833581924438,\n",
       "  -0.03358756750822067,\n",
       "  0.21189719438552856,\n",
       "  0.2135714590549469,\n",
       "  0.08427703380584717,\n",
       "  0.32364875078201294,\n",
       "  0.18831469118595123,\n",
       "  -0.013618148863315582,\n",
       "  -0.13334032893180847,\n",
       "  0.0537017285823822,\n",
       "  -0.06600081920623779,\n",
       "  0.01705087162554264,\n",
       "  0.0030617471784353256,\n",
       "  -0.4913731515407562,\n",
       "  -0.2814473807811737,\n",
       "  0.21592432260513306,\n",
       "  -0.11833769828081131,\n",
       "  0.09021563827991486,\n",
       "  -0.1232619434595108,\n",
       "  -0.22473391890525818,\n",
       "  -0.021080242469906807,\n",
       "  -0.17848722636699677,\n",
       "  0.1042303591966629,\n",
       "  -0.19742965698242188,\n",
       "  -0.3409152626991272,\n",
       "  -0.1316390484571457,\n",
       "  -0.2644228935241699,\n",
       "  0.0011196751147508621,\n",
       "  0.03214166313409805,\n",
       "  0.4724060297012329,\n",
       "  0.13371258974075317,\n",
       "  0.2204650193452835,\n",
       "  -0.01306075043976307,\n",
       "  0.08610144257545471,\n",
       "  0.46602338552474976,\n",
       "  -0.22371673583984375,\n",
       "  -0.211192786693573,\n",
       "  -0.1500362753868103,\n",
       "  -0.012413952499628067,\n",
       "  -0.011724654585123062,\n",
       "  0.16830536723136902,\n",
       "  0.1673279106616974,\n",
       "  -0.08815383911132812,\n",
       "  -0.020585039630532265,\n",
       "  -0.5135365724563599,\n",
       "  0.24202880263328552,\n",
       "  -0.024637483060359955,\n",
       "  -0.04640660434961319,\n",
       "  0.36015039682388306,\n",
       "  0.1663832664489746,\n",
       "  0.0007873028516769409,\n",
       "  -0.3459649085998535,\n",
       "  0.6558085680007935,\n",
       "  -0.03366789594292641,\n",
       "  0.030950777232646942,\n",
       "  -0.03802688047289848,\n",
       "  0.27694064378738403,\n",
       "  -0.03006269782781601,\n",
       "  0.10637607425451279,\n",
       "  0.2818686366081238,\n",
       "  -0.16324232518672943,\n",
       "  0.2009197473526001,\n",
       "  0.28008121252059937,\n",
       "  -0.04436352103948593,\n",
       "  0.2682880759239197,\n",
       "  0.1601073294878006,\n",
       "  0.2688365578651428,\n",
       "  -0.12914028763771057,\n",
       "  0.10621452331542969,\n",
       "  -1.473179817199707,\n",
       "  -0.10588079690933228,\n",
       "  -0.06695060431957245,\n",
       "  -0.5605920553207397,\n",
       "  -0.20685765147209167,\n",
       "  -0.24437373876571655,\n",
       "  0.24926047027111053,\n",
       "  0.17819996178150177,\n",
       "  0.1845102459192276,\n",
       "  0.0310687068849802,\n",
       "  0.5268228054046631,\n",
       "  -0.15077483654022217,\n",
       "  -0.051549509167671204,\n",
       "  0.18790081143379211,\n",
       "  -0.13560663163661957,\n",
       "  0.10213970392942429,\n",
       "  0.019233688712120056,\n",
       "  -0.11866386234760284,\n",
       "  -0.21842575073242188,\n",
       "  -0.15636397898197174,\n",
       "  -0.15318313241004944,\n",
       "  -0.35542595386505127,\n",
       "  -0.17256850004196167,\n",
       "  0.2136182188987732,\n",
       "  -0.3473866879940033,\n",
       "  0.3506321907043457,\n",
       "  0.17905259132385254,\n",
       "  -0.3207918405532837,\n",
       "  -0.05124085769057274]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodes_file_path = \"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/encodes/dense/bert-base-german-cased/mls-tasks-full/data_encoded.json\"\n",
    "with open(encodes_file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 1\n",
    "resistence = 0.5\n",
    "effect_hit = 1/(base*(1 - resistence)) - 1\n",
    "\n",
    "effect_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/peng_luh/__git/search_l3s/search_l3s_search_srv/datasets/mls-tasks-full/json/data.json\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 418,\n",
       " 'contents': 'Kick-off Grundlagen der Sensorik - Schwingungssensor; Cover; Sicherheitshinweise; Einführung; Projektvorstellung.   1. Cover:  Willkommen zum Projekt Grundlagen der Sensorik - Schwingungssensor Lesen Sie bitte die nachfolgenden Sicherheitshinweise sowie die einleitenden Hinweise zum Projektablauf aufmerksam durch, bevor Sie mit der Bearbeitung der Betrieblichen Aufträge in den Versuchen starten. 2. Sicherheitshinweise:  Sicherheitshinweise Achtung! Beachten Sie beim Aufbau und bei der Erprobung der Geräte alle erforderlichen Sicherheitsbestimmungen, die Laborordnung und die erforderlichen Schutzmaßnahmen! Verdrahten Sie den Laborversuch grundsätzlich im stromlosen Zustand! Bei Anschluss der Versorgungsspannungen auf richtige Polarität und Spannungshöhe prüfen! © Copyright: ETS DIDACTIC GMBH Im Hüttental 11 | 85125 Kinding  | Germany Alle Rechte vorbehalten. Das Werk und seine Teile sind urheberrechtlich geschützt. Jede Nutzung in anderen als den gesetzlich zugelassenen Fällen bedarf der vorherigen schriftlichen Einwilligung des Herausgebers. Hinweis zu § 60a/b UrhG: Weder das Werk noch seine Teile dürfen ohne eine solche Einwilligung in ein Netzwerk eingestellt werden. Dies gilt auch für Intranets von Schulen und sonstigen Institutionen. Ausdrücklich hiervon ausgenommen sind die Arbeitsblätter für Schüler. Diese dürfen innerhalb der Institution, die dieses Handbuch erworben hat, zur Unterrichtsgestaltung in unveränderter Form beliebig vervielfältigt werden. Falls Änderungen durch eine nicht von der ETS DIDACTIC GMBH autorisierte Stelle vorgenommen werden, erlöschen hierdurch die Produzentenhaftung und ein etwaiger Garantieanspruch. 3. Einführung:  Einführung Sensoren bilden zusammen mit Aktoren eine wichtige Grundlage für die Automatisierung von technischen Anwendungen. Die nachfolgende Abbildung  zeigt eine hierarchische Darstellung der verschiedenen Ebenen der automatisierten Produktion. Sensoren und Aktoren befinden sich hier auf der Feldebene, also der untersten Ebene des Automatisierungssystems. Im Feld messen Sensoren physikalische Prozessgrößen und -zustände und wandeln diese in elektrische Größen um. Die Daten der Feldebene werden an die Steuerungsebene (z. B. SPS) gesendet, welche über die Aktoren den Prozess führen kann. Automatisierungspyramide In vielen Anwendungen und Prozessen ist es wichtig, Schwingungen zu Überwachen und Störungen zu erkennen oder zum Zweck der Prozessführung zu messen. Allen Störungen ist gemeinsam, dass ihre Ursache Schwingungen und Stöße sind. Dies führt zu Rissentstehung und Materialversagen. Werden diese kontinuierlich oder in festen Abständen gemessen, werden Fehlfunktion, Abnutzung und Schäden erkannt und können behoben werden. Ein gängiges Beispiel hierfür ist die frühzeitige Erfassung von Störungen in Abluft– und Belüftungsanlagen. Die Instandhaltung und Instandsetzung bei Maschinen und Anlagen kann durch das frühzeitige Erkennen von Störungen erheblich verbessert werden. Eine ständige Maschinen– und Anlagenverfügbarkeit zeigt das hohe Marktpotential für die Schwingungssensorik. Je nach Anwendungsbeispiel liegen allerdings sehr unterschiedliche Anforderungen an Bandbreite, Empfindlichkeit, Dynamikbereich, Frequenzbereich, Null–g–Spannung, Spannungsrauschdichte oder der verfügbaren Schnittstellen vor. Dementsprechend sind am Markt eine Reihe von Sensoren und Messgeräten verfügbar, die in ihrer Funktionsweise recht unterschiedlich sind. Dieses Handbuch betrachtet die Schwingungsmessung mit mikromechanischem Beschleunigungssensor und einem kapazitiven Messprinzip. 4. Projektvorstellung:  Sensoranordnung für die Beschleunigungserfassung eines Lüftermotors In einem großen Unternehmen werden Magnesium–Druckgussteile mit Magnesium–Druckgussmaschinen hergestellt. Diese Maschinen befinden sich in großen Hallen. In den Hallen befinden sich große Abluft– und Belüftungsanlagen, die den in der Luft befindlichen Magnesiumstaub abtransportieren und Frischluft zuführen. Es ist unbedingt erforderlich, dass die Abluftanlagen vorhanden und zu jeder Zeit betriebsbereit sind. Aus den Hallen muss immer ausreichend Magnesiumstaub abtransportiert und in gleichem Maße Frischluft zugeführt werden. Trotz der Belüftung lagert sich der Magnesiumstaub aus der Luft an Maschinen und Anlagen ab. Von der Ablagerung ist auch die Abluft– und Belüftungsanlage betroffen. Der Magnesiumstaub kann sich in kleinen Schlitzen und Öffnungen ablagern. Gelangt der Staub in die Lagerung des Lüfterrades, hat das zur Folge, dass der Lüftermotor Unwucht bekommt und sich mit der Zeit selbst beschädigt und ausfällt. Aus Gründen des Maschinen– und Arbeitsschutzes, sowie zur Erhaltung und Bereitschaft der Anlagen, muss eine hohe Ausfallsicherheit der Abluft– und Belüftungsanlage gewährleistet werden. Belüftungsanlage Der Inhaber des Unternehmens möchte seine Maschinen mit Überwachungssensorik ausstatten. Er möchte mit dieser Umbaumaßnahme am Belüftungssystem beginnen und aufgrund der oben genannten Gründe einen Schwingungssensor einbauen lassen. Dieser Schwingungssensor überwacht die Schwingungen des Lüftermotors und hilft dabei Schäden frühzeitig zu erkennen und diese dann zu beheben. Um mehr über die Funktion und die Eigenschaften des Sensors zu erfahren, erarbeiten Sie in der Arbeitsplanung die Grundlagen und die wichtigsten Fakten aus dem Datenblatt, bevor Sie mit der Umsetzung des betrieblichen Auftrags starten. Hinweis zur Bearbeitung der Versuche: Vertiefende theoretische Grundlagen und Datenblätter finden Sie in jedem Arbeitsschritt im Menübereich \"Aufgabendokumente\". Nutzen Sie diese, um sich das nötige Wissen für die Lösung der Aufgabenstellung und zur Beantwortung der Fragen in den Formularen anzueignen. Sie können nun mit der Bearbeitung der Versuchsreihe starten.',\n",
       " '@id': '/mls-api/tasks/418'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].get(\"content\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
